[{"title":"Docker学习笔记","date":"2023-10-14T01:14:38.000Z","path":"2023/Docker学习笔记/","text":"Docker安装(Ubuntu环境) Docker命令 帮助命令 镜像命令 容器命令 常用其他操作命令 可视化 portainer Docker镜像 镜像 Docker镜像加载原理 Commmit 镜像 容器数据卷 使用容器数据卷 实战：安装MySQL 具名挂载和匿名挂载 初识DockerFile 数据卷容器 DockerFile Docker网络原理 IDEA整合Docker 集群 Docker Compose Docker Swarm CI&#x2F;CD Jenkins Docker安装(Ubuntu环境)参考：https://blog.csdn.net/Tester_muller/article/details/131440306 ubuntu下自带了Docker的库，不需要添加新的源。但是版本过低，需要使用root权限，卸载Ubuntu自带的低版本Docker（若有）:sudo apt-get remove docker docker-engine docker.io containerd runc 更新软件：sudo apt update;sudo apt upgrade 安装Docker依赖：apt-get install ca-certificates curl gnupg lsb-release 添加Docker官方GPG密钥：curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 添加Docker软件源（如：阿里云）：sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; 安装Docker：apt-get install docker-ce docker-ce-cli containerd.io 配置用户组（可选）：默认情况下，只有root用户和Docker组的用户才能运行Docker命令。我们可以将当前用户添加到Docker组，以避免每次使用Docker时都需要使用sudo. sudo usermod -aG docker $USER 运行Docker：systemctl start docker 安装工具：apt-get -y install apt-transport-https ca-certificates curl software-properties-common 重启Docker：service docker restart 验证是否安装成功sudo docker run hello-world 查看Docker版本：docker version 查看已安装镜像：docker images Docker执行流程图 ​ Docker执行流程图 Docker命令 ​ Docker命令结构图 帮助命令123docker version # 查看docker版本docker info # 显示docker的系统信息，包括镜像和容器的数量docker 命令 --help # 帮助命令 帮助文档的地址：https://docs.docker.com/engine/reference/commandline/ 镜像命令 docker images：查看所有本地已安装的镜像 12345678910111213141516171819202122232425262728293031323334 ubuntu@VM-8-12-ubuntu:~$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest 9c7a54a9a43c 6 months ago 13.3kB # 命令解释 REPOSITORY 镜像的仓库源 TAG 镜像的标签 IMAGE ID 镜像的id CREATED 镜像的创建时间 SIZE 镜像的大小 # 可选项 --all, -a # 列出所有镜像 --quiet, -q # 只显示镜像的id2. `docker search 镜像名`：搜索镜像 ```shell ubuntu@VM-8-12-ubuntu:~$ docker search mysql NAME DESCRIPTION STARS OFFICIAL AUTOMATED mysql MySQL is a widely used, open-source relation… 14567 [OK] mariadb MariaDB Server is a high performing open sou… 5558 [OK] # 可选项,通过搜索来过滤 --filter, -f Filter output based on conditions provided --format Pretty-print search using a Go template --limit Max number of search results --no-trunc Don&#x27;t truncate output --filter=STARS=3000 #搜索出来的镜像就是stars大于3000的 ubuntu@VM-8-12-ubuntu:~$ docker search mysql --filter=STARS=3000 NAME DESCRIPTION STARS OFFICIAL AUTOMATED mysql MySQL is a widely used, open-source relation… 14567 [OK] mariadb MariaDB Server is a high performing open sou… 5558 [OK] 等同于在dockerHub中搜索镜像 docker pull 下载镜像 1234567docker pull [OPTIONS] NAME[:TAG|@DIGEST]# 可选项--all-tags, -a Download all tagged images in the repository--disable-content-trust true Skip image verification--platform API 1.32+ Set platform if server is multi-platform capable--quiet, -q Suppress verbose output 1234567891011121314151617ubuntu@VM-8-12-ubuntu:~$ docker pull mysqlUsing default tag: latest # 不加参数默认下载最新版镜像latest: Pulling from library/mysql8e0176adc18c: Pull complete # 分层下载，docker images的核心 联合文件系统2d2c52718f65: Pull complete d88d03ce139b: Pull complete 4a7d7f11aa1e: Pull complete ce5949193e4c: Pull complete f7f024dfb329: Pull complete 5fc3c840facc: Pull complete 509068e49488: Pull complete cbc847bab598: Pull complete 942bef62a146: Pull complete Digest: sha256:1773f3c7aa9522f0014d0ad2bbdaf597ea3b1643c64c8ccc2123c64afd8b82b1 # 签名Status: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest #真实地址# 所以: docker pull mysql &lt;==&gt; docker pull docker.io/library/mysql:latest docker rmi 删除镜像 123docker rmi -f 容器id #删除指定的镜像docker rmi -f 容器id 容器id 容器id # 删除多个镜像docker rmi -f $(docker images -aq) #删除全部的镜像 容器命令注：先有镜像才能创建容器，可以在Linux上安装Docker。然后再在Docker上安装一个Centos镜像进行学习。（等同于在docker上装一个Centos VM） 1docker pull centos 创建容器并启动 123456789101112131415161718192021 docker run [OPTIONS] IMAGE # 参数说明 --name=&quot;name&quot; 容器名字 tomcat01，tomcat02 用来区分容器 -d 后台方式运行 -it 使用交互方式运行，进入容器查看内容 -p 指定容器的端口 -p 8080:8080 -p ip:主机端口:容器端口 -p 主机端口:容器端口 （常用） -p 容器端口 容器端口 -P 随机指定端口----------------------------------------------------------- # 通过前台启动容器并进入容器（前台进程）docker run -it centos /bin/bash# 查看容器内容ls# 停止容器并退出exit 查看所有运行的容器 1234docker ps # 查看当前运行的容器 -a # 查看当前及以往运行的容器 -n=? # 显示最近运行的？（几）个容器 -q # 只显示容器的编号 退出容器 12exit # 停止容器并退出Ctrl + P + Q # 退出不停止容器 删除容器 123docker rm 容器id # 删除指定容器（未运行的容器）。需要强制删除: rm -fdocker rm -f $(docker ps -aq) # 删除所有的容器docker ps -a -q|xargs docker rm -f # 删除所有的容器 启动和停止容器 1234docker start 容器id # 启动容器docker restart 容器id # 重启容器docker stop 容器id # 停止当前正在运行的容器docker kill 容器id # 强制停止当前容器 常用其他操作命令 通过后台启动容器：docker run -d 容器名 Docker常见的坑之一：Docker容器没有运行任何应用程序会启动后立即自动kill后exited。 如：docker run -d centos就无法正常从后台运行cenos，而docker run -it centos /bin/bash则可成功通过前台启动容器并进入容器。 原因：当你启动一个Docker容器时，你需要指定一个要运行的应用程序。如果你没有指定任何应用程序，容器将在启动后立即退出。 查看容器的日志：docker logs 容器id（需要保证容器正在运行） -t ：显示日志时间戳 -f ：显示所有日志 –tail number：要显示的日志条数 如：docker logs -tf --tail 10 f83add00ab91，即为查看id为f83add00ab91的容器最后的10条日志带时间戳字符串形式的详细信息 没有日志信息可以通过脚本创造一些日志：docker run -d centos /bin/sh -c &quot;while true;do echo docker66666;sleep 1;done&quot; 查看容器的进程信息：docker top 容器id 查看镜像的元数据：docker inspect 容器id 进入当前正在运行的容器 123456789101112131415161718192021222324252627282930 # 通常容器都是使用后台方式进行的，需要进入容器，修改一些配置 # 方式一 docker exec -it 容器id bashShell # 测试 ubuntu@VM-8-12-ubuntu:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbf64c038f8b1 centos &quot;/bin/sh -c &#x27;while t…&quot; 24 seconds ago Up 23 seconds upbeat_goldwasserubuntu@VM-8-12-ubuntu:~$ docker exec -it bf64c038f8b1 /bin/bash[root@bf64c038f8b1 /]# lsbin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var[root@bf64c038f8b1 /]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 16:16 ? 00:00:00 /bin/sh -c while true;do echo docker66666;sleep 1;doneroot 100 0 0 16:18 pts/0 00:00:00 /bin/bashroot 250 1 0 16:20 ? 00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 1root 251 100 0 16:20 pts/0 00:00:00 ps -ef[root@bf64c038f8b1 /]# # 方式二docker attach 容器id# 测试ubuntu@VM-8-12-ubuntu:~$ docker attach bf64c038f8b1正在执行的当前代码.....# 区别# docker exec # 进入容器后开启一个新的终端，可以在里边此操作（常用）# docker attach # 进入容器正在执行的终端，不会启动新的进程 从容器内拷贝文件到主机上 1234567891011121314# 命令docker cp 容器id:容器内路径 目的的主机路径#测试dockers attach bf64c038f8b1 # 进入正在执行的容器cd /home # cd到容器的home下ls # 查看容器home下的文件信息touch test.java # 创建test.java文件exit # 停止并退出容器，回到本机docker ps -a # 查看容器信息。无需容器运行，只有存在就可以进行拷贝docker cp bf64c038f8b1:/home/test.java /home # 将id为bf64c038f8b1的容器/home目录下的test.java文件拷贝到主机的/home目录下ls # 查看信息是否拷贝成功# 拷贝是一个手动过程，使用 -v 卷的技术，可以实现自动同步 注：sudo是获取root权限的命令 查看Docker工作目录(默认)：ls /var/lib/docker/ 删除Docker资源：rm -rf /var/lib/docker/ 停止Docker服务：sudo systemctl stop docker 卸载Docker软件包：sudo apt-get purge docker-ce docker-ce-cli containerd.io 删除Docker配置和数据：sudo rm -rf /etc/docker sudo rm -rf /var/lib/docker sudo rm -rf /var/lib/containerd 删除Docker用户组：sudo groupdel docker 删除Docker存储库：sudo rm -f /etc/apt/sources.list.d/docker.list 更新APT缓存：sudo apt-get update 清除Docker无用的依赖项：sudo apt-get autoremove 测试安装Nginx 12345678910111213141516171819202122232425262728293031323334353637# 安装nginx版本为1.24.0的容器docker pull nginx:1.24.0# -d # 后台运行# --name # 命名运行时的名字# -p 宿主机端口:容器端口 # 在宿主机指定端口下运行容器的指定端口 # 则如下命令为：以后台形式运行nginx:1.24.0容器 且是在宿主机的3344端口运行容器的80端口 并命名为nginx-1.24.0#如果最后直接写nginx 则是运行nginx的最新版本。若本机没有，则会自动下载再运行docker run -d --name nginx-1.24.0 -p 3344:80 nginx:1.24.0# curl 查看端口运行信息ubuntu@VM-8-12-ubuntu:~$ curl localhost:3344&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;....# 可以看到Welcome to nginx!等页面信息表示端口当前运行的为nginx，即nginx运行成功# 进入容器# docker /bin/bash:可以帮助开发者进入一个Docker容器的命令行界面，以便进行调试、查看日志、执行命令等操作。当需要进行容器内部的操作时，使用/bin/bash命令可以启动一个交互式的终端会话，使得开发者可以像在本地终端一样操作容器。docker exec -it nginx-1.24.0 /bin/bash# 运行进入后可查看Nginx配置文件位置root@831f7f5b5bf1:/# whereis nginxnginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx # /etc/nginx：配置文件目录 # /usr/share/nginx：网页发布目录root@831f7f5b5bf1:/# lsbin docker-entrypoint.d home lib64 mnt root srv usrboot docker-entrypoint.sh lib libx32 opt run sys vardev etc lib32 media proc sbin tmproot@831f7f5b5bf1:/# cd /etc/nginxroot@831f7f5b5bf1:/etc/nginx# lsconf.d mime.types nginx.conf uwsgi_paramsfastcgi_params modules scgi_params# 所以我们已经可以查到配置文件，进而实现进入容器内部去修改配置文件# 可以看出，这种方法会比较麻烦，那么我们有没有一种方式，使得可以在容器外部提供一个映射路径，达到在容器外修改文件名，容器内部自动更新修改？-v 数据卷！ ​ Docker端口暴露结构图 测试安装tomcat 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 官方使用 docker run 实现下载后直接运行docker run -it --rm tomcat:8.5# 一般启动都是后台，停止了容器之后，容器还是可以查到 docker run -it --rm，一般用来测试，用完即删# 先下载再启动docker pull tomcat:8.5# 公网测试访问结果： HTTP状态 404 - 未找到类型 状态报告描述 源服务器未能找到目标资源的表示或者是不愿公开一个已经存在的资源表示。Apache Tomcat/8.5.95# 以上结果虽404但也说明部署成功# why？？↓# 进入容器ubuntu@VM-8-12-ubuntu:~$ docker exec -it tomcat01 /bin/bashroot@5946fce6c6f4:/usr/local/tomcat# lsbin lib NOTICE tempBUILDING.txt LICENSE README.md webappsconf logs RELEASE-NOTES webapps.distCONTRIBUTING.md native-jni-lib RUNNING.txt workroot@5946fce6c6f4:/usr/local/tomcat# cd webappsroot@5946fce6c6f4:/usr/local/tomcat/webapps# lsroot@5946fce6c6f4:/usr/local/tomcat/webapps# # 由以上可以得出404的原因可能由：1. linux命令少了（未指定版本，默认下载）2. 没有webapps3. 阿里云镜像默认下载是最小的镜像，所有不必要的都剔除掉（未指定版本，默认下载）4. 只保证最小的运行环境# 解决方案（修改webapps.dist为webapps 或者 拷贝webapps.dist/* 到webapps下）root@5946fce6c6f4:/usr/local/tomcat# clearroot@5946fce6c6f4:/usr/local/tomcat# lsbin lib NOTICE tempBUILDING.txt LICENSE README.md webappsconf logs RELEASE-NOTES webapps.distCONTRIBUTING.md native-jni-lib RUNNING.txt workroot@5946fce6c6f4:/usr/local/tomcat# cd webapps.dist/root@5946fce6c6f4:/usr/local/tomcat/webapps.dist# lsdocs examples host-manager manager ROOTroot@5946fce6c6f4:/usr/local/tomcat/webapps.dist# cd..bash: cd..: command not foundroot@5946fce6c6f4:/usr/local/tomcat/webapps.dist# cd ..root@5946fce6c6f4:/usr/local/tomcat# cp -r webapps.dist/* webappsroot@5946fce6c6f4:/usr/local/tomcat# cd webappsroot@5946fce6c6f4:/usr/local/tomcat/webapps# lsdocs examples host-manager manager ROOTroot@5946fce6c6f4:/usr/local/tomcat/webapps# # 思考：如果我们每次部署项目，都要进入容器内部，就会显得十分麻烦。那么我们有没有一种方式，使得可以在容器外部提供一个映射路径，达到在容器外放置项目，容器内部自动同步？ 部署 ES + kibana 12345678910# es暴露的接口过多# es需要安全挂载？？# --net somenetwork ？？？ docker的网络# 运行命令docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=string-node&quot; -e ES_JAVA_OPTS=&quot;-Xmx512m&quot; elasticsearch[:version] # ES_JAVA_OPTS=&quot;-Xmx512m&quot;：限制运行内存# elasticsearch下载内存巨大 所以需要再下载的时候加内存限制docker stats 可视化 portainer（暂时使用） Rancher（CI&#x2F;CD可用） portainerDocker的可视化工具 1234567891011# 启动并下载最新版portainer/portainer镜像docker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --name portainer portainer/portainer# 查看正在运行的容器docker ps# 查看日志docker logs -f portainer# 本地运行 查看是否成功curl localhost:8088 一般docker不会选择使用可视化工具，自行测试一下学学使用即可。 Docker镜像镜像独立的软件包，用来打包软件运行环境及运行环境开发软件。 包括某个软件所需要的所有内容，包括代码、库、环境变量和配置文件。 Docker镜像加载原理 UnionFS(联合文件系统) UnionFS(联合文件系统)：分层、轻量级并且高性能的文件系统。支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同的目录挂载到通用一个虚拟文件系统下。 Union文件系统是Docker镜像的基础。 镜像可以通过分层进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各个文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 Docker镜像加载原理 bootfs：主要包括bootloader和kernel。bootloader主要是引导加载kernel，Linux行启动时就会加载bootfs文件系统，在Docker镜像的最底层是bootfs。当boot加载完成后整个内核就都在内存了，此时内存使用权已由bootfs转交给系统，此时系统也会卸载bootfs。 rootfs： 在bootfs之上，包括的就是典型如Linux系统中的&#x2F;dev，&#x2F;proc,&#x2F;bin,&#x2F;etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu、CentOS等。 Docker中的一个容器就是一个小的Linux虚拟机环境。 对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了。因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见，对于不同的Linux发行版，bootfs基本是一致的，rootfs会有差别，因此不同的发行版本可以用同一个bootfs。 虚拟机是分钟级，容器是秒级！ ​ Docker镜像分层的理解示意图 ​ Docker镜像下载示意图 特点 有些应用的某些层是相同的，则只需要下载不存在的层。 Docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部。这个可写成通常被称为容器层。 也就是说，容器之下都叫镜像层。 而我们操作过后需要提交的是将容器层和原有镜像层一起打包起来的镜像层。 Commmit 镜像12docker commit # 提交容器成为一个副本docker commit -m=&quot;提交内容的标签信息&quot; -a=&quot;作者&quot; 容器id 目标镜像名:[TAG] 测试 1234567# 启动一个默认的tomcat# 发行tomcat下的webapps是空的，镜像的原因，官方默认webapps下是没有文件的# 默认的webapps.list放置了基本文件。所有我们要运行有页面需要将webapps.list下的所有文件拷贝到webapps下# 完成以上操作后commit命令打包获得一个新镜像 容器数据卷如果数据都在容器中，那么删除容器数据就会丢失！需求：数据可以持久化 —&gt; 容器之间可以有一个数据共享的技术！Dokcer容器中产生的数据，同步到本地！ &#x3D;&#x3D;&#x3D;》卷技术。实现目录的挂载，Docker中的容器数据映射到Linux主机的某个目录下进而持久化。 ​ Docker卷挂载机制 也就是说：卷技术就是容器的持久化和同步操作；容器间也是可以数据共享的。 使用容器数据卷 方式一：直接使用命令 -v 12345678docker run -it -v 本机目录:容器目录 容器id(或容器名) [/bin/bash]# 测试# 挂载 centos镜像下 运行name为centos 的容器docker run -it -v /home/ceshi:/home --name centos /bin/bash# 查看 容器centos的 运行实例id为cfa751800ae1 的信息 # 查找Mounts信息docker inspect cfa751800ae1 测试文件同步 注意：挂载启动命令 12docker run -p 1000:2000 -t -i -v /src:/dst --privileged=true --name 容器名称 image_name:tag /bin/bash注：-t -i 可以写成-it 对该命令字段的理解： 123456789101112131415docker run：启动containerubuntu：你想要启动的image--name=&quot;name&quot; # 名字-t：进入终端-w, --workdir string 指定工作目录-i：获得一个交互式的连接，通过获取container的输入--rm: 运行完成即删除 # 一般不和 -it 一块运行-d:后台运行docker // 与-it相反-p: 指定端口(可以多次-p参数) 本机的1000端口映射到容器的2000端口-P: 大写的P，随机指定端口--net: --net=host不指定端口，与宿主机共用一套IP和端口-v: 挂载卷，挂载宿主机的src/文件到容器的dst/目录--privileged: 使用该参数，container内的root拥有真正的root权限。 否则，container内的root只是外部的一个普通用户权限。/bin/bash：在container中启动一个bash shell 测试卷技术的数据是双向的 实战：安装MySQL解决MySQL数据持久化问题！ 12345678910# 获取镜像docker pull mysql:5.7# 运行容器 需要做数据挂载！# 安装启动MySQL 需要配置密码！！！# 官方测试命令 docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag# 启动本地主机的MySQL 密码123456 端口映射为3308docker run -d -p 3308:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7# 运行后 使用本地电脑连接远程运行的mysql 连接成功则为部署成功 ​ MySQL运行后本地测试连接成功 查看挂载文件： ​ MySQL挂载成功 本地创建数据库，查看数据是否成功同步 ​ 测试MySQL数据持久化 ​ 测试容器删除后数据仍存在 至此，实现了MySQL数据持久化功能！ 具名挂载和匿名挂载12345678910111213141516# 匿名挂载# -P:随机映射端口# 使用-v 但不指定本地主机的映射路径 ==&gt; 只指定了容器内的路径docker run -d -P --name nginx01 -v /etc/nginx nginx# 查看数据卷信息docker volumn ls# 发现数据卷信息为 以下形式ubuntu@VM-8-12-ubuntu:~$ docker volume lsDRIVER VOLUME NAMElocal 5f4aa55e7d5d28d66fe6ebbe434c61332c01026e231048e58f8512d50a0df309# 则此形式为 匿名挂载 1234567891011121314# 具名挂载# -v 卷名:容器内路径# 即使用的相对路径juming-nginx 而不是/juming-nginx（从根目录开始的绝对路径）进行挂载docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx# 查看数据卷信息docker volumn ls# 信息看到有卷名ubuntu@VM-8-12-ubuntu:~$ docker volume lsDRIVER VOLUME NAMElocal juming-nginx# 查看卷名的具体位置docker volume inspect juming-nginx ​ 查看具名挂载信息 所有的docker容器内的卷，没有指定目录，都会存在/var/lib/docker/volumes/下。 拓展一个小问题： ​ Docker下查看volume出现的权限问题 起初：我想要cd到&#x2F;var&#x2F;lib&#x2F;docker，但是出现一个权限不够的错误，然后想到使用sudo cd &#x2F;etc&#x2F;docker时，又提示说sudo: cd：找不到命令。 所以：该问题主要是不具root权限 且 cd 无法直接用sudo运行导致 先来解决方案： 使用sudo -i提高用户权限 使用sudo -s 打开特殊的shell 以上命令都可以使用exit退出，也可以使用快捷键Ctrl+D退出 报错原因分析： shellshell是一个命令解析器所谓shell是一个交互式的应用程序。shell执行外部命令的 时候，是通过fork&#x2F;exec叉一个子进程，然后执行这个程序。 sudosudo 是一种程序，用于提升用户的权限，在linux中输入sudo就是调用sudo这个程序提升权限sudo的意思是，以别人的权限叉起一个进程，并运行程序。 cdcd是shell的内部命令。也就是说，是直接由shell运行的，不叉子进程。你在当前进程里当然不能提升进程的权限（其实也可以，不过得编程的时候写到代码里，然后再编译，而我们的 shell没有这个功能，否则岂不是太危险了？黑客.sh cd不是一个应用程序而是Linux内建的命令，而sudo仅仅只对应用程序起作用。sudo foo只意味着以root权限运行foo程序 所以，sudo cd &#x2F;etc&#x2F;docker会报sudo: cd：找不到命令。 Docker下查看所有卷信息 所有的docker容器内的卷，没有指定目录的情况下，都是在/var/lib/docker/volumes/xxxx/_data ​ Docker下找到配置文件信息 具名挂载可以方便我们找到所需要的卷，这也是我们大多数情况下使用的挂载方式 总结：如何确定是哪种挂载形式？ -v 容器内路径 ：匿名挂载 -v 卷名:容器内路径：具名挂载 -v /宿主机路径:容器内路径：指定路径挂载 拓展： 123456789# 通过 -v 容器内路径：ro rw 改变读写权限ro readonly # 只读rw readwrite # 可读可写# 一旦设置了这个容器的权限，容器对我们挂载出来的内容就有限制了docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:ro nginxdocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:rw nginx# ro 只要看到ro就说明了这个路径只能通过宿主机来操作，容器内部是无法操作的！ 初识DockerFileDockerFile就是用来构建docker镜像的构建文件，是一种命令脚本。 通过这个脚本可以生成镜像，镜像是分层的，而脚本的一个个命令，每个命令就是一层！ 测试 1234567891011121314# 创建一个dockerFile文件 名字自定义 建议使用 dockerFile# 文件中的内容 所有指令（大写） 参数FROM centosVOLUME [&quot;volume01&quot;,&quot;volume02&quot;] # 直接只写容器内路径 ==&gt; 匿名挂载CMD echo &quot;------end------&quot;CMD /bin/bash# 这里的一个命令就是镜像的一层# 在当前目录下生成镜像名为loumeng/centos的镜像docker build -f dockerfile1 -t loumeng/centos . ​ 编写DockerFile测试文件 构建dockerfile文件 在当前目录下生成镜像名为loumeng/centos的镜像：docker build -f dockerfile1 -t loumeng/centos . ​ Dockerfile构建镜像测试 测试：运行生成的镜像文件，查看数据卷 ​ 运行测试DockerFile结果 12345678# 测试数据同步# 在容器内部创建文件container.txt[root@3530dcbfd45b /]# cd volume01[root@3530dcbfd45b volume01]# touch container.txt [root@3530dcbfd45b volume01]# lsconrainer.txt[root@3530dcbfd45b volume01]# 12345678# 宿主机中查看是否有容器创建的文件root@VM-8-12-ubuntu:/home/docker-test-volume# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3530dcbfd45b 76a87817841c &quot;/bin/bash&quot; 6 minutes ago Up 6 minutes bold_goodall2ade1a1ee24f nginx &quot;/docker-entrypoint.…&quot; 4 hours ago Up 4 hours 0.0.0.0:32770-&gt;80/tcp, :::32770-&gt;80/tcp nginx02157272f9755b nginx &quot;/docker-entrypoint.…&quot; 5 hours ago Up 5 hours 0.0.0.0:32768-&gt;80/tcp, :::32768-&gt;80/tcp nginx01root@VM-8-12-ubuntu:/home/docker-test-volume# docker inspect 3530dcbfd45b# 可以看到如下信息 ​ Dockerfile构建镜像后查看数据卷的挂载路径 得到数据卷挂载宿主机的路径后，就可以查看我们刚建的数据文件有没有被同步了。 123456root@VM-8-12-ubuntu:/home/docker-test-volume# cd /var/lib/docker/volumes/abf6b7a64fbd98c625b979ee27cdb222a4af1863b7706c387c53489bd5080417/_dataroot@VM-8-12-ubuntu:/var/lib/docker/volumes/abf6b7a64fbd98c625b979ee27cdb222a4af1863b7706c387c53489bd5080417/_data# lscontainer.txtroot@VM-8-12-ubuntu:/var/lib/docker/volumes/abf6b7a64fbd98c625b979ee27cdb222a4af1863b7706c387c53489bd5080417/_data# # 发现宿主机中该路径下是有文件container.txt# 则说明我们的数据文件同步是没有问题的 总结： 这种方法我们是非常常用的。 假设构建容器时候没有挂载卷，就要手动使用-v 卷名:容器内路径命令进行挂载 数据卷容器--volumes-from ​ 数据卷挂载的基本原理示意图 **数据卷容器的概念示意图** 实现：多个MySQL实现数据共享？ 1234567# 匿名挂载运行容器mysql01docker run -d -p 3308:3306 -v /etc/mysql/conf.d -v /var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7# 将容器mysql02通过挂载到容器mysql02docker run -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql02 --volumes-from mysql01 mysql:5.7# 此时，就可以实现两个容器的数据同步了！ 结论 容器之间配置信息的传递，数据据卷容器的生命周期一直持续到没有容器使用为止。 但是一旦持久化到了本地，-v，这个时候，本地的数据是不会被删除的！ DockerFileDocker网络原理IDEA整合Docker集群Docker ComposeDocker SwarmCI&#x2F;CD Jenkins","comments":true,"tags":[{"name":"Docker","slug":"Docker","permalink":"http://example.com/tags/Docker/"}]},{"title":"Redis学习笔记","date":"2023-10-03T23:10:15.000Z","path":"2023/redis学习/","text":"​ 目录位置 Redis基础Redis VS MySQL Redis(NoSQL) MySQL(SQL) 数据结构 键值对（非结构化） 数据库表（结构化） 数据关联 非关系型数据库（无关联的） 关系型数据库（关联的） 查询方式 非SQL查询 SQL查询（有固定语法） 事务特性 BASE ACID 存储方式 内存 磁盘 扩展性 水平 垂直 使用场景 数据结构不固定；对ACID要求不高；对性能要求高 数据结构固定；数据安全性、一致性要求较高 NoSQL非结构化数据库类型： Redis：键值对类型 MongoDB：文档类型 HBase：列类型 Neo4j：Graph类型","comments":true,"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"Activiti7学习笔记","date":"2023-09-24T09:10:15.000Z","path":"2023/工作流学习笔记（activiti7）/","text":"一、什么是工作流 二、Activiti7概述 2.1 概述 2.2 使用 2.3 Activiti7开发环境 2.3.1 下载BPMN设计器 2.3.2 数据库支持 三、SpringBoot+MySQL搭建activiti7入门案例 3.1 创建mysql中activiti数据库的数据库 3.1.1 引入activiti依赖 3.1.2 test下添加测试类Activiti7Test01 3.1.3 配置数据库信息 3.1.4 数据库自动生成表 3.2 创建BPMN流程图 3.3 流程操作 3.3.1 流程部署 3.3.2 发起流程 3.3.3 查询流程 3.3.4 审批流程 3.3.5 涉及的表 四、任务分配 4.1 固定分配 4.2 表达式 4.2.1 值表达式 4.2.2 方法表达式 4.3 监听器配置 五、流程变量 5.1 运行时流程变量 5.1.1 全局流程变量 5.1.2 局部流程变量 5.2 历史流程变量 六、身份服务 6.1 审批人 6.2 候选人 6.3 候选人组 七、网关 7.1 排他网关 7.2 并行网关 7.3 包容网关 7.4 事件网关 八、 事件 8.1 定时器 8.1.1 启动事件 8.1.2 中间事件 8.1.3 边界事件 8.2 消息事件 8.2.1 启动事件 8.2.2 中间事件 8.2.3 边界事件 一、什么是工作流 多个参与者之间按照某种预定义的规则自动进行传递文档、信息或任务的过程，进而实现某种预期的业务目标 如：订单、客户订单处理、供应链管理、合同审核、请假申请、出差申请、加班申请、财务审批等等 二、Activiti7概述2.1 概述 使用建模语言BNPMN2.0 进行定义 画出业务流程图会转成xml文件，然后可以读取文件 2.2 使用 部署：activiti7是一个工作流引擎（jar包API），业务系统访问（操作）activiti的接口操作相关数据 定义：使用activit7建模工具定义业务流程，生成.bpmn文件即通过xml定义业务流程。 流程部署：存储.bpmn文件到数据库 启动实例：启动一个流程实例表示开始一次业务流程的运行 用户查询待办任务（task）：通过activiti查询 不需要sql语句 用户办理任务：用户查询待办任务，进行办理。如果流程还未结束需要往下走，如请假审批还需要领导审批，acitivi会自动完成。 流程结束：没有下一个任务点了就代表此次流程实例结束 2.3 Activiti7开发环境 jdk1.8+ mysql5.1.21+ Tomcat8.5+ IDEA（acticiti的流程定义工具插件可以安装再IDEA下，也可以再eclipse下） 支持spring5 BPMN开源设计器（https://gitee.com/MiyueSC/bpmn-process-designer） 因为该设计器是用Node.js做的，所以需要先把Node.js环境安装好。 然后把项目解压缩，并且在命令行进入该项目文件夹，执行初始化命令npm install。 然后执行下面的命令，才能让这个BPMN项目兼容高版本的Node.js12345# Windows系统执行这个命令set NODE_OPTIONS=--openssl-legacy-provider# Linux和MacOS系统执行这个命令export NODE_OPTIONS=--openssl-legacy-provider 4. 启动设计器：在命令行中执行`npm run demo`命令启动BPMN项目，然后打开浏览器访问本地的8100端口就能看到该设计器了。 2.3.1 下载BPMN设计器 git下载地址：https://github.com/miyuesc/bpmn-process-designer git在线地址：https://miyuesc.github.io/process-designer-v2/ 本地使用方法： 因为该BPMN设计器是用Node.js做的，所以需要先把Node.js环境安装好 把项目解压缩，并且在命令行进入该项目文件夹，执行初始化命令:cnpm install 在命令行中执行npm run demo命令启动BPMN项目 2.3.2 数据库支持 activit的运行需要数据库的支持，使用25张表，把流程定义节点内容读取到数据库表中，供后续使用 支持多种数据库及版本 h2 ：1.3.168+ mysql：5.1.21+ oracle：11.2.0.1.0+ postgres：8.1+ db2：DB2 10.1 using db2jdbc4+ mssql：2008 using sqljdbc4+ 三、SpringBoot+MySQL搭建activiti7入门案例3.1 创建mysql中activiti数据库的数据库如：创建activiticreate database activiti default character set utf8; 3.1.1 引入activiti依赖1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--activiti依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;7.0.0.GA&lt;/version&gt;&lt;/dependency&gt;&lt;!--mysql依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.33&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 3.1.2 test下添加测试类Activiti7Test013.1.3 配置数据库信息 注意配置databaseSchemaUpdate属性 方法一：配置文件形式（默认形式） 通过getDefaultProcessEngine()方法获取流程引擎对象 会加载resources 目录下的 activiti.cfg.xml activiti.cfg.xml内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/contex http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!--activiti单独运行的ProcessEngine配置对象(processEngineConfiguration),使用单独启动方式 默认情况下：bean的id=processEngineConfiguration --&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://127.0.0.1:3308/activiti?nullCatalogMeansCurrent=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=false&amp;amp;serverTimezone=GMT%2B8&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;jdbcPassword&quot; value=&quot;mysql1225&quot;&gt;&lt;/property&gt; &lt;!--数据库生成策略--&gt; &lt;!--activiti在生成表的时候,true 表示数据库中如果已经存在,那么直接使用,如果不存在,则直接创建--&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;!-- &amp;lt;!&amp;ndash;数据库连接池的构造注入&amp;ndash;&amp;gt;--&gt;&lt;!-- &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot;&gt;--&gt;&lt;!-- &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://127.0.0.1:3308/activiti?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;useSSL=false&amp;amp;serverTimezone=GMT%2B8&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &lt;property name=&quot;username&quot; value=&quot;root&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &lt;property name=&quot;password&quot; value=&quot;mysql1225&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &lt;property name=&quot;maxActive&quot; value=&quot;30&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &lt;property name=&quot;minIdle&quot; value=&quot;5&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &lt;/bean&gt;--&gt;&lt;!-- &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;--&gt;&lt;!-- &amp;lt;!&amp;ndash;代表数据源&amp;ndash;&amp;gt;--&gt;&lt;!-- &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;--&gt;&lt;!-- &amp;lt;!&amp;ndash;代表是否生成表结构&amp;ndash;&amp;gt;--&gt;&lt;!-- &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt;--&gt;&lt;!-- &lt;/bean&gt;--&gt;&lt;/beans&gt; 编写测试方法 12345678910/** * 获取processsEngine对象的第一种方式 * 默认的获取方式 */ @Test public void test01()&#123; //通过getDefaultProcessEngine()方法获取流程引擎对象 会加载resources 目录下的 activiti.cfg.xml ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); System.out.println(processEngine); &#125; 方法二: java代码形式 基于java代码获取processEngine对象 直接编写测试方法： 12345678910111213141516/** * 获取processsEngine对象的第二种方式 * 基于java代码获取processEngine对象 */ @Test public void test02()&#123; ProcessEngine processEngine = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration() .setJdbcDriver(&quot;com.mysql.cj.jdbc.Driver&quot;) // .setJdbcUrl(&quot;jdbc:mysql://localhost:3308/activiti?serverTimezone=UTC&amp;characterEncoding=utf8&amp;useUnicode=true&amp;useSSL=false&quot;) .setJdbcUrl(&quot;jdbc:mysql://localhost:3308/activiti?nullCatalogMeansCurrent=true&amp;serverTimezone=UTC&amp;characterEncoding=utf8&amp;useUnicode=true&amp;useSSL=false&quot;) .setJdbcUsername(&quot;root&quot;) .setJdbcPassword(&quot;mysql1225&quot;) .setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE)//activiti在生成表的时候,true 表示数据库中如果已经存在,那么直接使用,如果不存在,则直接创建 .buildProcessEngine(); System.out.println(&quot;processEngine = &quot;+processEngine); &#125; 3.1.4 数据库自动生成表运行test方法后，即第一次获取流程引擎时，数据库自动生成act开头的表则创建成功。第二部分是说明用途的两字节标识符 ACT_RE_*：RE代表repository。带有“静态”的意思。例如：流程定义和流程资源（图片、规则等） ACT_RU_*：RU代表runtime。保存“运行时信息”。例如：流程实例、用户任务、变量、作业等。Activiti只在流程实例运行中保存运行时数据，并在流程实例结束时删除记录，进而可以保证小而快 ACT_ID_*：ID代表identity。保存”身份信息“。例如：用户、组等 ACT_HI_*：HI代表history。保存“历史数据”。例如：已完成的流程实例、变量、任务等 ACT_GE_*：通用数据，用于不同场景下 3.2 创建BPMN流程图 设计器根据需求画出流程图，导出xml文件放在rescoures\\bpmn目录下，并重命名*.bpmn20.xml形式 xml文件右键View BPMN(Activiti) Diagram后，点击相关元素设置Assignee（任务处理人）等属性 3.3 流程操作 数据库比较关键的两张表：act_re_deployment:流程部署表act_re_procdef：流程定义表 注：一个流程部署可以包含多个流程定义 3.3.1 流程部署 需要通过repositoryService来完成 1234567891011121314151617/** * 流程部署操作 */@Testpublic void test03()&#123; //1. 获取processEngine对象 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); //2. 完成流程的部署操作，需要通过repositoryService来完成 RepositoryService repositoryService = processEngine.getRepositoryService(); //3. 完成部署 Deployment deploy = repositoryService.createDeployment() .addClasspathResource(&quot;bpmn/LeaveApply.bpmn20.xml&quot;) .name(&quot;第一个流程&quot;) .deploy(); System.out.println(deploy.getId()); System.out.println(deploy.getName());&#125; 流程定义信息查询：需要通过repositoryService来完成查询 123456789101112131415161718192021222324252627/** * 查询当前部署的流程有哪些 */@Testpublic void test04()&#123; //1. 获取processEngine对象 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); //2. 需要通过repositoryService来完成查询 RepositoryService repositoryService = processEngine.getRepositoryService(); //repositoryService.createProcessDefinitionQuery()//查询流程定义信息 List&lt;ProcessDefinition&gt; list = repositoryService.createProcessDefinitionQuery().list(); System.out.println(&quot;流程定义信息如下：&quot;); for (ProcessDefinition processDefinition:list ) &#123; System.out.println(processDefinition.getId()); System.out.println(processDefinition.getName()); &#125; //repositoryService.createDeploymentQuery()//查询流程部署信息==》相关流程定义的信息 System.out.println(&quot;流程部署信息如下：&quot;); List&lt;Deployment&gt; list1 = repositoryService.createDeploymentQuery().list(); for (Deployment deployment:list1 ) &#123; System.out.println(deployment.getId()); System.out.println(deployment.getName()); &#125;&#125; 即 我们可以通过Activiti相关的API获取相关的流程部署和流程定义的信息 3.3.2 发起流程 获取processEngine对象后，通过runtimeService获取流程定义的一个流程实例对象去发起流程 （流程定义：查act_re_procdef表） 编写test 123456789101112131415161718/** * 发起一个流程 * 通过runtimeService获取流程定义的实例 */@Testpublic void test05() &#123; //获取processEngine对象 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); //通过runtimeService获取流程定义的一个流程实例对象 流程定义：查act_re_procdef表 ProcessInstance processInstance = runtimeService.startProcessInstanceById(&quot;MyLeave:1:3&quot;); System.out.println(&quot;processInstance.getId() = &quot; + processInstance.getId()); System.out.println(&quot;processInstance.getDeploymentId() = &quot; + processInstance.getDeploymentId()); System.out.println(&quot;processInstance.getDescription() = &quot; + processInstance.getDescription()); &#125; 发起流程成功后，可在数据库act_ru_task表中看到如下信息，Assignee是指当前流程处理人 3.3.3 查询流程 查询待办执行中的任务处理是通过 TaskService来实现 Task 对象对应的其实就是 act_ru_task 这张表的记录 编写test方法代码 123456789101112131415161718192021/** *待办查询 */@Testpublic void test06()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); //查询待办 执行中的任务处理是通过 TaskService来实现 TaskService taskService = processEngine.getTaskService(); //Task 对象对应的其实就是 act_ru_task 这张表的记录 List&lt;Task&gt; employeeList = taskService.createTaskQuery().taskAssignee(&quot;zhangsan&quot;).list(); if(employeeList!=null &amp;&amp; employeeList.size()&gt;0)&#123; for (Task task : employeeList) &#123; System.out.println(&quot;task.getId() = &quot; + task.getId()); System.out.println(&quot;task.getName() = &quot; + task.getName()); System.out.println(&quot;task.getAssignee() = &quot; + task.getAssignee()); &#125; &#125;else&#123; System.out.println(&quot;当前没有待办任务&quot;); &#125;&#125; 3.3.4 审批流程 查询用户的所有待办，当前登录用户查询到相关审批流程信息后可以进行审批 通过TaskService来实现 编写test方法代码 1234567891011121314151617181920212223/** * 完成待办审批 */ @Test public void test07()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); TaskService taskService = processEngine.getTaskService(); //taskService.complete(&quot;2505&quot;);//模拟1 模拟对当前登录用户（employee）完成当前审批节点 使得 Assignee 从 employee --&gt; zhangsan //模拟2 对模拟流程稍作完善 //List&lt;Task&gt; list = taskService.createTaskQuery().taskAssignee(&quot;zhangsan&quot;).list();//模拟对当前登录用户（zhangsan）完成当前审批节点使得 Assignee 从 zhangsan --&gt; lisi List&lt;Task&gt; list = taskService.createTaskQuery().taskAssignee(&quot;lisi&quot;).list();//模拟对当前登录用户（lisi）完成当前审批节点 lisi是最后一个 Assignee 所以lisi完成后数据库中该task会被删除， if(list!= null &amp;&amp; list.size()&gt;0)&#123; for (Task task : list) &#123; //模拟对当前登录用户下的某个task做相关审批处理 完成该流程的本审批节点 //具体应该根据前端用户的操作数据获取值 进而进行下一步的相关审批 taskService.complete(task.getId()); &#125; &#125;else &#123; System.out.println(&quot;当前没有待办任务&quot;); &#125; &#125; 3.3.5 涉及的表上面一个审批流程下来所涉及的表结构 表名 说明 act_re_deployment 部署流程的记录表：一次部署行为会产生一张表 act_re_procdef 流程定义表：一张流程图对应的表 act_hi_procinst 流程实例表：发起一个流程，就会创建对应的一张表 act_ru_task 流程待办表：当前需要审批的记录表，节点审批后就会被删除 act_hi_actinst 历史记录表：流程审批节点的记录信息 四、任务分配4.1 固定分配如Part3案例代码中test方法所写，即把任务流程静态指派给固定的用户，正常业务中都要动态处理，基本不会用到该方式。 4.2 表达式4.2.1 值表达式 xml配置文件中对应属性设置$&#123;&#125;占位符 编写test方法，runtimeService.startProcessInstanceById方法有重载，在传入流程定义id的同时可以通过map传第二个参数值 4.2.2 方法表达式 xml配置文件中对应位置设置$&#123;&#125;，传入已注册的bean名字.方法实现调用 测试方法和前边Part3测试方法相同，无需额外传入参数，参数由容器自动注入 4.3 监听器配置 监听器分为三种：JavaDelegate TaskListener ExecutionListener 用户任务（UserTask）的监听器为TaskListener Java服务任务（Service Task）的监听器为JavaDelegate 其他的服务的监听器为ExecutionListener TaskListener中参数（DelegateTask）是有关于userTask的 JavaDelegate和ExecutionListener参数（DelegateExecution）是有关于流程的 编写监听器类(根据需求实现指定监听器接口，如TaskListener ) 123456789101112131415161718//此类定义的是用户进程监听器public class MyFirstListener implements TaskListener &#123; /** * 监听器触发回调方法 * @param delegateTask */ @Override public void notify(DelegateTask delegateTask) &#123; System.out.println(&quot;-----&gt;自定义的监听器执行了&quot;); if(EVENTNAME_CREATE.equals(delegateTask.getEventName()))&#123; //表示是Task的创建事件被触发了 //1.指定当前Task节点的处理人 delegateTask.setAssignee(&quot;wangwu&quot;); &#125; &#125;&#125; 编写xml配置文件，指定流程节点添加扩展属性（以：taskListener为例） 1234567&lt;bpmn:userTask id=&quot;employeeLeaveApply&quot; name=&quot;员工提交请假申请&quot;&gt; &lt;bpmn:extensionElements&gt; &lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.lm.activiti7study.listener.MyFirstListener&quot; /&gt; &lt;/bpmn:extensionElements&gt; &lt;bpmn:incoming&gt;Flow_07i37nu&lt;/bpmn:incoming&gt; &lt;bpmn:outgoing&gt;Flow_0xbl72x&lt;/bpmn:outgoing&gt; &lt;/bpmn:userTask&gt; 注：event属性要先写，否则可能会的读不到值而导致监听失败 123&lt;bpmn:extensionElements&gt; &lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.lm.activiti7study.listener.MyFirstListener&quot; /&gt;&lt;/bpmn:extensionElements&gt; 编写test类。无特殊参数，和前边Part3测试方法相同 五、流程变量监听器中更改流程变量不能通过map.set方法。而要通过如：delegateTask.setVariable(key,obj+&quot;-lm123&quot;);//有效操作√方式进行设置 5.1 运行时流程变量5.1.1 全局流程变量 流程变量的默认作用域是流程实例，随着流程实例的完成而消失。 当一个流程变量作用域是流程实例时，成为Global变量。 变量名不许重复 设置相同变量名的值，会进行覆盖 使用过程中会记录在act_ru_variable中 编写监听器代码 123456789101112131415161718192021222324252627282930/** * 更改流程变量 *///此类定义的是用户进程监听器public class MySecondListener implements TaskListener &#123; /** * 监听器触发回调方法 * @param delegateTask */ @Override public void notify(DelegateTask delegateTask) &#123; System.out.println(&quot;-----&gt;MySecondListener监听器执行了&quot;); if(EVENTNAME_CREATE.equals(delegateTask.getEventName()))&#123; //表示是Task的创建事件被触发了 //获取流程变量 Map&lt;String, Object&gt; variables = delegateTask.getVariables(); Set&lt;String&gt; keySet = variables.keySet(); for (String key : keySet) &#123; Object obj = variables.get(key); System.out.println(key+&quot;=&quot;+obj); //获取之后修改流程变量 // variables.put(key,&quot;lm123&quot;);//此方法是无效的 delegateTask.setVariable(key,obj+&quot;-lm123&quot;);//有效操作√ &#125; &#125; &#125;&#125; 设计流程(编写xml文件) ，给指定的流程节点进行值表达式配置（$&#123;&#125;）。如下以某流程节点为例 1234567&lt;bpmn:userTask id=&quot;employeeLeaveApply&quot; name=&quot;员工提交请假申请&quot; activiti:assignee=&quot;$&#123;assignee1&#125;&quot;&gt; &lt;bpmn:extensionElements&gt; &lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.lm.activiti7study.listener.MyThirdListener&quot;/&gt; &lt;/bpmn:extensionElements&gt; &lt;bpmn:incoming&gt;Flow_07i37nu&lt;/bpmn:incoming&gt; &lt;bpmn:outgoing&gt;Flow_0xbl72x&lt;/bpmn:outgoing&gt; &lt;/bpmn:userTask&gt; 编写test方法代码进行部署等测试（启动流程实例时需要通过map传入参数） 测试方法通过值表达式进行传值一定是全局变量，不能传局部变量 1234567891011121314151617181920212223/** * 设置全局流程变量 */ @Test public void test2() &#123; //获取processEngine对象 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;assignee1&quot;,&quot;assignee1张&quot;); map.put(&quot;assignee2&quot;,&quot;assignee2李&quot;); map.put(&quot;assignee3&quot;,&quot;assignee3王&quot;); map.put(&quot;as1&quot;,&quot;赵&quot;); map.put(&quot;as2&quot;,&quot;周&quot;); //传参 且此时会触发监听器中的修改办法 //可以在act_ru_variable表中看到 ProcessInstance processInstance = runtimeService.startProcessInstanceById(&quot;LeaveApply:3:7503&quot;,map);//模拟测试发起一个流程 System.out.println(&quot;processInstance.getId() = &quot; + processInstance.getId()); System.out.println(&quot;processInstance.getDeploymentId() = &quot; + processInstance.getDeploymentId()); System.out.println(&quot;processInstance.getDescription() = &quot; + processInstance.getDescription()); &#125; 获取全局变量：runtimeService.getVariableInstances(&quot;某实例的Execution_ID&quot;) 12345678910111213141516171819/** * * 查询当前流程变量信息 */ @Test public void test4()&#123; //获取processEngine对象 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); //查 某个流程实例 的变量信息 而不是某个流程定义下所有实例的全部流程变量 //传参 执行时ID ==》 查act_ru_task中的 Execution_ID Map&lt;String, VariableInstance&gt; variableInstances = runtimeService.getVariableInstances(&quot;10007&quot;); System.out.println(&quot;-----&gt;获取后输出当前流程实例变量&quot;); Set&lt;String&gt; keySet = variableInstances.keySet(); for (String key : keySet) &#123; System.out.println(key+&quot;=&quot;+variableInstances.get(key)); &#125; &#125; 5.1.2 局部流程变量 编写监听器代码 123456789101112131415161718192021222324252627282930/** * 测试局部和历史流程变量 * 更改流程变量 *///此类定义的是用户进程监听器public class MyThirdListener implements TaskListener &#123; /** * 监听器触发回调方法 * @param delegateTask */ @Override public void notify(DelegateTask delegateTask) &#123; System.out.println(&quot;-----&gt;MyThirdListener监听器执行了&quot;); if(EVENTNAME_CREATE.equals(delegateTask.getEventName()))&#123; //表示是Task的创建事件被触发了 //获取流程变量 Map&lt;String, Object&gt; variables = delegateTask.getVariables(); Set&lt;String&gt; keySet = variables.keySet(); for (String key : keySet) &#123; Object obj = variables.get(key); System.out.println(key+&quot;=&quot;+obj); //获取之后修改流程变量 // delegateTask.setVariable(key,obj+&quot;[]&quot;);//有效操作√ &#125; &#125; &#125;&#125; 设计流程(编写xml文件)：和全局变量配置文件相同，无变化。（即使用值表达式配置） 编写test方法代码 设置必要的全局变量 1234567891011121314151617181920212223/** * runtimeService 设置全局流程变量 */ @Test public void test2() &#123; //获取processEngine对象 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); //此处为设置全局变量 Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;assignee1&quot;,&quot;assignee1张&quot;); map.put(&quot;assignee2&quot;,&quot;assignee2李&quot;); map.put(&quot;assignee3&quot;,&quot;assignee3王&quot;); //通过runtimeService获取流程定义的一个流程实例对象 流程定义：查act_re_procdef表 //使用值表达式需要传入全局变量 ProcessInstance processInstance = runtimeService.startProcessInstanceById(&quot;LeaveApply:4:20003&quot;,map);//模拟测试发起一个流程 System.out.println(&quot;processInstance.getId() = &quot; + processInstance.getId()); System.out.println(&quot;processInstance.getDeploymentId() = &quot; + processInstance.getDeploymentId()); System.out.println(&quot;processInstance.getDescription() = &quot; + processInstance.getDescription()); &#125; 设置局部变量的两种方式如下。局部变量，通过某网关分支后，局部变量会变得不同 12345678910111213141516171819202122/** * runtimeService 设置局部变量 */@Testpublic void test3()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); //传参 运行时ID及局部变量键值对形式 runtimeService.setVariableLocal(&quot;22505&quot;,&quot;leaveId&quot;,&quot;123&quot;); runtimeService.setVariableLocal(&quot;22505&quot;,&quot;name&quot;,&quot;666&quot;);&#125; /** * TaskService 设置局部变量 */@Testpublic void test5()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); TaskService taskService = processEngine.getTaskService(); taskService.setVariableLocal(&quot;22508&quot;,&quot;taskServiceTest&quot;,&quot;6666666&quot;);&#125; ​ 区别：传入参数不同:runtimeService需要传入运行时ID（查act_ru_task表的Execution_ID）;TaskService需要传入任务ID(查act_ru_task表的ID） 读取局部变量（两种方法设置要用两种对应的方法读取，互相读取不到对方设置的局部变量。） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 /** * 读取局部变量 */ @Test public void test4()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); TaskService taskService = processEngine.getTaskService(); //传参 运行时ID 查act_ru_task的Execution_ID Map&lt;String, Object&gt; variablesLocal = runtimeService.getVariablesLocal(&quot;22505&quot;); System.out.println(&quot;-------&gt;runtimeService获取当前流程实例的局部变量&quot;); Set&lt;String&gt; keySet = variablesLocal.keySet(); for (String key : keySet) &#123; System.out.println(key+&quot;=&quot;+variablesLocal.get(key)); &#125; //传参 任务ID 查act_ru_task的ID Map&lt;String, Object&gt; variablesLocal1 = taskService.getVariablesLocal(&quot;22508&quot;); System.out.println(&quot;-------&gt;taskService获取当前流程实例的局部变量&quot;); Set&lt;String&gt; keySet1 = variablesLocal1.keySet(); for (String key : keySet1) &#123; System.out.println(key+&quot;=&quot;+variablesLocal1.get(key)); &#125; &#125;## 5.2 历史流程变量1. 流程文件不需要改变。使用值表达式分配方式2. 编写test方法查询 ```java /** * 读取历史变量 */ @Test public void test7()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); HistoryService historyService = processEngine.getHistoryService(); //historyService.createHistoricVariableInstanceQuery() // 所有工作流的历史数据都要通过historyService实现查询 //存在act_hi_varinst表中 不会被删除 会”永久“保存 List&lt;HistoricVariableInstance&gt; list = historyService.createHistoricVariableInstanceQuery().list(); System.out.println(&quot;-------&gt;historyService获取当前流程实例的历史流程变量&quot;); for (HistoricVariableInstance historicVariableInstance : list) &#123; System.out.println(&quot;historicVariableInstance = &quot; + historicVariableInstance); &#125; &#125; 六、身份服务6.1 审批人6.2 候选人6.3 候选人组七、网关7.1 排他网关 用于流程中进行条件判断，根据不同的条件选择不同的分支路径。只有满足条件的分支会被执行，其他分支会被忽略 会选择第一个条件判断为true的分支进行 如果会有多个分支满足条件，也只会选择第一个满足的，且不会再接着判断其他分支条件 如果分支条件为空，则认为该顺序流为true 流程设计代码（xml文件） 测试代码中需要通过传参形式传入条件判断所需的值 7.2 并行网关 用于将流程分成多个的分支，这些分支可以同时执行 当所有分支都执行完毕后，流程会继续向下执行 有并行网关就需要有join网关点 数据库会保存一条主流程实例信息和一条或多条子流程信息 并行网关后会有一个子流程实例生成多个子流程实例 7.3 包容网关用于根据多个条件的组合情况选择分支路径，可以选择满足任意一个条件的分支执行，或者选择满足所有条件的分支执行。 7.4 事件网关用于根据事件的触发选择分支，当指定给的事件触发时，流程会选择对应的分支执行。 八、 事件捕获：当流程执行达到这个事件时，会等待直到触发器动作。 抛出：当流程执行达到这个事件时，会触发一个触发器。 8.1 定时器 可以在数据库表act_ru_timer_job中查询到定时器的实时信息（流程结束时定时器消亡，该表中的信息会随着定时器的消亡而删除） timeDate：指定一个具体的日期和时间。如：2024-01-01T00:00:00 timeCycle：指定一个重复周期。如：R3/PT1H表示每间隔1小时触发一次共触发3次 timeDate：指定一个持续时间。如：PT2H30M表示持续2小时30分钟 需要开启异步执行时才会使用定时器，而异步执行默认为false。需要手动在配置文件中修改。即xml文件默认配置或代码形式部署配置时候asyncExecutorActivate属性为true。保证异步执行任务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 &lt;!--开启异步执行 测试定时器时部署操作和执行操作需要一起 否则部署完成之后定时器会消失--&gt; &lt;property name=&quot;asyncExecutorActivate&quot; value=&quot;true&quot;&gt;&lt;/property&gt;### 8.1.1 启动事件- 使用时需要注意 1. 子流程不能有定时器启动事件 2. 定时器启动事件，在流程部署的同时就开始计时。不需要调用`startProcessInstanceByXXX`去启动一个实例，而是会在指定时间自动启动一个实例。调用`startProcessInstanceByXXX`时会在定时启动之外额外启动一个流程 3. 当部署带有定时器的启动事件的流程的更新版本时，上一版本的定时器作业会被移除。（这是因为通常并不希望旧版本的流程仍然自动启动新的流程实例）### 8.1.2 中间事件1. 当我们完成前边的审批处理后，会启用定时器中间事件，完成后会接着执行后续的流程任务事件。2. 定时器中间事件需要手动启动一个实例后才会触发3. 如：“开始---&gt;入库审批---&gt;定时器中间事件（PT1M）---&gt;出库审批---&gt;结束”。则在`启动实例`后会进入`入库审批`，`入库审批`完成后，会进入`定时器`，`定时器`持续一分钟后，进入下一步`出库审批`任务，`出库审批`完成后会结束该工作流实例4. 类似于`进程的sleep`操作### 8.1.3 边界事件1. 中断型边界事件 1. 定时器的`cancelActivity`属性设置为false 2. 定时器触发边界事件后会转入子流程事件，同时主流程会直接结束不再往后执行2. 非中断型边界事件 1. 定时器的`cancelActivity`属性设置为true 2. 定时器触发边界事件后会转入子流程事件，勇士主流程不会结束，会等待（如：长时间未审批会触发发送通知信息的任务子流程，同时等待审批） 3. 只有前边的审批完成后，才会转接下一个流程任务3. 主要是使用`attachedToRef`属性为定时器设置依赖的事件（传入的值为：`依赖事件的ID`）（**必须要配置该属性，否则会编译报错**）## 8.2 消息事件### 8.2.1 启动事件注意事项：1. 需要先**定义消息**事件，且给启动事件**绑定消息**（id）2. 只有顶层流程（toplevel process）才支持消息启动事件 ，嵌入流程（子流程）不支持消息事件3. ` runtimeService.startProcessInstanceByMessage(&quot;mg01&quot;);`传入的应该是act_ru_event_subscr表中的**event_name** 即流程图中定义的消息名称 而**不是消息ID**4. 消息的name和id不要用中文5. **消息的name和id需要一致 否则会报错说找不到** ( **具体原因？？？**)6. 注意事项： 1）流程的**消息名称必须是唯一**的，一个流程定义不得包含多个同名的启动消息。否则部署流程的时候就会抛异常 2）**消息启动事件，在所有部署的流程里面必须要唯一**，否则也会抛异常 3）直接启动消息定义事件，会当作一个普通启动事件执行 4）**新版本发布，会取消上一版本的消息订阅** 5）启动流程实例的三种方法 1 ProcessInstance startProcessInstanceByMessage(String messageName); 2 ProcessInstance startProcessInstanceByMessage(String messageName, Map&lt;String, Object&gt; processVariables); 3 ProcessInstance startProcessInstanceByMessage(String messageName, String businessKey, Map&lt;String, Object&lt; 4 processVariables); 12345678910111213141516171819202122232425262728### 8.2.2 中间事件1. 设计流程：`“开始---&gt;用户任务1---&gt;消息中间事件---&gt;用户任务2---&gt;结束”`2. 部署流程3. `发起流程`并完成`用户任务1`后会进入`消息中间事件`，会**等待传入消息**从而触发消息事件4. 触发消息事件测试方法 ```java /** *触发消息事件 */ @Test public void test3()&#123; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); RuntimeService runtimeService = processEngine.getRuntimeService(); Execution execution = runtimeService.createExecutionQuery() .processInstanceId(&quot;25001&quot;) //查询当前的 执行实例的 编号（Id） 即act_ru_execution表的proc_inst_id .onlyChildExecutions()//只查询子流程 .singleResult(); //传入消息 触发消息事件 runtimeService.messageEventReceived(&quot;message&quot;, execution.getId()); &#125; 8.2.3 边界事件 部署步骤完全类似于定时器边界事件 不同的是：需要在流程定义时进行定义和绑定消息 同样分为非中断消息边界事件和中断消息边界事件（注意区别）","comments":true,"tags":[{"name":"Activiti7","slug":"Activiti7","permalink":"http://example.com/tags/Activiti7/"}]},{"title":"Java基础及集合框架","date":"2023-08-06T02:13:10.000Z","path":"2023/java基础及集合框架/","text":"集合概述 ​ 图1-1 Java集合框架 Java集合，也叫做容器，主要由两大类接口派生而来 Collection: 主要存放单一元素。又派生出：List、Set、Queue Map：主要存放键值对 List Set Queue Map的区别？ List(解决顺序) ：存储的元素是有序的、可重复的 Set(注重独一无二) ：存储的数据不可重复 Queue (实现排队)：按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的 Map(键值对)：key-value。类似于y&#x3D;f(x)；y代表value，是无序的、可重复的；x代表key，是无序的、不可重复的。每个键最多映射到一个值 Java三大特性：1、封装：一种将抽象性函式接口的实现细节部分包装、隐藏起来的方法。2、继承：子类继承父类的特征和行为，使得子类对象（实例）具有父类的实例域和方法，或子类从父类继承方法，使得子类具有父类相同的行为。3、多态：同一个行为具有多个不同表现形式或形态的能力。 12多态中：当父类(接口)引用指向子类(实现类)的对象时，父类的引用就能直接调用子类中的方法==&gt; 可以减少代码开发过程中的修改量 ArrayList1. 数据结构 动态数组 寻址公式： Q1：下标为什么从0开始不从1开始？寻址时要多计算一次 i-1 [baseAddress+i*dataTypeSize] 时间复杂度 查询： 随机查询 : O(1) 未知查询：未排序:O(n); 排序后: –&gt; 可二分查找–&gt; O(logn) 插入、删除 内存连续 所以为保证数据的连续性会挪动数据 使得插入和删除效率较低 最好 O(1) 最差O(n) 平均 O(n) 2. 源码 添加数据的逻辑扩容至1.5倍 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public boolean add(E e) &#123; //判断是否可以容纳e，若能，则直接添加在末尾；若不能，则进行扩容，然后再把e添加在末尾 ensureCapacityInternal(size + 1); // Increments modCount!! //将e添加到数组末尾 elementData[size++] = e; return true; &#125;// 每次在add()一个元素时，arraylist都需要对这个list的容量进行一个判断。通过ensureCapacityInternal()方法确保当前ArrayList维护的数组具有存储新元素的能力，经过处理之后将元素存储在数组elementData的尾部private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; //如果传入的是个！！空数组！！则最小容量取默认容量与minCapacity之间的最大值 //无参构造时 this.elementData=DEFAULTCAPACITY_EMPTY_ELEMENTDATA，所以若是无参构造则第一次添加数据时该条件肯定成立 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity);//JDK1.8中 DEFAULT_CAPACITY=10 所以第一次添加数据时返回10 &#125; return minCapacity;//除了第一次添加数据 都直接return minCapacity &#125; private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; //记录集合被修改的次数 // 若ArrayList已有的存储能力满足最低存储要求，则返回add直接添加元素； //如果最低要求的存储能力&gt; ArrayList已有的存储能力，这就表示ArrayList的存储能力不足，因此需要调用 grow();方法进行扩容 //第一次添加数据: 10 - 0 &gt; 0 则进行grow() 第2-10次添加数据: 2/3../10 - 10 &lt; 0 不进行grow() // 第11次 : 11 - 10 &gt; 0 进行grow() if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125;private void grow(int minCapacity) &#123; // 获取elementData数组的内存空间长度 int oldCapacity = elementData.length; // 扩容至原来的1.5倍 (右移1位--&gt;缩小2倍) int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 第11次添加数据: new = 10+5 =15 //校验容量是否够 if (newCapacity - minCapacity &lt; 0) // 第一次添加数据:0 - 10 &lt; 0;第11次添加数据: 15 - 11 &gt; 0 newCapacity = minCapacity; //若预设值大于默认的最大值，检查是否溢出 所以，若溢出hugeCapacity()中会抛出异常而无法完成扩容 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 调用Arrays.copyOf方法将elementData数组指向新的内存空间 //并将elementData的数据复制到新的内存空间 elementData = Arrays.copyOf(elementData, newCapacity);//第一次添加数据:new=10;第11次:new=15 &#125; 构造方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数（用户可以在创建ArrayList对象时自己指定集合的初始大小） */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //如果传入的参数大于0，创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //如果传入的参数等于0，创建空数组 this.elementData = EMPTY_ELEMENTDATA;//一对&#x27;&#123;&#125;’; EMPTY_ELEMENTDATA = &#123;&#125;; &#125; else &#123; //其他情况，抛出异常 throw new IllegalArgumentException(&quot;Illegal Capacity: &quot; + initialCapacity); &#125; &#125; /** * 默认无参构造函数 * DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 * 当添加第一个元素的时候数组容量(经过第一次扩容)才变成10 */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; //将指定集合转换为数组 elementData = c.toArray(); //如果elementData数组的长度不为0 if ((size = elementData.length) != 0) &#123; // 如果elementData不是Object类型数据（c.toArray可能返回的不是Object类型的数组所以加上下面的语句用于判断） if (elementData.getClass() != Object[].class) //将原来不是Object类型的elementData数组的内容，赋值给新的Object类型的elementData数组 elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 其他情况，用空数组代替 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() &#123; modCount++; //记录集合被修改的次数 if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125;&#125; 3. Q&amp;A 底层原理是什么？ 底层是动态数组实现 初始容量为0 第一次添加数据后为10 进行扩容时是扩容至原来容量的1.5倍，且每次扩容都需要拷贝数组 扩容机制： 先判断容量是否够存新数据， 即已使用的长度size+1是否存在 计算数组容量，如果不够则调用grow()方法扩容至1.5倍 确保新增数据有位置存储后，将新数据插入尾部 返回添加成功布尔值 ArrayList list = new ArrayList (10) 中list扩容了几次？ 0次 只是创建了一个指定大小的数组并没有扩容 123456public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //如果传入的参数大于0，创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if ... &#125; 数组和list之间的转换 数组 –&gt; List: 使用JDK中java.util.Arrays工具类的asList()方法。但底层只涉及对象的引用不涉及对象的创建，两者指向同一个地址，所以再修改数组内容，list会受影响 List –&gt; 数组：使用List的toArray()方法。无参toArray()方法返回数组Object数组，传入初始化长度的数组对象，返回该对象数组。而底层是通过copyOf()进行数据拷贝的，所以再修改list内容，数组不受影响 ArrayList和LinkList的区别是什么？※ 链表： 结点组成； 非连续、非顺序的物理存储结构 时间复杂度 单向链表：查找&#x2F;插入&#x2F;删除：头O(1)，其他O(n) 双向链表：因为有first和last指针，所以查找头尾的时间复杂度是O(1)，平均查找时间O(n)，给定节点找前驱O(1)；插入删除头尾O(1)，其他节点增删O(n)，给定节点增删O(1) 综上从以下几个方面Answer 底层数据结构？ 操作数据效率？ 内存空间占用？数组、内存连续、节省；双向链表、内存不连续、包括两指针故占用更多 线程安全 ？ 都不安全。 怎么改善？ 在方法内使用。局部变量是线程安全的 使用线程安全的ArrayList和LinkedList 都使用了synchronized包装而成 二叉搜索树（BST)、红黑树、散列表（HashTable）1. 二叉搜索树（BST) 任意一个结点大于左节点（如果有），小于右节点（如果有）；没有键值相等的节点 通常情况下是时间复杂度O(logn) 当为单枝树时性能最差，回退到O(n) 2. 红黑树（数据库索引） 节点只有红、黑 根是黑 叶子节点时黑色的空节点 红的子节点都是黑 任一节点到叶子节点的所有路径都包含相同数目的黑节点 以上5点性质在添加或者删除节点时，若不符合则会发生旋转 –&gt; 保证平衡 查找、 添加、删除：红黑树本质也是BST，所以也是O(logn) 3. 散列表（HashTable） key-value 支持随机访问 最主要的是 解决散列冲突（又叫哈希冲突、哈希碰撞，即多个key映射到一个value）问题 拉链法：每个下标位置称之为桶（或 槽），每个桶（或 槽）对应一个链表，所有散列值相同的都会放到同一个槽位对应的链表中 插入：O(1) key相同就覆盖，key不同就头插法插入元素 查找、删除：平均O(1)，但当某一个槽数据过多时候会退化为链表O(n) &#x3D;&#x3D;&gt; 改造为其他高效数据结构，如红黑树（同时也可以防止DDos攻击）O(logn) 再散列法 建立公共溢出区 HashMap1. HashMap的实现原理？ 数据结构，底层是数组+链表&#x2F;红黑树 jdk1.8之前是单纯的拉链法(数组+链表)；jdk1.8之后（数组+链表&#x2F;红黑树），当链表长度大于阙值（默认为8）且数据总量（数组长度）大于等于64时转换红黑树； 小于64时会先进行**扩容resize()**，而不是转换红黑树，以减少检索时间。 扩容时。红黑树拆分的树的节点**&lt;&#x3D;6个**时，会退化为链表 添加数据时，散列函数计算key确定下标。根据key计算出hashcode，根据hashcode计算出hash值【提问：为什么还要额外多算一步hash值而不直接使用hashcode？先思考一下，下边写寻址的part有回答~】，最后通过hash&amp;(length-1)（取模运算）计算出存储位置 2. 源码 扩容 : resize() 超过最大值就不再扩容，未超过就容量会扩容到原来数组的2倍， 即左移一位 创建时指定了初始容量或**负载因子(默认0.75)**，就会重新进行阙值初始化；或扩容前的容量小于16，就会重新计算resize上限 只有一个节点，直接计算新元素的位置 红黑树拆成2棵树，若子树节点个数小于UNIREEIFTY_THRESHOLD(默认是6），则转换为链表，大于UNIREEIFTY_THRESHOLD则保持子树的树结构 [注：UNIREEIFTY_THRESHOLD的值为 当桶上的节点数小于等于这个数时转换为链表] 综上扩容机制如下 在添加元素或初始化的时候都需要调用resize进行扩容，第一次添加数据初始化数组长度为16，以后每次扩容都是达到了扩容阙值（数组长度*0.75） 每次扩容的时候，都是扩容到之前的2倍 左移一位 扩容之后会创建新的数组，需要把老数组中的数据挪到新数组中 没有hash冲突的节点，直接使用e.hash &amp; (newCap - 1)【相当于取模新数组长度newCap的操作】计算新数组的索引位置 【拓：因为 位与 运算比取模运算的效率更高，所以采用按位运算 前提是数组长度必须是2的n次幂】 ​ 图3-1 &amp;和%运算的对应关系 如果是红黑树，走红黑树的逻辑 如果是链表，则需要遍历链表，可能需要拆分链表。通过(e.hash &amp; oldCap)是否为0分为两类： 等于0时，则将该头节点放到新数组时的索引位置等于其在旧数组时的索引位置，记为低位区链表lo开头-low; 不等于0时,则将该头节点放到新数组时的索引位置等于其在旧数组时的*索引位置再加上旧数组长度***，记为高位区链表hi开头high. (e.hash &amp; oldCap)=0使用原理的推导过程 oldCap: 旧数组的长度 因为oldCap是2的n次幂的整数,其二进制表达为1个1后面跟n个0：1000…0，若想要e.hash&amp;oldCap的结果为0，则e.hash的二进制形式中与对应oldCap的二进制的1的位置一定为0，其他位置的可以随意，这样即可保证结果为0；假设：oldCap&#x3D; 2 ^ 3 &#x3D;8 &#x3D; 1000则e.hash可以是 0101e.hash&amp;oldCap 0000&#x3D;0 也就是说：只有hash&lt;oldCap时才会为0,即直接计算新索引后放到新索引位置，反之要放到计算的新索引+旧数组长度的索引位置下 final Node&lt;K,V&gt;[] resize() &#123; //旧数组 Node&lt;K,V&gt;[] oldTab = table; //旧数组的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; //旧数组的扩容阈值，注意看，这里取的是当前对象的 threshold 值，下边的第2种情况会用到。 int oldThr = threshold; //初始化新数组的容量和阈值，分三种情况讨论。 int newCap, newThr = 0; //1.当旧数组的容量大于0时，说明在这之前肯定调用过 resize扩容过一次，才会导致旧容量不为0。 //为什么这样说呢，之前我在 tableSizeFor 卖了个关子，需要注意的是，它返回的值是赋给了 threshold 而不是 capacity。 //我们在这之前，压根就没有在任何地方看到过，它给 capacity 赋初始值。 if (oldCap &gt; 0) &#123; //容量达到了最大值 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //新数组的容量和阈值都扩大原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //2.到这里，说明 oldCap &lt;= 0，并且 oldThr(threshold) &gt; 0，这就是 map 初始化的时候，第一次调用 resize的情况 //而 oldThr的值等于 threshold，此时的 threshold 是通过 tableSizeFor 方法得到的一个2的n次幂的值(我们以16为例)。 //因此，需要把 oldThr 的值，也就是 threshold ，赋值给新数组的容量 newCap，以保证数组的容量是2的n次幂。 //所以我们可以得出结论，当map第一次 put 元素的时候，就会走到这个分支，把数组的容量设置为正确的值（2的n次幂) //但是，此时 threshold 的值也是2的n次幂，这不对啊，它应该是数组的容量乘以加载因子才对。别着急，这个会在③处理。 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //3.到这里，说明 oldCap 和 oldThr 都是小于等于0的。也说明我们的map是通过默认无参构造来创建的， //于是，数组的容量和阈值都取默认值就可以了，即 16 和 12。 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //③ 这里就是处理第2种情况，因为只有这种情况 newThr 才为0， //因此计算 newThr（用 newCap即16 乘以加载因子 0.75，得到 12） ，并把它赋值给 threshold if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //赋予 threshold 正确的值，表示数组下次需要扩容的阈值（此时就把原来的 16 修正为了 12）。 threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) //我们可以发现，在构造函数时，并没有创建数组，在第一次调用put方法，导致resize的时候，才会把数组创建出来。这是为了延迟加载，提高效率。 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果原来的数组不为空，那么我们就需要把原来数组中的元素重新分配到新的数组中 //如果是第2种情况，由于是第一次调用resize，此时数组肯定是空的，因此也就不需要重新分配元素。 if (oldTab != null) &#123; //遍历旧数组 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //取到当前下标的第一个元素，如果存在，则分三种情况重新分配位置 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //1.如果当前元素的下一个元素为空，则说明此处只有一个元素 //则直接用它的hash()值和新数组的容量取模就可以了，得到新的下标位置。 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //2.如果是红黑树结构，则拆分红黑树，必要时有可能退化为链表 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //3.到这里说明，这是一个长度大于 1 的普通链表，则需要计算并 //判断当前位置的链表是否需要移动到新的位置 else &#123; // preserve order // loHead 和 loTail 分别代表链表旧位置的头尾节点 Node&lt;K,V&gt; loHead = null, loTail = null; // hiHead 和 hiTail 分别代表链表移动到新位置的头尾节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //如果当前元素的hash值和oldCap做与运算为0，则原位置不变 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //否则，需要移动到新的位置 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //原位置不变的一条链表，数组下标不变 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //移动到新位置的一条链表，数组下标为原下标加上旧数组的容量 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561572. put：put流程（参考） ![HashMap-put-JDK1.8](https://gitee.com/RoleHalo/blog-image/raw/master/image/Java-CollectionFramework/HashMapput-JDK1.8.png) ​ **图3-3 HashMap-put-JDK1.8** ![HashMap的put逻辑示意图](https://gitee.com/RoleHalo/blog-image/raw/master/image/Java-CollectionFramework/HashMap的put逻辑示意图.png)​ **图3-4 HashMap的put逻辑示意图**![HashMap扩容流程](https://gitee.com/RoleHalo/blog-image/raw/master/image/Java-CollectionFramework/HashMap扩容流程.png)​ **图3-5 HashMap的扩容流程示意图**综上 **put**简要流程如下: 1. 首先计算hash值，找到该元素在数组中的存储下标 1. 如果数组时空的，则调用resize进行初始化扩容 1. 如果没有哈希冲突直接存储对应位置上 4. 如果有冲突 1. 如果时红黑树，走红黑树的添加逻辑 2. 如果时链表，小于8直接放入，若key已存在，就覆盖value；大于8小于64就进行扩容；大于8且大于64，则将这个节点结构转为红黑树；### 3. hashMap的寻址算法 1. 寻址算法 1. 计算对象的`hashCode()` 2. 调用hash()进行二次哈希，`hashcode`值右移18位再异或运算，让哈希分布更加均匀 3. 最后`(capacity-1)&amp;hash`得到索引2. 回答最早提到的问题：为什么还要通过`hashcode`计算`hash`而不直接使用`hashcode`？ - 作用：为了使得hash值分布更加均匀，减少hash冲突3. HashMap数组长度到底为什么必须是2的n次幂？ 1. 计算索引的时候效率更好：2的n次幂可以使用**位与**运算代替取模运算 2. 扩容时重新计算索引效率更高：即使用`(e.hash &amp; oldCap)=0`将原来的各个数据分为两类# 多线程/并发编程### 1. 线程介绍1. **进程**是系统***分配资源***的单位，一个进程可以包含若干线程；而**线程是CPU*调度和执行*的单位**1. **线程是独立的执行路径**1. 程序运行时，即使没有自己创建线程，后台也会有多个线程，如主线程，GC线程1. main()称之为主线程，是**系统的入口**，用于执行整个程序1. 在一个进程中，多个线程的运行由调度器安排，**调度器与操作系统密切相关，先后顺序无法人为干预**1. 对**同一份资源**操作时，会存在资源抢夺问题，需要加入**并发控制**1. 线程会带来**额外的开销**，如CPU调度时间、并发控制时间等1. 每个线程在自己的工作内交互，**内存控制不当会导致数据不一致**### 2. 线程创建※1. 线程创建的三种方式 - **继承Thread类（就是实现Runnable接口）※** 1. 继承Thread类 2. 重写run()方法：方法内则为线程的执行体 3. 调用start()方法启动线程 4. 注意：线程开启不一定立即执行，由CPU调度执行；Java是单继承 - **实现Runnable接口 ※※** 1. 实现Runnable接口 2. 重写run()方法 3. 创建线程Thread对象（将Runnable接口对象作为参数传入Thread对象中），调用start()方法启动线程 ==&gt;**即Thread类静态代理了Runnable** 4. 优点：避免单继承局限性，灵活方便，方便同一个对象被多个线程同时使用 - 实现Callable接口（了解即可） 1. 实现callable接口，***需要返回值类型*** 2. 重写call方法，***需要抛出异常*** 3. 创建目标对象 4. 创建执行服务：`ExecutorService executorService = Executors.newFixedThreadPool(1);` 5. 提交执行：`Future&lt;Boolean&gt; future = executorService.submit(testCallable);` 6. 获取结果：`boolean res = future.get();` 7. 关闭服务：`executorService.shutdownNow();`2. **静态代理：**（如结婚找婚庆公司后就只需要关心自己私事，其他额外的交给婚庆公司布置） 1. 真实对象和代理对象实现 同一个接口 2. 代理对象代理真实对象 3. 优点： 1. 代理对象可以做很多真实对象做不了的事情 2. 真实对象专注于做自己的事3. `Lambda`表达式 1. 避免匿名类定义过多 2. 使得代码更加简洁 3. 去掉无意义的代码，留下核心逻辑 4. **函数式接口**：任何接口，如果只包含唯一一个抽象方法，那么它就是一个函数时接口 ；函数时接口可以使用该表达式调用 5. ```java //为了方便开发从 第2-&gt;第6 形式逐步演变简化 //Lambda无参简化实现函数式接口 public class TestLambda1 &#123; //3. 静态内部类 static class Like2 implements ILike&#123; @Override public void lambda() &#123; System.out.println(&quot;I like lambda2&quot;); &#125; &#125; public static void main(String[] args) &#123; ILike like = new Like(); like.lambda(); like = new Like2(); like.lambda(); //4. 局部内部类 class Like3 implements ILike&#123; @Override public void lambda() &#123; System.out.println(&quot;I like lambda3&quot;); &#125; &#125; like = new Like3(); like.lambda(); //5. 匿名类 like = new ILike() &#123; @Override public void lambda() &#123; System.out.println(&quot;I like lambda4&quot;); &#125; &#125;; like.lambda(); //6. Lambda简化实现函数式接口 like = () -&gt;&#123; System.out.println(&quot;I like lambda5&quot;); &#125;; like.lambda(); &#125; &#125; //1. 定义函数式接口 interface ILike&#123; void lambda(); &#125; //2. 定义外部实现类 class Like implements ILike&#123; @Override public void lambda() &#123; System.out.println(&quot;I like lambda1&quot;); &#125; &#125; //Lambda有参简化实现函数式接口 public class TestLambda2 &#123; public static void main(String[] args) &#123; //1.Lambda简化形式1 //单一参数： ILove love = (int a) -&gt; &#123; System.out.println(&quot;I love you1-1--&gt;&quot;+a); &#125;; love.Love(2); //多参数： ILove2 love2 = (int a,int b)-&gt;&#123; System.out.println(&quot;I love you2-1--&gt;&quot;+a+&quot; &quot;+b); &#125;; love2.Love2(2,1); //2.Lambda简化形式2 //单一参数： love = (a) -&gt; &#123; System.out.println(&quot;I love you1-2--&gt;&quot;+a); &#125;; love.Love(3); //多参数： love2 = (a,b) -&gt; &#123; System.out.println(&quot;I love you2-2--&gt;&quot;+a+&quot; &quot;+b); &#125;; love2.Love2(2,2); //3.Lambda简化形式3 //单一参数： love = a -&gt; &#123; System.out.println(&quot;I love you1-3&quot;); &#125;; love.Love(3); //多参数:无 多参数必须加括号，不能省略 &#125; &#125; //定义函数式接口 单参数 interface ILove&#123; void Love(int a); &#125; //定义函数式接口 多参数 interface ILove2&#123; void Love2(int a,int b); &#125; 3. 线程状态 ​ 图4-1 线程状态示意图 线程方法 更改线程优先级：&#96;&#96; 在指定的毫秒数内让当前正在执行的线程休眠：&#96;&#96; 等待该线程终止：&#96;&#96; 暂停当前正在执行的线程对象。并执行其他线程：&#96;&#96; 中断线程(不建议yo)：&#96;&#96; 测试线程是否处于活动状态：&#96;&#96; 4. 线程同步※5. 线程通信问题6. 高级主题","comments":true,"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Spring cloud项目搭建学习","date":"2023-08-06T00:49:12.000Z","path":"2023/springcloud的基本使用/","text":"目录 目录 写在前面 远程调用 RestTemplate Feign Feign远程调用 Feign自定义 Feign性能优化 Feign最佳实践分析 注册中心 Eureka注册中心（AP） Ribbon负载均衡 Nacos Nacos注册中心（CP+AP） Nacos服务多级存储模型 负载均衡 环境隔离-namespace（最外层&#x2F;最高隔离级别） Nacos配置管理 写在前面搭建测试项目各版本： 12345678Maven：4.0.0jdk：1.8Spring boot：2.3.12.RELEASE（3.0以上不再支持jdk8）Springcloud：Hoxton.SR12（sr5以下Spring boot可用2.2.x; sr5及以上用Spring boot2.3.x）Mysql：8.0.33Mybatis：2.1.1Nacos：2.0.3（注意与1.0搭建集群时的配置区别）Nginx：1.24.0 远程调用 RestTemplate Feign远程调用 Http请求 声明式、基于SpringMVC注解 RestTemplate 配置使用步骤（消费者微服务）： 注册：在启动文件中配置RestTemplate方法，使用@Bean注册为bean 1234@Beanpublic RestTemplate restTemplate()&#123; return new RestTemplate();&#125; @Autowired依赖注入controller 12@Autowiredprivate RestTemplate restTemplate; 调用get&#x2F;post相关方法获取http返回值 12String url = &quot;http://userservice/user/&quot;+order.getUserId();User user = restTemplate.getForObject(url, User.class); //将结果自动封装为user类 FeignFeign远程调用feign内部已经封装了ribbon（&#x3D;&#x3D;注：nacos负载均衡也是配置再ribbon下，所以ribbon和nacos的负载均衡规则不会冲突&#x3D;&#x3D;），所以会自动实现服务的负载均衡 配置使用步骤（消费者微服务）： 引依赖 12345&lt;!-- feign客户端依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 启动类添加注解，启动feign注解自动装配 123456789@MapperScan(&quot;com.lm.user.mapper&quot;)@SpringBootApplication@EnableFeignClients//开启feign的自动装配public class OrderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderApplication.class, args); &#125;&#125; 编写feign客户端接口（最好单独建feign客户端包（clients）方便管理） 123456789/** * feign 远程调用 */@FeignClient(&quot;userservice&quot;)public interface UserClient &#123; @GetMapping(&quot;user/&#123;id&#125;&quot;) User findById(@PathVariable(&quot;id&quot;) Long id);&#125; 使用Client接口实现http请求 123456789101112131415161718192021222324252627282930@RestController@RequestMapping(&quot;order&quot;)public class OrderController &#123; @Autowired private OrderService orderService; //@Autowired // private RestTemplate restTemplate; @Autowired private UserClient userClient; @GetMapping(&quot;&#123;orderId&#125;&quot;) public Order queryOrderByid(@PathVariable(&quot;orderId&quot;) Long orderId)&#123; Order order = orderService.queryOrderById(orderId); //feign实现远程调用 User user = userClient.findById(order.getUserId()); //restTemplate远程调用 // String url = &quot;http://userservice/user/&quot;+order.getUserId(); // User user = restTemplate.getForObject(url, User.class); //封装user到order order.setUser(user); return order ; &#125;&#125; Feign自定义 自定义类型： 自定义日志配置方式 配置文件方式 123456 feign: client: config:# default: #Feign日志文件 全局 配置 userservice: #Feign日志文件 局部 配置 对某个微服务生效 loggerLevel: FULL #日志文件类型 java代码方式 先声明一个logger的bean（建议放config包下单独管理） 123456789/** * feign日志配置注解形式要先声明一个Logger.Level作为bean */public class FeignClientConfiguration &#123; @Bean public Logger.Level feignLogger()&#123; return Logger.Level.BASIC;//日志类型为basic &#125;&#125; 通过对启动类（或Feign客户端接口类）添加注解配置全局（或局部）自定义bean生效 121. 启动类修改注解：@EnableFeignClients(defaultConfiguration = FeignClientConfiguration.class)//开启feign的日志全局配置2. Feign客户端接口修改注解：@FeignClient(value = &quot;userservice&quot;, configuration = FeignClientConfiguration.class)//feign日志文件局部配置 Feign性能优化 从底层客户端实现优化 URLConnection：默认实现，不支持连接池 Apache HttpClient ：支持连接池 引依赖：消费者微服务中引入httpclient依赖 12345&lt;!-- 为feign引入httpclient依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;/dependency&gt; 修改配置文件：修改消费者对feign.httpclient的配置 12345feign: httpclient: enabled: true #开启对htttpClient的支持 max-connections: 200 #最大连接数 max-connections-per-route: 50 #每个路径的最大连接数 OkHttp：支持连接池 从日志级别设置优化 尽量不使用full级别日志（调试错误时可以使用该级别） 日常一般使用basic或none级别即可 Feign最佳实践分析企业实践出来相对较好的Feign使用方式 继承：给消费者的FeignCLient与提供者的Controller定义统一的父接口最为标准 面向契约编程 但服务紧耦合 且SpringMVC不生效父接口参数，即父接口参数列表中的映射不会被继承（如：参数注解@PathVariavle注解），需要本地重新自定义出来 抽取：将FeignClient抽取为独立模块，并且把接口相关的pojo、默认的feign配置都放到该模块下，提供给所有服务使用（通过引用依赖进行使用） 耦合度低 代码模块清晰 以抽取方式实现最佳实践步骤： 创建新模块 如：feign-api，引入Feign客户端依赖等需要的依赖 创建其他服务需要的feign远程调用的client接口及各实体类 修改或导入其他服务中的重复配置及实体类为Feign下的类，并引入以下自定义的依赖 12345678&lt;!-- 抽出feign-api 引依赖 --&gt;&lt;dependency&gt; &lt;!-- 抽取出的自定义feign模块的组id --&gt; &lt;groupId&gt;com.lm&lt;/groupId&gt; &lt;!-- 自定义模块名 feign-api --&gt; &lt;artifactId&gt;feign-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 当定义的FeignClient不在消费者服务启动类的扫描包范围内时，这些FeignClient的bean则无法成功注入进行使用。如下图报错：。解决方案： 启动类中指定feignclient所在包 1@EnableFeignClients(basePackages = &quot;com.lm.feign&quot;)//feign抽出后扫描feign下所有包 启动类中指定feignClient字节码 1@EnableFeignClients(clients = UserClient.class)//feign抽出后只指定扫描feign下需要的客户端包 注册中心 Eureka Nacos AP AP+CP Ribbon Ribbon Eureka注册中心（AP） Eureka-server Eureka-client 记录微服务信息 各个微服务 &#x3D;&#x3D;服务端&#x3D;&#x3D;配置使用步骤： 创建模块项目 引依赖: spring-cloud-start-netflix-eureka-server 12345&lt;!--eureka服务端依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置文件 编写eureka配置 12345678910111213server: port: 10086 #eureka端口号spring: application: name: eurekasever #服务器名称eureka: client: #设置注册中心的地址，访问地址localhost:10086 service-url: defaultZone: http://localhost:$&#123;server.port&#125;/eureka/ server: # 是否启用自我保护机制 enable-self-preservation: false 客户端配置使用步骤 引依赖 12345&lt;!--eureka客户端依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件中添加配置 spring.application.name配置服务名称 12application: name: userservice #eureka服务名称 配置eureka的相关信息 12345eureka: client: #设置注册中心的地址，注意加空格，访问地址localhost:10086 service-url: defaultZone: http://127.0.0.1:10086/eureka/ Ribbon负载均衡 微服务在注册中心中拉去服务并进行负载均衡（Ribbon实现），最终确定使用哪个实例 配置使用步骤： 修改微服务消费者中业务逻辑代码中的url，用微服务提供者的服务名代替端口号（因为一个服务可能有多个实例，端口号也不一定唯一，配置为指定端口号显然不显示） 123String url = &quot;http://localhost:8081/user/&quot;+order.getUserId(); //8081是userservice的端口号 ↓String url = &quot;http://userservice/user/&quot;+order.getUserId(); 在微服务消费者启动类中的RestTemplate方法上添加负载均衡注解 12345@Bean@LoadBalanced //负载均衡注解public RestTemplate restTemplate()&#123; return new RestTemplate();&#125; Ribbion实现负载均衡原理123sequenceDiagramRibbon-&gt;&gt;Eureka_server: 请求拉取指定微服务的服务列表Eureka_server-&gt;&gt;Ribbon: 请求列表 Ribbon会根据规则选择处一个实例进行响应（默认是轮询规则） 通过IRule实现修改负载均衡规则 代码方式：在消费者微服务的启动类中直接重写IRule方法（自定义后消费者微服务再使用的所有微服务规则都会改变） 1234@Bean //全体微服务都会改变为自定义的负载均衡方式public IRule RandomRule()&#123; return new RandomRule();&#125; 配置方式：在配置文件中添加新的配置，配置指定一个或几个提供者微服务的注册微服务名（eureka中注册）（只对某个或某些提供者微服务调用时起作用） 123userservice: #对该微服务的调用进行Ribbon的负载均衡重定义 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #负载均衡规则 拓展：懒加载和饥饿加载 懒加载：Ribbon默认。第一次访问时才会创建LoadBalaceClient，所以第一次访问耗时相比之下会很长 饥饿加载：会在服务项目启动时创建，降低第一次访问耗时 只需要更改该微服务配置文件中配置即可，配置如下： 1234ribbon: eager-load: enabled: true #是否开启饥饿加载 clients: userservice #提供者微服务注册名，指定对某个或某些提供者微服务进行饥饿加载 NacosNacos注册中心（CP+AP） 注：属于Spring配置 准备工作： 下载Nacos （按需求可以更改Nacos端口号，默认8848） GitHub主页：https://github.com/alibaba/nacos GitHub的Release下载页：https://github.com/alibaba/nacos/releases 运行: 在Nacos的bin目录下cmd并执行startup.cmd -m standalone命令通过非集群方式启动（nacos默认是集群方式启动） 父工程配置使用步骤 引依赖 12345678&lt;!--nacos的管理依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.7.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 且注释掉Eureka的依赖 子工程（各个微服务）配置使用步骤 引依赖 123456 &lt;!-- nacos客户端依赖包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 且注释掉Eureka的依赖 修改配置文件: spring.cloud.nacos.server-addr 123cloud: nacos: server-addr: localhost:8848 #Nacos的端口号 且注释掉Eureka的配置 Eureka和Nacos注册中心对比 ribbon等配置两者通用 两者的细节对比 12345678sequenceDiagram消费者微服务-&gt;&gt;服务列表: 保存拉取下来的信息消费者微服务-&gt;&gt;注册中心: 定时拉去服务(pull)[Eureka、Nacos]注册中心-&gt;&gt;消费者微服务: 主动推送变更消息(push)[Nacos] =&gt;消息更新的更及时提供者微服务-&gt;&gt;注册中心: 注册服务信息[Eureka、Nacos]提供者微服务-&gt;&gt;注册中心: 30s心跳检测[Eureka、Nacos的临时实例]注册中心-&gt;&gt;提供者微服务: 主动询问[Nacos的非临时实例]消费者微服务-&gt;&gt;提供者微服务: 远程调用 Nacos非临时实例配置（在该服务的配置文件配置即可） 12345cloud: nacos: server-addr: localhost:8848 discovery: ephemeral: false #是否为临时实例，默认为true 无特殊需求推荐使用临时实例，会一定程度降低服务运行压力Nacos服务多级存储模型 服务级别（从上到下级别从低到高） 服务：例如userservice 集群：例如上海或者杭州 配置各个微服务：在配置文件（.yml）中配置spring.cloud.nacos.discovery.cluster-name属性即可 12345cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: SH #集群名称 如：SH为上海 修改消费者微服务的负载均衡规则为NacosRule（优先同集群，集群内随机） 123userservice: #对该微服务的调用进行ribbon 的负载均衡重定义 ribbon: NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则 com.netflix.loadbalancer.RandomRule(随机访问)/ com.alibaba.cloud.nacos.ribbon.NacosRule(Nacos集群) 实例：例如在杭州机房的某台部署了userservice的服务器负载均衡 可在优先同集群，集群内随机的基础上添加权重实现Nacos的权重负载均衡 在Nacos的后台控制界面中选择相对性的提供者微服务，点击“编辑”按钮，填写权重值保存即可 权重值可以为：0-1（&#x3D;&#x3D;权重为0则完全不会访问&#x3D;&#x3D;） 可用于实现“不停服维护”之类的开发操作 环境隔离-namespace（最外层&#x2F;最高隔离级别）12345graph LRnamespace--&gt;groupgroup--&gt;service/dataservice/data--&gt;集群集群--&gt;实例 在Nacos后台界面新建命名空间，填写命名空间名和描述信息，命名空间ID自动生成即可 在微服务的配置文件中添加namespace配置spring.cloud.nacos.discovery.namespace即可（注：配置&#x3D;&#x3D;填写命名空间ID&#x3D;&#x3D;而不是命名空间名） 12345cloud: nacos: server-addr: localhost:8848 discovery: namespace: 02abc9ce-8f77-4132-b105-74f36e0267fa # 命名空间ID Nacos配置管理 统一配置管理 配置更改热更新 bootstrap.yml的加载在application.yml之前123456graph LR项目启动--&gt;读本地配置application.yml项目启动--&gt;读取bootstrap.yml其加载顺序优先级高于在本地配置读取bootstrap.yml其加载顺序优先级高于在本地配置--&gt;读本地配置application.yml读本地配置application.yml--&gt;创建spring容器创建spring容器--&gt;加载bean Nacos配置管理配置使用步骤 在nacos后台添加配置管理 配置管理DataID其实就是配置文件名，但是为了区分开，命名格式统一为“微服务名-profile.后缀名”。例如userservice-dev.yaml 填写描述 添加后期可能有需求热更新且进行统一配置管理的配置项。 例如： 12pattern: dateformat: yyyy-MM-dd HH:mm:ss 完成发布 在&#x3D;&#x3D;需要管理的微服务&#x3D;&#x3D;中进行配置 引依赖 12345&lt;!-- nacos配置管理依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; 创建&#x3D;&#x3D;bootstrap.yml&#x3D;&#x3D;文件，并添加配置【微服务名、环境、nacos地址、文件后缀名】 12345678910spring: application: name: userservice #服务名 profiles: active: dev #环境 cloud: nacos: server-addr: localhost:8848 #nacos地址 config: file-extension: yaml #配置文件的后缀名 同时删除该微服务application.yml中的重复配置。 验证：微服务可通过@Value读取配置，若读取到则为配置成功 123456789101112@RestController@RequestMapping(&quot;user&quot;)public class UserController &#123; @Value(&quot;$&#123;pattern.dateformat&#125;&quot;) //@Value读取配置文件中的值 private String dateformat; @GetMapping(&quot;now&quot;) public String now()&#123; return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat));//使用自定义的dateformat变量对当前时间进行格式化 &#125;&#125; 此时还为实现配置管理的热更新，还需要重启服务才能更新 实现配置管理的热更新 在使用@Value的所在&#x3D;&#x3D;类&#x3D;&#x3D;上添加@RefreshScope注解即可 123456789101112@RestController@RefreshScope //实现热更新@RequestMapping(&quot;user&quot;)public class UserController &#123; @Value(&quot;$&#123;pattern.dateformat&#125;&quot;) private String dateformat; @GetMapping(&quot;now&quot;) public String now()&#123; return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat)); &#125;&#125; 使用@ConfigurationProperties注解实现（**&#x3D;&#x3D;推荐使用，比较灵活&#x3D;&#x3D;**） 引入@ConfigurationProperties的springboot注解解释依赖 12345678910&lt;build&gt; &lt;finalName&gt;app&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!-- &lt;version&gt;2.3.5.RELEASE&lt;/version&gt;--&gt; //父工程定义则不需要再写版本号 &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 创建管理类（最好单独建立config包下，方便管理） 12345678910111213import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;/** * 实现Nacos统一配置的pattern属性管理 */@Data@Component@ConfigurationProperties(prefix = &quot;pattern&quot;) //前缀拼接上变量名 和配置文件中一致则会取值public class PatternProperties &#123; private String dateformat;&#125; 调用：通过指定properties获取相关属性值 123456789101112131415@RestController@RequestMapping(&quot;user&quot;)public class UserController &#123; @Autowired private UserService userService; @Autowired private PatternProperties patternProperties; @GetMapping(&quot;now&quot;) public String now()&#123; return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat()));//通过patternProperties.getDateformat()获取配置文件属性值 &#125;&#125; 多环境配置共享 如某些配置在开发、测试、发布等环境中值相同，则可以共享配置 微服务会从Nacos中读取多个配置文件[spring.applicatiom.name]-[spring.profiles.active].yaml、[spring.applicatiom.name].yaml。且无论profile怎么变化，[spring.applicatiom.name].yaml一定会被加载，所以共享配置可以写入该配置文件中。 配置文件优先级： Nacos远端配置 &gt; 本地配置 [spring.applicatiom.name]-[spring.profiles.active].yaml &gt; [spring.applicatiom.name].yaml（Nacos内部配置） Nacos集群的搭建（企业级开发） &#x3D;&#x3D;一个Nacos-client 通过Nginx映射管理多个Nacos结点&#x3D;&#x3D; 每个Nacos结点都可以访问同一个MySql集群 nacos集群配置 建立名为nacos(1.X版本)&#x2F;nacos_config(2.X版本)的数据库，并运行nacos安装目录下自带的sql文件(\\conf\\nacos-mysql.sql)进行数据库的构建。 将nacos安装目录下/conf/application.properties.example文件删除.example后缀更名为application.properties。 配置application.properties 配置nacos端口 12345#*************** Spring Boot Related Configurations ***************#### Default web context path:server.servlet.contextPath=/nacos### Default web server port:server.port=8888 #nacos端口号 配置数据库类型（解开mysql注释） 123456#*************** Config Module Related Configurations ***************#### If use MySQL as datasource:spring.datasource.platform=mysql ### Count of DB:db.num=1 配置mysql数据库连接 1234### Connect URL of DB:db.url.0=jdbc:mysql://127.0.0.1:3308/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user.0=rootdb.password.0=mysql1225 配置cluster.conf文件:粘贴进去配置的nacos集群ip：端口（2.X版本若使用本机三个不同端口模拟&#x3D;&#x3D;不能用127.0.0.1代替本机真实ip&#x3D;&#x3D;，需要用(真实ip：端口号)配置） 123192.168.1.19:5555192.168.1.19:7777192.168.1.19:8888 使用本机三个不同端口模拟，可通过复制整个nacos文件夹复制三份，分别命名为nacos端口号1、nacos端口号2、nacos端口号3，然后分别更改配置文件application.properties中的端口号即可。 分别使用命令startup.cmd启动三个节点即可完成nacos集群配置。（bin目录下通过启动命令startup.cmd以集群方式启动） Nginx反向代理配置 下载Nginx并解压在不含中文的目录下。官方下载：http://nginx.org/en/download.html 配置nginx.conf文件，在http任意位置添加一下配置 123456789101112131415161718192021222324252627282930http&#123; upstream nacos-cluster &#123; server 192.168.1.19:8888; #nacos集群各个结点及端口号 server 192.168.1.19:7777; server 192.168.1.19:5555; &#125; server&#123; listen 81; #nacos反向代理端口号 80端口会被nginx自身占用，所以最好避开80端口，可以用81（不要修改http中nginx自己其他的server的80端口） location / &#123; proxy_pass http://nacos-cluster; &#125; &#125;&#125; #http结束# 若nacos为2.X版本则需要额外配置如下grpc协议监听端口# stream与http平级，不要写在http中# 需要端口偏移 偏移量为+1000stream &#123; upstream nacosGrpc &#123; server 192.168.1.19:9888; server 192.168.1.19:8777; server 192.168.1.19:6555; &#125; server &#123; listen 1081; # nacos反向代理端口号+1000 proxy_pass nacosGrpc; &#125;&#125; 启动命令：安装目录下cmd通过start nginx 或 start nginx.exe启动nginx 12nginx -s reload #重新加载Nginx配置文件，然后以优雅的方式重启Nginxnginx -s stop #强制停止Nginx服务 项目文件配置 bootstrap.yml文件中配置server-addr(Nacos集群配置Nginx反向代理&#x3D;&#x3D;必须要配置bootstrap.yml&#x3D;&#x3D;，否则根本提前加载不进去Nacos集群ip，更无法负载均衡) 123456spring: application: name: userservice #服务名 cloud: nacos: server-addr: localhost:81 #nacos代理地址 bootstrap.yml常用一般配置项（记得注释掉application.yml中的重复配置项） 12345678910spring: application: name: orderservice #服务名 profiles: active: dev #环境 cloud: nacos: server-addr: localhost:81 #nacos地址 config: file-extension: yaml #配置文件的后缀名","comments":true,"tags":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://example.com/tags/Spring-cloud/"}]},{"title":"mysql语法再整理","date":"2023-06-18T09:13:15.000Z","path":"2023/mysql语法再整理/","text":"mysql语法学习 理论基础 多表连接 内连接 外连接 交叉连接 常规例题 leetcode-数据库-175-组合两个表 leetcode-数据库-181-超过经理收入的员工 leetcode-数据库-182-查找重复的电子邮箱 leetcode-数据库-183-从不订购的客户 leetcode-数据库-196-删除重复的电子邮箱 leetcode-数据库-197-上升的温度 leetcode-数据库-511-游戏玩法分析Ⅰ leetcode-数据库-577-员工奖金 leetcode-数据库-584-寻找用户推荐人 leetcode-数据库-586-订单最多的用户 leetcode-数据库-595-大的国家 leetcode-数据库-596-超过5名学生的课 leetcode-数据库-1141-查询近30天活跃用户 leetcode-数据库-1633-各赛事的用户注册率 leetcode-数据库-1527-患某种疾病的患者 leetcode-数据库-610-判断三角形 leetcode-数据库-1407-排名靠前的旅行者 leetcode-数据库-1731-每名经理的下属员工数量 leetcode-数据库-1484-按日期分组销售产品 leetcode-数据库-1517-查找拥有有效邮箱的用户 mysql语法学习 理论基础多表连接内连接 a表： id age 1 18 2 19 3 20 b表： id 表头 2 xiaoer 3 zhangsan 4 lisi 关键字：inner join 或 join 得到满足某一条件下的A、B内部共同有的数据 会把A、B所有交叠的信息全部保留下来，包括id列。所以就&#x3D;&#x3D;可能会出现两个id列&#x3D;&#x3D;。 select a.*,b.* from a join b on a.id = b.id; 12345678910111213141516171819202122232425 - 结果： - | id | age | id(1) | name | | :--: | :--: | :---: | :------: | | 2 | 19 | 2 | xiaoer | | 3 | 20 | 3 | zhangsan |- 注意： - 一般都要加上on使用，，否则会被解释为交叉连接#### 外连接1. 左连接 - 关键字：left join 或者 left outer join - 得到的结果是A中所有数据+B中符合某一条件下的数据。若A中的数据在B中找不到对应合适的数据项，会置为null - ``` select a.*,b.* from a left join b on a.id = b.id; 结果： id age id(1) name 1 18 NULL NULL 2 19 2 xiaoer 3 20 3 zhangsan 左连接+where b.clumn is null 关键字：left join 或者 left outer join+where b.clumn is null 得到的结果是A中的数据“减去”B中符合该条件下的数据后剩下的数据 select a.*,b.* from a left join b on a.id = b.id where b.id is null; 123456789101112131415161718 - 结果： - | id | age | id(1) | name | | :--: | :--: | :---: | :--: | | 1 | 18 | NULL | NULL |3. 右连接 - 关键字：right join 或者 right outer join - 得到的是B中所有数据+A中符合某条件下的数据，若A中没有满足B中的数据项则置为NULL - ``` select a.*,b.* from a right join b on a.id = b.id; 结果 id age id(1) name 2 19 2 xiaoer 3 20 3 zhangsan NULL NULL 4 lisi 右连接+where is null 关键字：right join 或者 right outer join+where a.clumn is null 得到的是B中所有数据“减去”A中符合某条件的数据剩下的数据项 select a.*,b.* from a right join b on a.id = b.id where a.id is null; 12345678910111213141516171819202122232425 - 结果： - | id | age | id(1) | name | | :--: | :--: | :---: | :---: | | NULL | NULL | 4 | lisi4 |5. left join + nuion + right join（sql中的full union） - 关键字：left join nuion right join - union后重复的数据项会合并 - 得到A和B满足条件下所有数据项，A中没有B的对用数据或者B中没有A中对应数据的数据项会被置为空 - ``` select a.*,b.* from a left join b on a.id = b.id union select a.*,b.* from a right join b on a.id = b.id; 结果： id age id(1) name 1 18 NULL NULL 2 19 2 xiaoer 3 20 3 zhangsan NULL NULL 4 lisi (left join + where a.clumn is null) nuion + (right join+where b.clumn is null)（sql中的full union） 关键字：left join where a.clumn is null nuion right join where b.clumn is null 得到的A、B中不满足某一条件的各自剩下的数据项 select a.*,b.* from a left join b on a.id = b.id where b.id is null union select a.*,b.* from a right join b on a.id = b.id where a.id is null; 1234567891011121314151617181920 - 结果： - | id | age | id(1) | name | | :--: | :--: | :---: | :--: | | 1 | 18 | NULL | NULL | | NULL | NULL | 4 | lisi |#### 交叉连接1. 笛卡尔积 - 关键字：cross join - 得到符合某一条件下A各项与B各项的==全排列组合== - ``` select a.*,b.* from a cross join b 结果： id age id(1) name 1 18 2 xiaoer 2 19 2 xiaoer 3 20 2 xiaoer 1 18 3 zhangsan 2 19 3 zhangsan 3 20 3 zhangsan 1 18 4 lisi 2 19 4 lisi 3 20 4 lisi cross join + where 关键字：cross join where 等价于 内连接 满足某一条件下的A、B内部共同有的数据 &#96;&#96;&#96;select a.,b.from across join bwhere a.id &#x3D; b.id; 1234567891011121314151617181920 - 结果： - | id | age | id(1) | name | | :--: | :--: | :---: | :------: | | 2 | 19 | 2 | xiaoer | | 3 | 20 | 3 | zhangsan | - 注意：cross join + on 也会被解释为cross join +where## 常规例题### leetcode-数据库-175-组合两个表- 题意 表: `Person` +————-+———+ | 列名 | 类型 | +————-+———+ | PersonId | int | | FirstName | varchar | | LastName | varchar | +————-+———+ personId 是该表的主键（具有唯一值的列）。 该表包含一些人的 ID 和他们的姓和名的信息。 123表: `Address` +————-+———+ | 列名 | 类型 | +————-+———+ | AddressId | int | | PersonId | int | | City | varchar | | State | varchar | +————-+———+ addressId 是该表的主键（具有唯一值的列）。 该表的每一行都包含一个 ID &#x3D; PersonId 的人的城市和州的信息。 123456789编写解决方案，报告 `Person` 表中每个人的姓、名、城市和州。如果 `personId` 的地址不在 `Address` 表中，则报告为 `null` 。以 **任意顺序** 返回结果表。结果格式如下所示。**示例 1:** 输入: Person表: +———-+———-+———–+ | personId | lastName | firstName | +———-+———-+———–+ | 1 | Wang | Allen | | 2 | Alice | Bob | +———-+———-+———–+ Address表: +———–+———-+—————+————+ | addressId | personId | city | state | +———–+———-+—————+————+ | 1 | 2 | New York City | New York | | 2 | 3 | Leetcode | California | +———–+———-+—————+————+ 输出: +———–+———-+—————+———-+ | firstName | lastName | city | state | +———–+———-+—————+———-+ | Allen | Wang | Null | Null | | Bob | Alice | New York City | New York | +———–+———-+—————+———-+ 解释: 地址表中没有 personId &#x3D; 1 的地址，所以它们的城市和州返回 null。 addressId &#x3D; 1 包含了 personId &#x3D; 2 的地址信息。 123- 解答示例： SELECT person.firstname,person.lastName,address.city,address.state FROM person LEFT JOIN address on person.personId &#x3D; address.personId; 1234567### leetcode-数据库-181-超过经理收入的员工- 题意 表：`Employee` +————-+———+ | Column Name | Type | +————-+———+ | id | int | | name | varchar | | salary | int | | managerId | int | +————-+———+ id 是该表的主键（具有唯一值的列）。 该表的每一行都表示雇员的ID、姓名、工资和经理的ID。 123456789编写解决方案，找出收入比经理高的员工。以 **任意顺序** 返回结果表。结果格式如下所示。**示例 1:** 输入: Employee 表: +—-+——-+——–+———–+ | id | name | salary | managerId | +—-+——-+——–+———–+ | 1 | Joe | 70000 | 3 | | 2 | Henry | 80000 | 4 | | 3 | Sam | 60000 | Null | | 4 | Max | 90000 | Null | +—-+——-+——–+———–+ 输出: +———-+ | Employee | +———-+ | Joe | +———-+ 解释: Joe 是唯一挣得比经理多的雇员。 123- 解答示例： SELECT a.name Employee from employee a JOIN employee b on a.managerId &#x3D; b.id WHERE a.salary &gt; b.salary 123456789- 要点：注意关键字优先级： where &gt; group by &gt; having &gt; oder by### leetcode-数据库-182-查找重复的电子邮箱- 题意 表: `Person` +————-+———+ | Column Name | Type | +————-+———+ | id | int | | email | varchar | +————-+———+ id 是该表的主键（具有唯一值的列）。 此表的每一行都包含一封电子邮件。电子邮件不包含大写字母。 123456789编写解决方案来报告所有重复的电子邮件。 请注意，可以保证电子邮件字段不为 NULL。以 **任意顺序** 返回结果表。结果格式如下例。**示例 1:** 输入: Person 表: +—-+———+ | id | email | +—-+———+ | 1 | &#97;&#64;&#x62;&#x2e;&#99;&#111;&#x6d; | | 2 | &#x63;&#x40;&#x64;&#x2e;&#99;&#x6f;&#109; | | 3 | &#97;&#64;&#x62;&#46;&#99;&#111;&#109; | +—-+———+ 输出: +———+ | Email | +———+ | &#x61;&#64;&#x62;&#46;&#99;&#x6f;&#x6d; | +———+ 解释: &#97;&#64;&#x62;&#x2e;&#99;&#111;&#x6d; 出现了两次。 12345678910- 解答示例- 要点### leetcode-数据库-183-从不订购的客户- 题意 `Customers` 表： +————-+———+ | Column Name | Type | +————-+———+ | id | int | | name | varchar | +————-+———+ 在 SQL 中，id 是该表的主键。 该表的每一行都表示客户的 ID 和名称。 123`Orders` 表： +————-+——+ | Column Name | Type | +————-+——+ | id | int | | customerId | int | +————-+——+ 在 SQL 中，id 是该表的主键。 customerId 是 Customers 表中 ID 的外键( Pandas 中的连接键)。 该表的每一行都表示订单的 ID 和订购该订单的客户的 ID。 123456789找出所有从不点任何东西的顾客。以 **任意顺序** 返回结果表。结果格式如下所示。**示例 1：** 输入： Customers table: +—-+——-+ | id | name | +—-+——-+ | 1 | Joe | | 2 | Henry | | 3 | Sam | | 4 | Max | +—-+——-+ Orders table: +—-+————+ | id | customerId | +—-+————+ | 1 | 3 | | 2 | 1 | +—-+————+ 输出： +———–+ | Customers | +———–+ | Henry | | Max | +———–+ 1234567891011- 解答示例- 要点### leetcode-数据库-196-删除重复的电子邮箱- 题意 表: `Person` +————-+———+ | Column Name | Type | +————-+———+ | id | int | | email | varchar | +————-+———+ id 是该表的主键列(具有唯一值的列)。 该表的每一行包含一封电子邮件。电子邮件将不包含大写字母。 12345678910111213编写解决方案 **删除** 所有重复的电子邮件，只保留一个具有最小 `id` 的唯一电子邮件。（对于 SQL 用户，请注意你应该编写一个 `DELETE` 语句而不是 `SELECT` 语句。）（对于 Pandas 用户，请注意你应该直接修改 `Person` 表。）运行脚本后，显示的答案是 `Person` 表。驱动程序将首先编译并运行您的代码片段，然后再显示 `Person` 表。`Person` 表的最终顺序 **无关紧要** 。返回结果格式如下示例所示。**示例 1:** 输入: Person 表: +—-+——————+ | id | email | +—-+——————+ | 1 | &#x6a;&#x6f;&#104;&#x6e;&#x40;&#x65;&#x78;&#x61;&#x6d;&#112;&#108;&#101;&#x2e;&#99;&#111;&#109; | | 2 | &#98;&#x6f;&#98;&#x40;&#x65;&#x78;&#97;&#x6d;&#x70;&#x6c;&#101;&#46;&#x63;&#111;&#109; | | 3 | &#x6a;&#x6f;&#x68;&#110;&#64;&#x65;&#x78;&#97;&#x6d;&#112;&#108;&#x65;&#46;&#x63;&#x6f;&#109; | +—-+——————+ 输出: +—-+——————+ | id | email | +—-+——————+ | 1 | &#106;&#111;&#x68;&#110;&#64;&#101;&#x78;&#x61;&#109;&#112;&#x6c;&#x65;&#46;&#x63;&#111;&#109; | | 2 | &#98;&#x6f;&#x62;&#64;&#x65;&#x78;&#x61;&#x6d;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109; | +—-+——————+ 解释: &#106;&#111;&#104;&#110;&#x40;&#101;&#120;&#x61;&#109;&#x70;&#x6c;&#101;&#46;&#99;&#111;&#x6d;重复两次。我们保留最小的Id &#x3D; 1。 1234567891011- 解答示例- 要点### leetcode-数据库-197-上升的温度- 题意 表： `Weather` +—————+———+ | Column Name | Type | +—————+———+ | id | int | | recordDate | date | | temperature | int | +—————+———+ id 是该表具有唯一值的列。 该表包含特定日期的温度信息 123456789编写解决方案，找出与之前（昨天的）日期相比温度更高的所有日期的 `id` 。返回结果 **无顺序要求** 。结果格式如下例子所示。**示例 1：** 输入： Weather 表： +—-+————+————-+ | id | recordDate | Temperature | +—-+————+————-+ | 1 | 2015-01-01 | 10 | | 2 | 2015-01-02 | 25 | | 3 | 2015-01-03 | 20 | | 4 | 2015-01-04 | 30 | +—-+————+————-+ 输出： +—-+ | id | +—-+ | 2 | | 4 | +—-+ 解释： 2015-01-02 的温度比前一天高（10 -&gt; 25） 2015-01-04 的温度比前一天高（20 -&gt; 30） 1234567891011- 解答示例- 要点### leetcode-数据库-511-游戏玩法分析Ⅰ- 题意 活动表 `Activity`： +————–+———+ | Column Name | Type | +————–+———+ | player_id | int | | device_id | int | | event_date | date | | games_played | int | +————–+———+ 在 SQL 中，表的主键是 (player_id, event_date)。 这张表展示了一些游戏玩家在游戏平台上的行为活动。 每行数据记录了一名玩家在退出平台之前，当天使用同一台设备登录平台后打开的游戏的数目（可能是 0 个）。 12345查询每位玩家 **第一次登陆平台的日期**。查询结果的格式如下所示： Activity 表： +———–+———–+————+————–+ | player_id | device_id | event_date | games_played | +———–+———–+————+————–+ | 1 | 2 | 2016-03-01 | 5 | | 1 | 2 | 2016-05-02 | 6 | | 2 | 3 | 2017-06-25 | 1 | | 3 | 1 | 2016-03-02 | 0 | | 3 | 4 | 2018-07-03 | 5 | +———–+———–+————+————–+ Result 表： +———–+————-+ | player_id | first_login | +———–+————-+ | 1 | 2016-03-01 | | 2 | 2017-06-25 | | 3 | 2016-03-02 | +———–+————-+ 1234567891011- 解答示例- 要点### leetcode-数据库-577-员工奖金- 题意 表：`Employee` +————-+———+ | Column Name | Type | +————-+———+ | empId | int | | name | varchar | | supervisor | int | | salary | int | +————-+———+ empId 是该表中具有唯一值的列。 该表的每一行都表示员工的姓名和 id，以及他们的工资和经理的 id。 123表：`Bonus` +————-+——+ | Column Name | Type | +————-+——+ | empId | int | | bonus | int | +————-+——+ empId 是该表具有唯一值的列。 empId 是 Employee 表中 empId 的外键(reference 列)。 该表的每一行都包含一个员工的 id 和他们各自的奖金。 123456789编写解决方案，报告每个奖金 **少于** `1000` 的员工的姓名和奖金数额。以 **任意顺序** 返回结果表。结果格式如下所示。**示例 1：** 输入： Employee table: +——-+——–+————+——–+ | empId | name | supervisor | salary | +——-+——–+————+——–+ | 3 | Brad | null | 4000 | | 1 | John | 3 | 1000 | | 2 | Dan | 3 | 2000 | | 4 | Thomas | 3 | 4000 | +——-+——–+————+——–+ Bonus table: +——-+——-+ | empId | bonus | +——-+——-+ | 2 | 500 | | 4 | 2000 | +——-+——-+ 输出： +——+——-+ | name | bonus | +——+——-+ | Brad | null | | John | null | | Dan | 500 | +——+——-+ 1234567891011- 解答示例- 要点### leetcode-数据库-584-寻找用户推荐人- 题意 表: `Customer` +————-+———+ | Column Name | Type | +————-+———+ | id | int | | name | varchar | | referee_id | int | +————-+———+ 在 SQL 中，id 是该表的主键列。 该表的每一行表示一个客户的 id、姓名以及推荐他们的客户的 id。 123456789找出那些 **没有被** `id = 2` 的客户 **推荐** 的客户的姓名。以 **任意顺序** 返回结果表。结果格式如下所示。**示例 1：** 输入： Customer 表: +—-+——+————+ | id | name | referee_id | +—-+——+————+ | 1 | Will | null | | 2 | Jane | null | | 3 | Alex | 2 | | 4 | Bill | null | | 5 | Zack | 1 | | 6 | Mark | 2 | +—-+——+————+ 输出： +——+ | name | +——+ | Will | | Jane | | Bill | | Zack | +——+ 1234567891011- 解答示例- 要点### leetcode-数据库-586-订单最多的用户- 题意 表: `Orders` +—————–+———-+ | Column Name | Type | +—————–+———-+ | order_number | int | | customer_number | int | +—————–+———-+ 在 SQL 中，Order_number是该表的主键。 此表包含关于订单ID和客户ID的信息。 123456789查找下了 **最多订单** 的客户的 `customer_number` 。测试用例生成后， **恰好有一个客户** 比任何其他客户下了更多的订单。查询结果格式如下所示。**示例 1:** 输入: Orders 表: +————–+—————–+ | order_number | customer_number | +————–+—————–+ | 1 | 1 | | 2 | 2 | | 3 | 3 | | 4 | 3 | +————–+—————–+ 输出: +—————–+ | customer_number | +—————–+ | 3 | +—————–+ 解释: customer_number 为 ‘3’ 的顾客有两个订单，比顾客 ‘1’ 或者 ‘2’ 都要多，因为他们只有一个订单。 所以结果是该顾客的 customer_number ，也就是 3 。 12345678910111213 **进阶：** 如果有多位顾客订单数并列最多，你能找到他们所有的 `customer_number` 吗？- 解答示例- 要点### leetcode-数据库-595-大的国家- 题意 `World` 表： +————-+———+ | Column Name | Type | +————-+———+ | name | varchar | | continent | varchar | | area | int | | population | int | | gdp | bigint | +————-+———+ name 是该表的主键（具有唯一值的列）。 这张表的每一行提供：国家名称、所属大陆、面积、人口和 GDP 值。 1234567891011121314如果一个国家满足下述两个条件之一，则认为该国是 **大国** ：- 面积至少为 300 万平方公里（即，`3000000 km2`），或者- 人口至少为 2500 万（即 `25000000`）编写解决方案找出 **大国** 的国家名称、人口和面积。按 **任意顺序** 返回结果表。返回结果格式如下例所示。**示例：** 输入： World 表： +————-+———–+———+————+————–+ | name | continent | area | population | gdp | +————-+———–+———+————+————–+ | Afghanistan | Asia | 652230 | 25500100 | 20343000000 | | Albania | Europe | 28748 | 2831741 | 12960000000 | | Algeria | Africa | 2381741 | 37100000 | 188681000000 | | Andorra | Europe | 468 | 78115 | 3712000000 | | Angola | Africa | 1246700 | 20609294 | 100990000000 | +————-+———–+———+————+————–+ 输出： +————-+————+———+ | name | population | area | +————-+————+———+ | Afghanistan | 25500100 | 652230 | | Algeria | 37100000 | 2381741 | +————-+————+———+ 1234567891011- 解答示例- 要点### leetcode-数据库-596-超过5名学生的课- 题意 表: `Courses` +————-+———+ | Column Name | Type | +————-+———+ | student | varchar | | class | varchar | +————-+———+ 在 SQL 中，(student, class)是该表的主键列。 该表的每一行表示学生的名字和他们注册的班级。 123456789查询 **至少有5个学生** 的所有班级。以 **任意顺序** 返回结果表。查询结果格式如下所示。 **示例 1:** 输入: Courses table: +———+———-+ | student | class | +———+———-+ | A | Math | | B | English | | C | Math | | D | Biology | | E | Math | | F | Computer | | G | Math | | H | Math | | I | Math | +———+———-+ 输出: +———+ | class | +———+ | Math | +———+ 解释: -数学课有6个学生，所以我们包括它。 -英语课有1名学生，所以我们不包括它。 -生物课有1名学生，所以我们不包括它。 -计算机课有1个学生，所以我们不包括它。 1234567891011- 解答示例- 要点### leetcode-数据库-1141-查询近30天活跃用户- 题意 表：`Activity` +—————+———+ | Column Name | Type | +—————+———+ | user_id | int | | session_id | int | | activity_date | date | | activity_type | enum | +—————+———+ 该表没有包含重复数据。 activity_type 列是 ENUM(category) 类型， 从 (‘open_session’， ‘end_session’， ‘scroll_down’， ‘send_message’) 取值。 该表记录社交媒体网站的用户活动。 注意，每个会话只属于一个用户。 123456789编写解决方案，统计截至 `2019-07-27`（包含2019-07-27），近 `30` 天的每日活跃用户数（当天只要有一条活动记录，即为活跃用户）。以 **任意顺序** 返回结果表。结果示例如下。**示例 1:** 输入： Activity table: +———+————+—————+—————+ | user_id | session_id | activity_date | activity_type | +———+————+—————+—————+ | 1 | 1 | 2019-07-20 | open_session | | 1 | 1 | 2019-07-20 | scroll_down | | 1 | 1 | 2019-07-20 | end_session | | 2 | 4 | 2019-07-20 | open_session | | 2 | 4 | 2019-07-21 | send_message | | 2 | 4 | 2019-07-21 | end_session | | 3 | 2 | 2019-07-21 | open_session | | 3 | 2 | 2019-07-21 | send_message | | 3 | 2 | 2019-07-21 | end_session | | 4 | 3 | 2019-06-25 | open_session | | 4 | 3 | 2019-06-25 | end_session | +———+————+—————+—————+ 输出： +————+————–+ | day | active_users | +————+————–+ | 2019-07-20 | 2 | | 2019-07-21 | 2 | +————+————–+ 解释：注意非活跃用户的记录不需要展示。 1234567891011- 解答示例- 要点### leetcode-数据库-1633-各赛事的用户注册率- 题意 用户表： `Users` +————-+———+ | Column Name | Type | +————-+———+ | user_id | int | | user_name | varchar | +————-+———+ user_id 是该表的主键(具有唯一值的列)。 该表中的每行包括用户 ID 和用户名。 123注册表： `Register` +————-+———+ | Column Name | Type | +————-+———+ | contest_id | int | | user_id | int | +————-+———+ (contest_id, user_id) 是该表的主键(具有唯一值的列的组合)。 该表中的每行包含用户的 ID 和他们注册的赛事。 123456789编写解决方案统计出各赛事的用户注册百分率，保留两位小数。返回的结果表按 `percentage` 的 **降序** 排序，若相同则按 `contest_id` 的 **升序** 排序。返回结果如下示例所示。**示例 1：** 输入： Users 表： +———+———–+ | user_id | user_name | +———+———–+ | 6 | Alice | | 2 | Bob | | 7 | Alex | +———+———–+ Register 表： +————+———+ | contest_id | user_id | +————+———+ | 215 | 6 | | 209 | 2 | | 208 | 2 | | 210 | 6 | | 208 | 6 | | 209 | 7 | | 209 | 6 | | 215 | 7 | | 208 | 7 | | 210 | 2 | | 207 | 2 | | 210 | 7 | +————+———+ 输出： +————+————+ | contest_id | percentage | +————+————+ | 208 | 100.0 | | 209 | 100.0 | | 210 | 100.0 | | 215 | 66.67 | | 207 | 33.33 | +————+————+ 解释： 所有用户都注册了 208、209 和 210 赛事，因此这些赛事的注册率为 100% ，我们按 contest_id 的降序排序加入结果表中。 Alice 和 Alex 注册了 215 赛事，注册率为 ((2&#x2F;3) * 100) &#x3D; 66.67% Bob 注册了 207 赛事，注册率为 ((1&#x2F;3) * 100) &#x3D; 33.33% 1234567891011- 解答示例- 要点### leetcode-数据库-1527-患某种疾病的患者- 题意 患者信息表： `Patients` +————–+———+ | Column Name | Type | +————–+———+ | patient_id | int | | patient_name | varchar | | conditions | varchar | +————–+———+ 在 SQL 中，patient_id （患者 ID）是该表的主键。 ‘conditions’ （疾病）包含 0 个或以上的疾病代码，以空格分隔。 这个表包含医院中患者的信息。 123456789查询患有 I类糖尿病的患者 ID （patient_id）、患者姓名（patient_name）以及其患有的所有疾病代码（conditions）。I 类糖尿病的代码总是包含前缀 `DIAB1` 。按 **任意顺序** 返回结果表。查询结果格式如下示例所示。**示例 1:** 输入： Patients表： +————+————–+————–+ | patient_id | patient_name | conditions | +————+————–+————–+ | 1 | Daniel | YFEV COUGH | | 2 | Alice | | | 3 | Bob | DIAB100 MYOP | | 4 | George | ACNE DIAB100 | | 5 | Alain | DIAB201 | +————+————–+————–+ 输出： +————+————–+————–+ | patient_id | patient_name | conditions | +————+————–+————–+ | 3 | Bob | DIAB100 MYOP | | 4 | George | ACNE DIAB100 | +————+————–+————–+ 解释：Bob 和 George 都患有代码以 DIAB1 开头的疾病。 1234567891011- 解答示例- 要点### leetcode-数据库-610-判断三角形- 题意 表: `Triangle` +————-+——+ | Column Name | Type | +————-+——+ | x | int | | y | int | | z | int | +————-+——+ 在 SQL 中，(x, y, z)是该表的主键列。 该表的每一行包含三个线段的长度。 123456789对每三个线段报告它们是否可以形成一个三角形。以 **任意顺序** 返回结果表。查询结果格式如下所示。**示例 1:** 输入: Triangle 表: +—-+—-+—-+ | x | y | z | +—-+—-+—-+ | 13 | 15 | 30 | | 10 | 20 | 15 | +—-+—-+—-+ 输出: +—-+—-+—-+———-+ | x | y | z | triangle | +—-+—-+—-+———-+ | 13 | 15 | 30 | No | | 10 | 20 | 15 | Yes | +—-+—-+—-+———-+ 1234567891011- 解答示例- 要点### leetcode-数据库-1407-排名靠前的旅行者- 题意 表：`Users` +—————+———+ | Column Name | Type | +—————+———+ | id | int | | name | varchar | +—————+———+ id 是该表中具有唯一值的列。 name 是用户名字。 123表：`Rides` +—————+———+ | Column Name | Type | +—————+———+ | id | int | | user_id | int | | distance | int | +—————+———+ id 是该表中具有唯一值的列。 user_id 是本次行程的用户的 id, 而该用户此次行程距离为 distance 。 123456789编写解决方案，报告每个用户的旅行距离。返回的结果表单，以 `travelled_distance` **降序排列** ，如果有两个或者更多的用户旅行了相同的距离, 那么再以 `name` **升序排列** 。返回结果格式如下例所示。**示例 1：** 输入： Users 表： +——+———–+ | id | name | +——+———–+ | 1 | Alice | | 2 | Bob | | 3 | Alex | | 4 | Donald | | 7 | Lee | | 13 | Jonathan | | 19 | Elvis | +——+———–+ Rides 表： +——+———-+———-+ | id | user_id | distance | +——+———-+———-+ | 1 | 1 | 120 | | 2 | 2 | 317 | | 3 | 3 | 222 | | 4 | 7 | 100 | | 5 | 13 | 312 | | 6 | 19 | 50 | | 7 | 7 | 120 | | 8 | 19 | 400 | | 9 | 7 | 230 | +——+———-+———-+ 输出： +———-+——————–+ | name | travelled_distance | +———-+——————–+ | Elvis | 450 | | Lee | 450 | | Bob | 317 | | Jonathan | 312 | | Alex | 222 | | Alice | 120 | | Donald | 0 | +———-+——————–+ 解释： Elvis 和 Lee 旅行了 450 英里，Elvis 是排名靠前的旅行者，因为他的名字在字母表上的排序比 Lee 更小。 Bob, Jonathan, Alex 和 Alice 只有一次行程，我们只按此次行程的全部距离对他们排序。 Donald 没有任何行程, 他的旅行距离为 0。 1234567891011- 解答示例- 要点### leetcode-数据库-1731-每名经理的下属员工数量- 题意 Table: `Employees` +————-+———-+ | Column Name | Type | +————-+———-+ | employee_id | int | | name | varchar | | reports_to | int | | age | int | +————-+———-+ employee_id 是这个表的主键. 该表包含员工以及需要听取他们汇报的上级经理的ID的信息。 有些员工不需要向任何人汇报（reports_to 为空）。 123456789对于此问题，我们将至少有一个其他员工需要向他汇报的员工，视为一个经理。编写SQL查询需要听取汇报的所有经理的ID、名称、直接向该经理汇报的员工人数，以及这些员工的平均年龄，其中该平均年龄需要四舍五入到最接近的整数。返回的结果集需要按照 `employee_id `进行排序。查询结果的格式如下： Employees table: +————-+———+————+—–+ | employee_id | name | reports_to | age | +————-+———+————+—–+ | 9 | Hercy | null | 43 | | 6 | Alice | 9 | 41 | | 4 | Bob | 9 | 36 | | 2 | Winston | null | 37 | +————-+———+————+—–+ Result table: +————-+——-+—————+————-+ | employee_id | name | reports_count | average_age | +————-+——-+—————+————-+ | 9 | Hercy | 2 | 39 | +————-+——-+—————+————-+ Hercy 有两个需要向他汇报的员工, 他们是 Alice and Bob. 他们的平均年龄是 (41+36)&#x2F;2 &#x3D; 38.5, 四舍五入的结果是 39. 1234567891011- 解答示例- 要点### leetcode-数据库-1484-按日期分组销售产品- 题意 表 `Activities`： +————-+———+ | 列名 | 类型 | +————-+———+ | sell_date | date | | product | varchar | +————-+———+ 该表没有主键(具有唯一值的列)。它可能包含重复项。 此表的每一行都包含产品名称和在市场上销售的日期。 12345678编写解决方案找出每个日期、销售的不同产品的数量及其名称。每个日期的销售产品名称应按词典序排列。返回按 `sell_date` 排序的结果表。结果表结果格式如下例所示。**示例 1:** 输入： Activities 表： +————+————-+ | sell_date | product | +————+————-+ | 2020-05-30 | Headphone | | 2020-06-01 | Pencil | | 2020-06-02 | Mask | | 2020-05-30 | Basketball | | 2020-06-01 | Bible | | 2020-06-02 | Mask | | 2020-05-30 | T-Shirt | +————+————-+ 输出： +————+———-+——————————+ | sell_date | num_sold | products | +————+———-+——————————+ | 2020-05-30 | 3 | Basketball,Headphone,T-shirt | | 2020-06-01 | 2 | Bible,Pencil | | 2020-06-02 | 1 | Mask | +————+———-+——————————+ 解释： 对于2020-05-30，出售的物品是 (Headphone, Basketball, T-shirt)，按词典序排列，并用逗号 ‘,’ 分隔。 对于2020-06-01，出售的物品是 (Pencil, Bible)，按词典序排列，并用逗号分隔。 对于2020-06-02，出售的物品是 (Mask)，只需返回该物品名。 1234567891011- 解答示例- 要点### leetcode-数据库-1517-查找拥有有效邮箱的用户- 题意 表: `Users` +—————+———+ | Column Name | Type | +—————+———+ | user_id | int | | name | varchar | | mail | varchar | +—————+———+ user_id 是该表的主键（具有唯一值的列）。 该表包含了网站已注册用户的信息。有一些电子邮件是无效的。 1234567891011121314编写一个解决方案，以查找具有有效电子邮件的用户。一个有效的电子邮件具有前缀名称和域，其中：1. **前缀** 名称是一个字符串，可以包含字母（大写或小写），数字，下划线 `&#x27;_&#x27;` ，点 `&#x27;.&#x27;` 和/或破折号 `&#x27;-&#x27;` 。前缀名称 **必须** 以字母开头。2. **域** 为 `&#x27;@leetcode.com&#x27;` 。以任何顺序返回结果表。结果的格式如以下示例所示：**示例 1：** 输入： Users 表: +———+———–+————————-+ | user_id | name | mail | +———+———–+————————-+ | 1 | Winston | &#119;&#105;&#x6e;&#x73;&#x74;&#x6f;&#x6e;&#x40;&#108;&#101;&#101;&#x74;&#99;&#111;&#100;&#101;&#46;&#x63;&#111;&#109; | | 2 | Jonathan | jonathanisgreat | | 3 | Annabelle | &#x62;&#101;&#108;&#108;&#x61;&#45;&#64;&#x6c;&#101;&#101;&#116;&#99;&#x6f;&#100;&#101;&#46;&#99;&#x6f;&#x6d; | | 4 | Sally | &#x73;&#97;&#108;&#x6c;&#x79;&#46;&#x63;&#x6f;&#x6d;&#x65;&#64;&#108;&#101;&#101;&#116;&#x63;&#111;&#100;&#101;&#x2e;&#99;&#111;&#x6d; | | 5 | Marwan | quarz#&#x32;&#x30;&#50;&#x30;&#x40;&#108;&#101;&#101;&#116;&#x63;&#111;&#x64;&#101;&#x2e;&#x63;&#111;&#109; | | 6 | David | &#100;&#97;&#118;&#105;&#x64;&#54;&#57;&#64;&#x67;&#109;&#97;&#105;&#x6c;&#x2e;&#x63;&#x6f;&#109; | | 7 | Shapiro | &#46;&#115;&#x68;&#97;&#112;&#x6f;&#x40;&#108;&#x65;&#x65;&#x74;&#99;&#111;&#100;&#x65;&#46;&#99;&#x6f;&#x6d; | +———+———–+————————-+ 输出： +———+———–+————————-+ | user_id | name | mail | +———+———–+————————-+ | 1 | Winston | &#119;&#105;&#x6e;&#115;&#x74;&#111;&#x6e;&#64;&#x6c;&#x65;&#x65;&#116;&#x63;&#111;&#100;&#x65;&#46;&#x63;&#111;&#109; | | 3 | Annabelle | &#98;&#x65;&#x6c;&#x6c;&#97;&#x2d;&#64;&#108;&#x65;&#x65;&#x74;&#99;&#111;&#100;&#101;&#46;&#x63;&#x6f;&#x6d; | | 4 | Sally | &#115;&#97;&#x6c;&#x6c;&#121;&#x2e;&#99;&#111;&#x6d;&#x65;&#64;&#108;&#101;&#101;&#x74;&#x63;&#x6f;&#x64;&#101;&#46;&#99;&#111;&#x6d; | +———+———–+————————-+ 解释： 用户 2 的电子邮件没有域。 用户 5 的电子邮件带有不允许的 ‘#’ 符号。 用户 6 的电子邮件没有 leetcode 域。 用户 7 的电子邮件以点开头。 &#96;&#96;&#96; 解答示例 要点","comments":true,"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"mysql学习笔记","date":"2020-06-18T09:18:12.000Z","path":"2020/mysql/","text":"目录 目录 写在前面：MySQL安装 mysql重点内容 mysql优化 如何定位慢查询 优化sql语句慢查询 索引 sql优化经验 事务 事务特性（ACID） 隔离级别 MVCC（多版本并发控制） 日志 锁 写在前面：MySQL安装 MySQL可以解压到U盘里 打开解压的文件夹K:/softwareInstall/mysql-8.0.20-winx64 ，在该文件夹下创建 my.ini 配置文件，编辑 my.ini 配置以下基本信息： 1234567891011121314151617[client]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]# 设置3306端口port = 3306# 设置mysql的安装目录basedir=K:/softwareInstall/mysql-8.0.20-winx64# 设置 mysql数据库的数据的存放目录，MySQL 8+ 不需要以下配置，系统自己生成即可，否则有可能报错datadir=K:/softwareInstall/mysql-8.0.20-winx64/data# 允许最大连接数max_connections=20# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB 启动下 MySQL 数据库：cd K:\\softwareInstall\\mysql-8.0.11\\bin mysqld --initialize --console在 Windows 系统下，以管理员身份打开命令窗口(cmd)，进入 MySQL 安装目录的 bin 目录。 1234567启动：cd K:/softwareInstall/mysql-8.0.20-winx64/binmysqld --console 关闭：cd K:/softwareInstall/mysql-8.0.20-winx64/binmysqladmin -uroot shutdown 执行完成后，会输出 root 用户的初始默认密码，如： 12018-04-20T02:35:05.464644Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: RqUDv!g8j%D; RqUDv!g8j%D;就是初始密码，后续登录需要用到，你也可以在登陆后修改密码。 输入安装命令：mysqld install将mysql服务添加到系统的服务中，这样下面的命令net start mysql才会生效。 启动输入命令即可：net start mysql 停止服务net stop mysql 注意: 在5.7版本中需要初始化 data 目录: 12cd K:/softwareInstall/mysql-8.0.20-winx64/bin mysqld --initialize-insecure 登录MySQL，当 MySQL 服务已经运行时, 我们可以通过 MySQL 自带的客户端工具登录到 MySQL 数据库中, 首先打开命令提示符, 输入以下格式的命名: 12345678910mysql -h 主机名 -u 用户名 -p -h myserver -P 端口参数说明： -h : 指定客户端所要登录的 MySQL 主机名, 登录本机(localhost 或 127.0.0.1)该参数可以省略; -u : 登录的用户名; -p : 告诉服务器将会使用一个密码来登录, 如果所要登录的用户名密码为空, 可以忽略此选项。 如果我们要登录本机的 MySQL 数据库，只需要输入以下命令即可：mysql -u root -p输入 exit 或 quit 退出登录。 mysql重点内容mysql优化如何定位慢查询 - 聚合查询 - 多表查询 - 表数据量过大 - 深度分页查询 开源工具 调试工具：Arthas 运维工具：Skywalking Mysql自带慢日志 1234#开启mysql慢日志查询slow_query_loh=1#设置慢日志的时间为2秒，sql语句执行时间超过2秒。就会使为慢查询，记录慢查询日志（/var/lib/mysql/localhost-slow.log）long_query_time=2 优化sql语句慢查询&gt; - 聚合查询 &gt; - 多表查询 &gt; - 表数据量过大 以上可以通过sql的执行计划解决。 采用explain或者desc命令获取select语句信息 字段解析 possible_key：当前sql可能会用到的索引 key：sql实际命中的索引 key_len：索引占用的大小（两者结合可以检查索引是否命中 即索引本身存在是否有时效的情况） extra：额外的&#x3D;&#x3D;优化建议&#x3D;&#x3D; using where、using index ：查找使用了索引，使用的数据都在索引列，不需要回表查询数据 using index condition ：查找使用了索引，但需要回表查询数据（有优化的空间） type：sql连接类型。性能&#x3D;&#x3D;由好到差&#x3D;&#x3D;：NULL、system、const、eq_ref、ref、range、index、all system：查询系统表 const：根据主键查询 eq_ref：主键索引查询或唯一索引查询 ref：索引查询 range：范围查询 index：索引树扫描（需优化） all：全盘扫描（需优化） 索引 什么是索引 帮助mysql高效获取数据的数据结构（有序）。 提高数据检索的效率，降低数据库的io成本 通过索引对数据进行排序，降低数据排序的 成本，降低了cpu的消耗 innodb引擎（MySQL默认引擎）采用B+树数据结构存储索引 阶数更多，路径更短 磁盘读写代价更低，非叶子节点只存储指针，叶子节点存储数据 更便于扫库和区间查询，叶子节点是一个双向链表 B+树和B树对比优点 磁盘读写代价更低 查询效率更稳定：都要扫到叶子节点才能找到数据 便于扫库和区间查询 ：叶子节点之间有双向指针，可以顺序检索 聚簇索引（聚集索引）和非聚簇索引（二级索引） 聚簇索引（聚集索引）：数据和索引在一起。必须有，且只有一个。保存整行数据 主键 无主键则选（unique）唯一索引 若1 2都无，数据库会自动创建id 非聚集索引（二级索引）：数据和索引分开存储。可以有多个。只保存主键值 （需要根据主键进行回表查询才能找到整条数据） 如：将name设置为二级索引 那么name为anna的索引存储的就是anna的id 10 回表查询：一般走二级索引情况下会需要回表查询 覆盖索引：查询使用了索引，且需要返回的列在该索引中全部可以找到（&#x3D;&#x3D;非覆盖索引需要回表查询&#x3D;&#x3D;） &#x3D;&#x3D;MySQL超大分页的处理&#x3D;&#x3D;：数据量比较大时，使用limit分页查询，需要对数据进行排序，越往后的页需要对数据效率越低 优化：覆盖索引+子查询 123456//查询id第9000000-9000010共10条数据select * from tb_user limit 9000000,10;//会对前9000010条数据全部排序，然后截取9000000-9000010共10条数据//覆盖索引+子查询优化select * from tb_user t (select id from tb_user order by id limit 9000000,10)a //此处为覆盖查询，会比非覆盖查询快得多）where t.id = a.id; 索引创建原则 &#x3D;&#x3D;数据量大，查询频繁。单表超10w，增加用户体验感&#x3D;&#x3D; &#x3D;&#x3D;常常作为查询条件where、排序（order by）、分组（group by）操作的字段&#x3D;&#x3D; 区分度高的列，尽量建立唯一索引。区分度越高，索引效率越高 字符串字段，字段较长，针对字段特点建立前缀索引 &#x3D;&#x3D;尽量使用联合索引，减少单列索引&#x3D;&#x3D;。联合索引更多的可以实现覆盖查询，避免回表 &#x3D;&#x3D;控制索引的数量&#x3D;&#x3D;。索引越多维护成本也越大 若索引不能存null值，创建表时使用not null约束 - 主键索引 - 唯一索引 - 根据业务创建的复合索引 什么时候索引失效 &#x3D;&#x3D;复合索引或联合索引时&#x3D;&#x3D;，&#x3D;&#x3D;违反最左前缀法则&#x3D;&#x3D;。查询使用的索引从最左开始写，不能跳过索引列 &#x3D;&#x3D;范围查询 右边的列&#x3D;&#x3D;索引会失效 不要在&#x3D;&#x3D;索引列上进行运算操作&#x3D;&#x3D;，否则失效 &#x3D;&#x3D;字符串不加单引号&#x3D;&#x3D;。主要是由于发生类型的转换而导致失效 以%开头的like&#x3D;&#x3D;模糊查询&#x3D;&#x3D;，可能失效 %在头部会失效，如%小学% %在尾部不会失效，如小学% sql优化经验 表的设计 （阿里开发手册《嵩山版》）如： 设置合适的数值 设置合适的字符串类型char定长效率高，varchar可变长，效率低 索引（参考索引part） sql语句 **避免使用select *** 避免造成索引失效 尽量用union all（可能会查出显示重复数据）代替union 。union all会把两次查询所有结果都留下，但union会多一次过滤去删除重复的数据 避免在where子句中对字段进行表达式操作，以免索引失效 join优化。能用innerjoin就不用left join&#x2F;rignt join，如果必须要用就以小表为驱动，内连接会对比两个表，优先把小表放外边；而left join&#x2F;rignt join就不会调整顺序 主从复制（主要解决访问压力）、读写分离(若无相关项目 了解即可)：数据库读的操作较多时，为了避免操作造成的性能影响，可以使用读写分离解决数据库写入影响查询效率的问题 分库分表: 解决存储压力 前提：项目业务数据逐渐增多，或业务发展比较迅速 单表数据量达到1000w或20G以后 优化已解决不了性能问题（主从读写分离、查询索引…） IO瓶颈（磁盘IO、网络IO）、CPU瓶颈（聚合查询、连接数太多） 拆分原则(若无相关项目 了解即可) 垂直分库：以表为依据，根据不同的业务将不同的表放到不同的库中 如：用户、订单、商品三个微服务 特点一：按业务对数据分级管理、维护、监控、扩展 特点二：在高并发下，提高磁盘IO和数据量连接数 垂直分表：以字段为依据，根据字段属性将不同字段拆分到不同的表中 拆分原则：把不常用的单独放在一个表中；把text、blob等大字段差分出来放在附表中 特点一：冷热数据分离 特点二：减少IO过度争抢，两表互不影响 水平分库：将一个库的而数据拆分到多个库中（如 数据库user1 数据库user2 数据库user3 都是存储的user的相关表 只是范围&#x2F;分类…不一样 ） 特点一：解决了单库大数量，高并发的性能瓶颈问题 特点二：提高了系统的稳定性和可用性 水平分表：将一个表的数据拆分到多个表中（可以在一个库中 如user数据库中有 tb_order1 tb_order2 tb_order3 都是存储的order信息 只是信息范围&#x2F;分类…不一样） 特点一：优化单一数据量过大而产生的性能问题 特点二：避免IO争抢并减少锁表的几率 策略： mycat sharding-sphere 事务事务是一组操作的集合，是不可分割的工作单位，事务会把所有操作作为一个整体一起向系统提交或撤销操作请求。要么同时成功，要么同时失败 事务特性（ACID）​ 以转账为案例理解 原子性（Atomicity）:事务是不可分割的最小操作单元。通过undo log（回滚日志） 来保证的 一致性（Consistency）：事务完成后数据保持一致状态。通过持久性+原子性+隔离性来保证 隔离性（Isolation）：事务在不受外部并发操作的影响下独立运行。通过 MVCC（多版本并发控制） 或锁机制来保证的 持久性（Durability）：持久化。事务一旦完成或者回滚，对数据库的数据的改变是永久的。通过redo log（重做日志）来保证的 隔离级别并发事务问题严重性： 脏读(一个事务读取到了另外一个食物还没提交的数据)&gt;不可重复读(一个事务先后读取同一条数据的结果不同)&gt;幻读(一个事务按照条件查询数据时，没有对应数据，但是在插入数据时，这条数据又出现了，就好像“幻影”) 读未提交：解决不了问题 读已提交：可解决脏读 可重复读：虽然未彻底解决幻读（&#x3D;&#x3D;Innodb默认隔离级别&#x3D;&#x3D;），但很大程度上避免了幻读 快照读（普通select查询）：由 &#x3D;&#x3D;MVCC（多版本并发控制）&#x3D;&#x3D;实现。 实现的方式是开始事务后（执行 begin 语句后），在执行第一个查询语句后，会创建一个 Read View 后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据 所以事务过程中每次查询的数据都一样 即使中途有其他事务插入了新纪录，是查询不出来这条数据的，这样就很好了避免幻读问题 当前读（除了普通查询是快照读，其他都是当前读）：next-key lock临键锁（即记录锁+间隙锁）。 串行化：可解决所有问题，但串行效率低，性能差 隔离水平由1-4逐渐增加，数据越安全，但性能也越差 MVCC（多版本并发控制）维护一个数据的多个版本，使得读写操作没有冲突 如何实现？以下1-4点 隐藏字段 DB_TRX_ID：最近修改事务id DB_ROLL_PIR：回滚指针，指向undo log中这条记录的最新版本(已提交的修改操作)，undo log中最新的数据记录会指向上一个版本的记录（如果有） DB_ROW_ID：隐藏主键，若表没有主键，将会生成该隐藏字段 undo log 逻辑日志。更新操作时候会生成相反操作的命令 insert时的undo log日志只在回滚时需要，在事务提交后会被立即删除 update和delete时的undo log日志不仅在回滚时需要，MVCC版本访问也需要，所以不会被立即删除 undo log版本链 undo log中最新的数据记录会指向上一个版本的记录（如果有），进而形成一个版本链表。链表头部是最新的旧版本，尾部是最早的旧版本 readview（读视图） readview：是快照读sql执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id 主要字段： m_id : 在创建readview时,当前数据库的活跃事务的id集合[活跃事务: 启动了 但还没有提交事务] min_trx_id: 活跃事务中最小的事务id max_trx_id: 全局事务中最大的事务id+1 creator_trx_id:创建该readview的事务id 拓展：innoDB存储引擎的&#x3D;&#x3D;数据表中&#x3D;&#x3D;的&#x3D;&#x3D;聚簇索引&#x3D;&#x3D;有两个隐藏字段 &#x3D;&#x3D;trx_id&#x3D;&#x3D;: 当一个事务对某条聚簇索引进行改动时，就会把该事务的id记录到trx_id中 roll_pointer: 每次对某条聚簇索引进行改动时，都会把旧版本的记录写入undo日志，然后这个隐藏列是个指针，指向每一个旧版本记录，可以找到修改前的记录 从数据库表中记录的最新版本【即数据库表隐藏字段trx_id的当前值，如果不可访问则推向前一个版本】开始判断能访问到undo log的哪个版本的数据 一个事务去访问记录时，版本访问规则： 1234567trx_id == creator_trx_id 可以访问该版本 ==&gt;说明这个版本就是当前事务自己更新记录trx_id &lt; min_trx_id 可以访问该版本 ==&gt;说明这个版本是在创建Readview之前已提交的事务生成的trx_id &gt; max_trx_id 不可以访问该版本 ==&gt;说明这个版本是在创建readview之后才开启的事务生成的min_trx_id &lt;= trx_id &lt;= min_trx_id trx_id在m_id中:不可以访问该版本 ==&gt;说明该版本记录的活跃事务仍活跃 trx_id不在m_id中:可以访问该版本 ==&gt;说明该版本记录的活跃事务已经被提交 当前读 共享锁、排它锁操作就是当前读 读取是当前记录的最新版本 通过next-key lock(记录锁+间隙锁)解决了幻读 快照读 普通的select就是快照读 通过MVCC解决了幻读 读提交：每次select都会生成一个readview 可重复读：每次事务启动时生成一个readview，然后整个事务都用这个readview 日志 redo log与undo log区别？ redo log 是物理日志，记录的是数据的物理变化。 事务完成后的数据状态。commit时由于服务宕机而失败时用来同步数据 保证数据的持久性 undo log 逻辑日志，事务回滚时，通过逆操作恢复数据 事务开始前的数据状态 保证数据的原子性和一致性 拓：事务的隔离性是如何实现的？MVCC？参考上述part 为什么需要buffer pool？与redo log怎么配合使用？ 为什么需要redo log？ 为什么需要undo log？锁 全局锁 表级锁 表锁 元数据锁（MDL） 意向锁 AUTO-INC 锁 行级锁的三大类型： Record Lock：记录锁。仅仅把一条记录锁上 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）; 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。 Gap Lock：间隙锁。锁定一个范围，但是不包含记录本身。（只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。） Next-Key Lock：Record Lock + Gap Lock的组合。锁定一个范围，并且锁定记录本身","comments":true,"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://example.com/tags/Mysql/"}]},{"title":"java基础学习","date":"2019-08-06T00:18:12.000Z","path":"2019/Java学习（基础补缺版）/","text":"目录 目录 第一章 java语言概述 文档注释 API文档的说明 Java的语言特点 JVM 第二章 变量与运算符 关键字 标识符 变量 基本数据类型变量间的转化 String类型 运算符 第三章 流量控制第一章 java语言概述文档注释 例如： 1234567/** 这是文本注释(java特有的) 可以被 javadoc 所解析生成一套以网页文件形式体现的该程序的说明文档 @author loumeng @version 1.0*/ 使用命令： javadoc -d mkdir -author -version 文件名.java 创建文件夹为mkdir的网页文件夹 API文档的说明 API（Application programming interface，应用程序编程接口） Java的语言特点 跨平台 面向对象 健壮性 安全性高 简单性 高性能 JVM 实现java的跨平台性 自动内存管理：GC自动回收 内存溢出 内存泄露 第二章 变量与运算符关键字 全是小写 goto contes 保留字 标识符 可以自定义的地方、 类名，包名。。。 命名规则 （否则编译会报错） &#x3D;&#x3D;”自洽”&#x3D;&#x3D; 26字母大小写开头，0-9，_ 或$ 组成 数字不可以开头 不可以使用但可以包含关键字或者保留字 java严格区分大小写 长度无限制 标识符不能包含空格 命名规范 包名：多单词组成时字母都小写 类名、接口名：多单词组成时，所有单词的首字母大写 变量名、方法名：多单词组成时，第一个的单词首字母小写，第二个及以后的每个单词首字母大写 常量名：所有字母都大写，多单词时每个单词用下划线连接 变量 整型变量 byte 1字节 &#x3D; 8 bit short 2字节 int(&#x3D;&#x3D;常量默认为int&#x3D;&#x3D;) 4字节 long 8字节 。赋值最后用小写或者大写的L结尾。例如：long l1 = 12138L 或者 long l1 = 12138l 浮点类型变量 float 4字节 赋值最后用小写或者大写的F结尾。例如：float f1 = 12138F 或者 float f1 = 12138f double 8字节 通过测试 浮点型数据精度不高 如果需要极高的精度 使用BigDecimal类替换浮点型变量 bool类型 字符类型 char 基本数据类型变量间的转化注：不包含boolean类型 123运算规则 1. 自动类型提高 2. 强制类型转换 自动类型提升 byte &lt; short &lt; int &lt; long &lt; float &lt; double &#x3D;&#x3D;调用方法时候传参是自动类型转换&#x3D;&#x3D;，而不是强制类型转换 规则：当容量小的变量与容量大的变量做运算时，结果自动转换为容量大的变量数据类型（&#x3D;&#x3D;大转小编译不通过&#x3D;&#x3D;） 强制类型提升 例如： 12345long l1 = 123L;short s1 = (short)l1;是可以通过编译的 规则：当容量小(或者大)的变量与容量大(或者小)的变量做运算时，结果强制转换为容量大(或者小)的变量数据类型（&#x3D;&#x3D;主要用于大转小&#x3D;&#x3D;，但精度可能会丢失） String类型 属于引用类型 可以使用双引号的方式进行复制 可以包含0或者1个或者多个字符 包括Boolean在内的8种都可以转 可以直接通过”+”进行运算 运算结果肯定是 String类型 无法转换为基本数据类型 只能转换为其他引用数据类型 运算符 按功能 算数运算符(7个)： +、-、*、&#x2F;、%、++（前&#x2F;后）、–（前&#x2F;后） 赋值运算符(12个)： &#x3D;、+&#x3D;、-&#x3D;、&#x2F;&#x3D;、%&#x3D;、&gt;&gt;&#x3D;、&lt;&lt;&#x3D;、&gt;&gt;&gt;&#x3D;、&amp;&#x3D;、|&#x3D;、^&#x3D;等 比较（关系）运算符(6个)： &gt;、&gt;&#x3D;、&lt;、&lt;&#x3D;、&#x3D;&#x3D;、|| 逻辑运算符(6个)： &amp;、|、^、！、&amp;&amp;、|| &amp;和| 两个条件无论第一个条件是否通过都需要运行第二个条件 &amp;&amp;和|| 两个条件第一个条件已经不符合则直接跳过，不再对第二个条件进行运行判断 位运算符(7个)：&amp;、|、^、~、&lt;&lt;、&gt;&gt;、&gt;&gt;&gt; 条件运算符(1个)：&#x3D;&#x3D;(条件表达式)？结果1：结果2&#x3D;&#x3D; 如果表达式结果为true，则执行结果表达式1，否则执行结果表达式2 凡是可以使用条件运算符的位置，都可以使用if-else，反之则不然 &#x3D;&#x3D;建议：二者都能使用的时候使用条件运算符，执行效率稍快&#x3D;&#x3D; Lambda运算符(1个)：-&gt; 按操作数个数 一元运算符（单目运算符）: +、-、++、–、！、~ 二元运算符（双目运算符） 三元运算符（三目运算符）: (条件表达式)？结果1：结果2 第三章 流量控制 if-else结构 Scanner类 switch-case for循环 while循环和do-while循环 无限循环结构和嵌套循环的使用","comments":true,"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"}]},{"title":"Oracle学习笔记","date":"2019-06-06T03:15:12.000Z","path":"2019/OracleNotes/","text":"目录 目录 第一章 ： 数据库的安装以及配置 登录方式： 修改密码： 解锁用户： 锁定用户： 在进行网络配置的时候出现：ORA-12514: TNS:监听程序当前无法识别连接描述符中请求的服务解决方案 命令行用户登录： 在SQL Plus中可以执行SQL语句和SQL Plus命令: 第二章 ： 系统结构： 物理结构 逻辑结构 数据块(多个)–&gt;区(多个)–&gt;段(多个)–&gt;表空间(多个)–&gt;数据库 内存结构 进程结构 Oracle进程结构 Oracle例程后台进程 数据字典 数据字典的分类： 第五章 用户管理 物理存储结构的规划 逻辑存储结构的规划 表空间 1.创建表空间 修改表空间 表空间删除 查询表空间信息 数据文件设置与管理 数据文件 创建数据文件 修改数据文件大小 改变数据文件的可用性 改变数据文件的名称和位置 查询数据文件信息 控制文件设置与管理 补充：oracle的启动状态 实现多路复用控制文件 删除控制文件 第六章 模式 约束与参数 PRIMARY KEY：主键约束 惟一性约束：UNIQUE PRIMARY KEY与UNIQUE比较 检查约束 外键约束：FOREIGN KEY 空&#x2F;非空约束：NULL&#x2F;NOT NULL 参数 参数（parameter_list） 索引 序列 分区 分区概念 对巨型表进行分区具有下列优点： 范围分区： 列表分区 散列分区 复合分区 第七章 数据操纵与事务处理 第一章 ： 数据库的安装以及配置登录方式：1）普通用户：system&#x2F;密码2）系统管理员：conn sys&#x2F;密码 as sysdba; 修改密码： 先登录sys用户 alter user 用户名 identified by 密码在知道自己的密码情况下可以直接使用password命令直接修改密码 解锁用户： 先登录sys用户 alter user 用户名 account unlock; 锁定用户： 先登录sys用户 alter user 用户名 account lock; 在进行网络配置的时候出现：ORA-12514: TNS:监听程序当前无法识别连接描述符中请求的服务解决方案解决方案： 配置监听器 配置listener.ora 此目录下：F:\\app\\windows\\product\\11.2.0\\dbhome_1\\NETWORK\\ADMIN 在里面添加如下内容： 123456789101112131415161718 (SID_LIST = (SID_DESC = (SID_NAME = CLRExtProc) (ORACLE_HOME = F:\\app\\windows\\product\\11.2.0\\dbhome_1) (PROGRAM = extproc) (ENVS = &quot;EXTPROC_DLLS=ONLY:F:\\app\\windows\\product\\11.2.0\\dbhome_1\\bin\\oraclr11.dll&quot;) ) //添加部分，ORCL为实例名 (SID_DESC = (GLOBAL_DBNAME = ORCL) (ORACLE_HOME = F:\\app\\windows\\product\\11.2.0\\dbhome_1) (SID_NAME = ORCL) ) ) 重启服务 sys:系统管理员，不能以normal身份登录 system：普通用户sqlplus sys&#x2F;Lm20191103@orcl as sysdba 命令行用户登录： system登录: sqlplus system/system@orcl sys登录: sqlplus sys/sys@orcl as sysdba scott登录: sqlplus scott/scott@orcl sQL&gt;select * from scott.emp; SQL &gt;select name from V$database; 1231. SYS:当创建个数据库时，SYS用户 将被默认创建并授予DBA角色。(常用 )4. SYSTEM:与SYS一样，在创建Oracle数据库时,SYSTEM用户被默认创建并被授予DBA角色，用于创建显示管理信息的表或视图，以及被各种Oracle数据库应用和工具使用的内容表或视图。(常用)5. SCOTT, 一个测试用户，基本没有什么权限。 1. 最重要的区别，存储的数据的重要性不同sys: sys是超级用户。 所有Oracle的数据字典的基表和视图都存放在sys用户空间中，这些基表和视图对于Oracle的运行是至关重要的，由数据库自已维护，任何用户都不能手动更改。 sys用户自动创建，拥有dba,sysdba,sysoper等角色或权限，是Oracle权限最高的用户。 system: system:数据库内置的普通管理员。 system用户空间用于存放次一级的内部数据，如Oracle的 一些特性或工具的管理信息。 system用户自动创建，拥有dba, sysdba 等角色或系统权限。 2. 其次的区别，权限的不同。 最直接的区别： sys 可以创建数据库，而system不可以。 sys用户必须以as sysdba形式登录。 sysdba属于system privilege,也称为administrative privilege,拥有例如数据库开启关闭之类些系统管理级别的权限。 在SQL Plus中可以执行SQL语句和SQL Plus命令:123451. SQL语句不区分大小写。2. SQL语句可输入在一行或多行中。3. 关键字不能缩写，也不能跨行分开写。4. 子句通常放在单独的行中。应使用缩进来提高可读性。5. 在SQL*Plus 中，必须使用分号(;) 结束每条SQL语句。 连接命令： conn[ect] 用法: conn 用户名&#x2F;密码@网络服务标识[as sysdbal&#x2F;sysoper] 当用特权用户身份连接时，必须带上as sysdba或as sysoper 如: 12345SQL &gt;connect sys/sys@orcl as sysdba; SQL &gt;conn system/system; SQL &gt;conn scott/tiger; 编辑命令: List: 显示缓冲区内容(显示上一条命令) 语法格式: L[ist] 12345SQL&gt;L SQL&gt;L 2 SQL&gt;L 1 2 Append语句:向缓冲区中的当前行尾部添加指定的文本 语法格式: append text Change：修改缓冲区文本 语法格式：change &#x2F;old&#x2F;new run(&#x2F;) : 执行缓冲区中的SQL语句 举例: System登录显示scott.emp表内容。 1234567 SQL&gt;conn system/system SQL&gt;select * from empSQL&gt;ListsQL&gt;runSQL &gt;change lemp/scott.empSQL &gt;list SQL &gt;run 因为行编辑麻烦，所以使用Edit命令编辑缓冲区。Edit命令打 开Notepad对缓冲区的内容进行操作编辑。 SQL&gt;Edit save命令把当前SQL缓冲区的内容保存到指定的文件当中。save的语法是:SAV[E] [FILE] file_ name [Create] | [REPLACE]|[APPEND] Append表示把当前的内容添加到已经存在的文件中。 Replace表示覆盖当前已有的文件。默认的扩展名是.sql 例子： SQL&gt;select * from scott.emp; SQL&gt;save e:\\SQL_employee.sql 把当前缓冲区中的内容存到文件SQL_employee.sql中 get命令把文件内容调入缓冲区。 get的语法是：get filename [LIST] [NOLIST] SQL&gt;get e:\\SQL_employee.sql Edit命令也可以打开编辑指定的sq|脚本: SQL &gt;edit e:\\SQL_employee.sql; Start和@命令调用执行脚本文件。 start命令语法: start filename [arg1 arg2..] SQL&gt;start e:\\sql_employee.sql @命令语法: @filename [arg1 arg2..] SQL&gt;@e:\\sql_employee.sql 两个命令的差别在于: start的只能在Sqlplus会话内部使用 @命令既可以在会话内部运行，也可以在启动sqlplus时的命令行级别运行。 spool 命令 格式: spool filename 说明:该命令可以把sq|*plus屏幕上的内容输出到指定文件，包括你输入的sq|语句及其执行结果。123 SQL&gt;spool d:\\screen.txtSQL &gt;select * from scott.emp;SQL&gt;spool off; (只有关闭spool输出，才会在输出文件中看到输出的内容) 如在d:\\b.sql,建立文本文件，内容有select * from emp;以及输出结果。 describe命令返回存储对象的描述。 sQL&gt;desc 表名; 显示表结构 环境变量的显示与设置命令 显示: SQL &gt;show al SQL &gt;show linesize pagesize 设置: SQL&gt;set linesize 100 pagesize 20 SQL &gt;show linesize pagesize pagesize :设置一页显示的行数。在默认情况下，该值为14 linesize:设置一行的字符数量， 默认值为80。 pause:查询的结果超过-次屏幕，设置Pause值 使其暂停显示，直到用户按Enter键继续，默认值为OFF， 用SET PAUSE ON[OFF]命令设置。 例子：SQL&gt; SET PAUSE ON[OFF] 用户加锁：alter user scott account lock;用户解锁：alter user scott account unlock; 修改密码为tiger：alter user scott identified by tiger; 第二章 ： 系统结构： 数据库服务器的主要组成以及这些组成部分之间的联系和操作方式。 服务器：磁盘上的数据库（DB）和对磁盘上的数据进行管理的数据库管理系统（） DB：对应数据库的的存储结构 Oracle数据库存储结构分为： 物理存储：数据库在操作系统中的数据组织与管理方式。文件、数据块 逻辑存储：数据库在数据库系统内部的数据组织与管理方式。数据表等关系：一般物理储存结构变现为一系列文件形式，是可见的；逻辑存储结构是对物理存储结构的组织一管理，一般是不可见的。 数据库：是用于保存数据的一系列物理结构和逻辑结构 软件结构（实例）：DBMS的运行方式。包括：内存结构和后台运行。在服务器运行过程中内存结构 和一些列 进程 组成的。每个运行的Oracle数据库都对应一个Oracle例程，成为实例 总结:Oracle数据库服务器由数据库和实例组成数据库和实例的关系：数据库是Oracle用于保存数据的一系列物理结构和逻辑结构用户直接与实例交互，由实例访问数据库。每个数据库至少有一个与之对应的实例 物理结构 数据文件(.DBF)：用于储存数据库中所有数据； 控制文件(.CTL)：用于记录和描述数据库的物理存储结构信息 （重做）日志文件(.log)：用于记录外部程序（用户）对数据库的修改操作 初始化参数(.ORA):用于设置数据库启动时参数初始值; 跟踪文件:用于记录用户进程、数据库后台进程的运行情况; 归档文件(.ARC) :用于保存已经写满的重做日志文件 口令文件:用于保存具有SYSDBA, SYSOPER权限的用户名和SYS用户口令 逻辑结构数据库的逻辑结构是面向用户的，描述了数据库在逻辑上是如何组织和存储数据,数据库的逻辑结构支配一一个数据库如何使用其物理空间。 数据块(多个)–&gt;区(多个)–&gt;段(多个)–&gt;表空间(多个)–&gt;数据库 数据块：最小的逻辑存储单元（即最小的I&#x2F;o读写单元）。分为标准块和非标准块两种。 由数据库初始化参数 DB_BLOCK_SIZE 设置，大小不变。 &#x3D;&#x3D;区&#x3D;&#x3D;：由一系列连续的数据块构成的逻辑存储单元，是存储空间分配的最小单元。（例：空表也会被分配一个区） &#x3D;&#x3D;段&#x3D;&#x3D;：由一个或多个连续或不联系的区组成的逻辑存储单元。分类：表段、索引段、临时段、回退段 &#x3D;&#x3D;表空间&#x3D;&#x3D;：Oracle数据库最大的逻辑存储单元。由多个段组成。一个表空间可以对应若干 数据文件（属于物理逻辑存储结构）。 表空间分类： 系统表空间 非系统表空间：撤销表空间、临时表空间、用户表空间 物理和逻辑存储结构的对应关系:Oracle数据库的物理存储结构与逻辑存储结构之间的基本关系: 一个数据库在物理上包含多个数据文件，在逻辑上包含多个表空间。 一个表空间包含一个或多个数据文件，一个数据文件只能从属于某个表空间。 数据库的逻辑块由一个或多个操作系统块构成。一个逻辑区只能从属于一个数据文件，而一个数据文件可包含一个或多个逻辑区 内存结构 系统全局区SGA：是一组共享内存结构 数据高速缓冲区（Data Buffer Cache）： 在数据缓冲区中被修改后的数据由数据写入进程(DBWR)写到硬盘的数据文件中永久保存。 提高获取和更新数据的性能 大小：DB_CACHE_SIZE 数据高速缓冲区越大，用户需要的数据在内存中的可能性越大，即缓存命中率高，从而减少了Oracle访问硬盘数据的次数，提高数据库系统执行的效率。需要确定一个合理的数据数据缓冲区的大小。 缓冲块的类型: 脏缓存块(Dirty Buffers) :脏缓存块中保存的是已经被修改过的数据。 空闲缓存块(FreeBuffers):空闲缓存块中不包含任何数据，它们等待后台进程或服务器进程向其中写入数据。 命中缓存块(PinnedBuffers):命中缓存块是那些正被使用的数据块，同时还有很多会话等待修改或访问的数据块。 干净缓存块(CleanBuffers):干净缓存块是指那些当前没有被使用，即将被换出内存的缓存块。 重做日志缓冲区： 存放数据库事务提交的操作信息，这些信息对数据库的恢复有着重要作用。当重做日志缓冲区被添满时，由日志写入进程把重做日志缓冲区的内容写到磁盘的重做日志文件中保存。 大小：log_buffer log_ buffer值越 大，重做日志缓冲区就可以存放更多的事务提交的记录，减少了数据被频繁写入到重做日志文件中的次数。 共享池：库高速缓存、数据字典高速缓存 功能：用于缓存与sql和pl&#x2F;sql语句、数据字典、资源锁以及其他控制结构相关数据 组成： 库缓存：用于缓存已经解释并执行过的sql语句和pl&#x2F;sql程序代码，以提高sql或pl&#x2F;sql程序的执行效率；包括sql工作区和pl&#x2F;sql工作区 数据字典缓存区：保存最常用的而数据字典信息。如：数据库对象信息、账户信息、数据库结构信息等。 大小：SHARED_POOL_ SIZE 合适的共享池大小，可使编译过的程序代码长驻内存，大大降低重复执行相同的SQl语句、PL&#x2F;SQL程序的系统开销，从而提高数据库的性能。 大型池(Large Pool)：用于缓冲大型 I&#x2F;O 请求的可选区域，以便支持并行查询、共享服务器、Oracle XA 以及某些类型的备份操作 流池(stream Pool)：由 Oracle Streams 使用 java池(Java Pool)：用于存放 Java 虚拟机 (JVM) 中特定于会话的 Java 代码和数据 程序全局区PGA（大小和SGA相比小很多，通常不讲）：保存用户私有的 排序区： 游标信息区： 会话信息区 堆栈区 进程结构Oracle进程结构 进程的概念:进程是操作系统中一个独立的可以调度的活动，用于完成指定的任务。 进程与程序的区别在于: 进程是动态的概念，即动态创建，完成任务后立即消亡而程序是一个静态实体。 进程强调执行过程，而程序仅仅是指令的有序集合。 用户进程 服务器进程(Server process):服务器进程是接收用户进程信息，并根据请求与数据库进行通信。这些通信实现数据操作，完成用户对数据库数据的处理要求。 服务器进程主要完成以下任务: 解析并执行用户提交的sql语句及PL&#x2F;sql程序; SGA的数据高速缓冲区中搜索用户进程所要访问的在数据，如果数据不在缓冲区中，则需要从硬盘数据文件中读取所需的数据，再讲它们复制到缓冲区中; 将用户改变数据库的操作信息写入日志缓冲区中; 将查询或执行后的结果数据返回给用户进程; 后台进程: 为了保证Oracle数据库在任意一个时刻可以处理多用户的并发请求，进行复杂的数据操作，而且还要优化系统性能，Oracle数据库起用了一些相互独立的附加进程，称为后台进程。服务器进程在执行用户进程请求时，调用后台进程来实现对数据库的操作。 后台进程主要完成以下任务: 在内存与磁盘之间进行I&#x2F;0操作; 监视各个服务器进程状态; 协调各个服务器进程的任务; 维护系统性能和可靠性等。 Oracle例程后台进程 数据库写入进程(DBWR ) 日志写入进程(LGWR) 日志归档进程(ARCH) 查点进程(CKPT) 系统监控进程(SMON) 进程监控进程(PMON)等 1.&#x3D;&#x3D;数据库写入进程(DBWR)&#x3D;&#x3D; 数据库写入进程(databasewriter,DBwr)将缓冲区里的数据写入到数据文件。数据库写入进程的作用是将已更改的数据块从内存写入数据文件。使缓冲区有更多的空闲缓冲块，保证服务进程将所需要的数据从数据文件中读取到数据高速缓冲区，提高缓存命中率。 默认情况下，启动例程时只启动了一个数据库写入进程，即为DBW0 初始化参数DB_ WRITER PROCESSES最多定义20个数据库写入进程执行写入操作 每个数据库写入进程都分配了09或aj编号 2.日志写入进程(LGWR) 日志写入进程负责把重做日志缓冲区的数据写入重做日志文件中永久保存。 数据库写入进程在工作之前，需要了解日志写入进程是否已经把相关的日志缓冲区中记载的数据写入重做日志文件中，如果相关的日志缓冲区中的记录还没有被写入，DBWR会通知LGWR完成相应的工作，然后DBWR才开始写入。 检查点进程（CKPT） 检查点是一个事件，当该事件发生时（每隔一段时间发生），&#x3D;&#x3D;DBWR&#x3D;&#x3D;进程把数据高速缓冲区中&#x3D;&#x3D;脏缓存块&#x3D;&#x3D;写入数据文件中，同时Oracle将对数据库控制文件和数据文件的头部的&#x3D;&#x3D;同步序号&#x3D;&#x3D;进行更新，以记录下当前的数据库结构和形态，以确保数据文件、控制文件和重做日志文件的一致性 SMON 功能：在 启动时负责对数据库进行恢复 回收不再使用的临时空间 将各个表控件的空闲碎片合并 PMON（进程监控进程） 日志归档进程（ARCH） 归档进程负责在日志切换后将已经写满的重做日志文件复制到归档目标中，防止写满的重做日志文件被覆盖 最多可启动十个归档进程 该后台进程只有在ARCHIVELOG(归档日志)模式下才有效 默认情况下只有两个归档日志进程(ARC0和ARC1)7. 数据字典 在数据库创建按过程中创建的，保存了数据库系统信息以及数据库中所有的对象信息，是数据库运行的技术 一系列的表和视图，这些表和视图对于所有的用户(包括DBA)，都是只读的 只有Oracle系统可以对数据字典进行管理与维护 在Oracle数据库中，所有数据字典表和视图都属于sys模式，存储于system表空间中 Oracle数据字典保存数据库本身的系统信息及所有数据库对象信息，包括: 各种数据库对象的定义信息，包括表、视图、索引、同义词、序列、存储过程、函数、包、触发器及其他各种对象; 数据库存储空间分配信息，如为某个数据库对象分配了多少空间，已经使用子多少空间等; 数据库安全信息，包括用户、权限、角色、完整性等; 数据库运行时的性能和统计信息; 其他数据库本身的基本信息。 数据字典的主要用途： 通过访问数据字典获取用户、模式对象、数据库对象定义与存储等信息，以判断端用户权限额合法性、模式对象的存在性以及存储空间的可用性 使用ddl语句修饰修改数据库队形后，将在数据字典中记录所做的修改 在任何数据库用户都可以从数据字典只读视图中任何数据库用户都可以从数据字典只读视图中获取各种数据库对象信息; DBA可以从数据字典动态性能视图中获取数据库的运行状态，作为进行性能调整的依据。 维护与管理： DDL：如增加或者减少表空间，增加或减少用户。 DCL：如授予用户权限，回收用户权限。 DML：某些DML语句，如引起表空间扩展的插入、修改语句 数据字典的分类： 数据字典结构分为: 数据字典表和数据字典视图 静态数据字典视图 通过对静态数据字典表进行解密和处理，创建了一系列用户可读的静态数据字典视图。在数据库创建过程中，通过自动运行catalog.sql脚本创建静态数据字典视图及其公共同义词，并进行授权 动态数据字典视图 在动态性能表上创建的视图称为动态数据字典视图，又称为动态性能视图。所有动态性能视图命名都以V$开头，Oracle自动为这些视图创建了以V$开头命名的公共同义词，因此动态性能视图又称为“V$视图” 根据数据字典对象的虚实性可分为: 静态数据字典 和 动态数据字典 。 静态数据字典表： 静态数据字典表是在数据库创建过程中自动运行sql.bsq脚本创建的，由SYS用户所拥有，表中信息都是经过加密处理的。静态数据字典表的命名中通常包含$符号。只有Oracle才能读&#x2F;写这些静态数据字典表。 动态数据字典表：动态数据字典表是在数据库实例运行过程中由Oracle动态创建和维护的一系列“虚表”，在实例关闭时被释放。动态数据字典表中记录与数据库运行的性能相关的统计信息，因此又称为动态性能表。通常，动态性能表的命名以X$开头。动态性能表由SYS用户所拥有 查询表dictionary,可以获得全部可以访问的数据字典表或数据字典视图的名称和解释; 查询表dict columns，，可以获得全部可以访问的数据字典表或数据字典视图中的字段名称和解释。 示例 123SQL&gt;SELECT * FROM dictionary;SQL&gt; SELECT * FROM dict columns WHERETABLE NAME=&#x27;USER TABLES&#x27;; 静态数据字典表的使用 静态数据字典表只能由Oracle进行维护，用户不能对这些表进行直接操作。 静态数据字典视图的使用 通常，用户通过对静态数据字典视图的查询可以获取所需要的所有数据库信息。Oracle静 态数据字典视图可以分为3类，各类视图具有独特的前缀。 名称前缀 含义 USER_ 包含了当前数据库用户所拥有的所有模式对象的信息 ALL_ 包含了当前数据库用户可以访问的所有模式对象的信息 DBA_ 包含了所有数据库对象信息，只有具有DBA角色的用户才能够访问这些视图 动态性能表的使用 动态性能表都属于SYS用户，Oracle使用这些表生成动态性能视图。 动态性能视图的使用 动态性能视图是SYS用户所拥有的，在默认情况下，只有SYS用户和拥有DBA角色的用户可以访问。与静态数据字典表和视图不同，在数据库启动的不同阶段只能访问不同的动态性能视图。 第五章 用户管理物理存储结构的规划 规划数据文件。创建数据文件数量，设置文件的大小，扩展方式及文件在磁盘上的分配。规划数据文件的目的是数据库存储应满足业务数据变化的需要。 规划控制文件和重做日志文件。文件的数量，存放位置等。目的是既能形成冗余，避免数据丢失，又能提高系统I&#x2F;O的性能。 将数据库设置成归档模式，及归档路径等相关信息的设置。目的保证当系统出现介质故障时能够完全的进行数据库的恢复。 逻辑存储结构的规划 规划创建多个永久表空间，以便于实现数据的分区管理。 规划创建索引空间，以便于实现索引数据和业务数据的分离。 规划创建临时表空间，以便于对临时信息的管理。 规划创建撤销表空间，以便实现对回退信息的管理。 表空间1.表空间时Oracle数据库中最大的逻辑容器2.一个表空间包含多个数据文件3.数据库容量在物理上有数据文件的大小和数量决定，逻辑上由表空间大小和数量决定 1.创建表空间 在创建本地管理方式下的表空间时，首先应该确定表空间的名称类型、对应的数据文件的名称和位置以及表空间的管理方式、区的分配方式、段的管理方式。 表空间名称不能超过30个字符，必须以字母开头，可以包含字母数字以及一些特殊字符等; 表空间属性: 类型:永久性表空间(PERMANENT TABLESPACE)、临时表空间(TEMP TABLESPACE)、撤销表空间(UNDOTABLESPACE )、大文件表空间( BIGFILE TABLESPACE) 表空间管理方式:字典管理方式(DICTIONARY)和本地管理方式(LOCAL)，默认是本地管理方式 区分配方式:自动分配( AUTOALLOCATE)和定制分配(UNIFORM)，默认是自动分配 段的管理方式:自动管理(AUTO) 和手动管理(MANUAL)，默认是自动管理 12345例4：创建一个永久性的表空间hrtbs4，区定制分配，段采用手动管理方式。SQL&gt; CREATE TABLESPACE hrtbs4 DATAFILE &#x27;d:\\app\\administrator\\oradata\\hrtbs4_1.dbf&#x27; SIZE 50M EXTENT MANAGEMENT LOCAL UNIFORM SIZE 512K SEGMENT SPACE MANAGEMENT MANUAL; 注： EXTENT MANAGEMENT LOCAL :表空间定置管理（可以不写，目前大多默认） 123456 例5：创建一个大文件表空间，文件大小为1G，区的分配采用定制方式。 SQL&gt; CREATE BIGFILE TABLESPACE big_tbs DATAFILE &#x27;d:\\app\\administrator\\oradata\\orcl\\big01.dbf&#x27; SIZE 1G UNIFORM SIZE 512K;``` 注意：大文件表空间中段的管理只能采用自动管理方式，而不能采用手动管理方式。 例6：创建一个临时表空间hrtemp1 SQL&gt;CREATE TEMPORARY TABLESPACE hrtemp1 TEMPFILE ‘d:\\app\\administrator\\oradata\\hrtemp1_1.dbf ‘ SIZE 20M EXTENT MANAGEMENT LOCAL UNIFORM SIZE 15M; 123 例7：创建一个临时表空间hrtemp2，并放入临时表空间组temp_group 。 同时，将临时表空间hrtemp1也放入该temp_group中。 SQL&gt;CREATE TEMPORARY TABLESPACE hrtemp2 TEMPFILE &#39;d:\\app\\administrator\\oradata\\hrtemp2_1.dbf&#39; SIZE 20M EXTENT MANAGEMENT LOCAL UNIFORM SIZE 15M TABLESPACE GROUP temp_group; ALTER TABLESPACE HRTEMP1 TABLESPACE GROUP temp_group; 123456789101112### 修改表空间表空间创建之后，都可以对表空间进行修改，包括： 1. 表空间的扩展 - 添加数据文件 - 改变已有数据文件的大小 - 改变数据文件的可扩展性 - 重新设置数据文件的大小。- 扩展表空间方法一：为表空间添加数据文件- 可以通过ALTER TABLESPACE…ADD DATAFILE语句为永久表空间添加数据文件。- 通过ALTER TABLESPACE…ADD TEMPFILE语句为临时表空间添加数据文件。 例9：向USERS表空间中添加一个大小为10MB的数据文件。 SQL&gt;ALTER TABLESPACE users ADD DATAFILE &#39;d:\\app\\administrator\\oradata\\ users02.dbf&#39; SIZE 10M; 123456789 - 说明： 1. 如果添加的文件不存在，正常增加 2. reuse语句使用是针对已经删除的表空间中的文件（但在操作系统层面没有删除的文件）- 扩展表空间之方法二：改变数据文件的大小1- 可以通过改变表空间已有数据文件的大小，达到扩展表空间的目的。- 如果在创建表空间或为表空间增加数据文件时没有指定AUTOEXTEND ON选项，则该文件的大小是固定的。如果为数据文件指定了AUTOEXTEND ON选项，当数据文件被填满时，数据文件会自动扩展，即表空间被扩展了。 例11：修改USERS表空间数据文件users02.dbf为自动增长方式。 SQL&gt; ALTER DATABASE DATAFILE &#39;d:\\app\\administrator\\oradata\\users02.dbf&#39; AUTOEXTEND ON NEXT 1M MAXSIZE UNLIMITED; 12345678``` 例12：取消USERS表空间数据文件USERS02.DBF的自动增长方式。 SQL&gt;ALTER DATABASE DATAFILE &#x27;d:\\app\\administrator\\oradata\\users02.dbf&#x27; AUTOEXTEND OFF;``` - 扩展表空间之方法三：改变数据文件的大小2- 可以使用`ALTER DATABASE DATAFILE…RESIZE` 改变表空间已有数据文件的大小。 例13：将USERS表空间的数据文件users02.dbf大小设置为8MB。 SQL&gt;ALTER DATABASE DATAFILE &#39;d:\\app\\administrator\\oradata\\users02.dbf&#39;RESIZE 8M; 123456789102. 可用性3. 读/写状态的修改### 表空间删除1. 语法: `DROP TABLESPACE tablespace_name` 1. 如果表空间非空，应带有子句： ` INCLUDING CONTENTS` 2. 若要删除操作系统下的数据文件，应带有子句：`AND DATAFILES`- 示例 （删除表空间，同时删除其所对应的数据文件） SQL&gt;DROP TABLESPACE userdata(//tableSpaceName) INCLUDING CONTENTS AND DATAFILES; 122. 如果其他表空间中的约束（外键）引用了要删除表空间中的主键或者唯一性约束，需要使用`CASCADE CONSTRAINTS`子句删除参照完整性约束，否则删除表空间时会报错。 - 删除hrundo1表空间，同时删除其所对应的数据文件，以及其他表空间中与hrundo1表空间相关的参照完整性约束。 DROP TABLESPACE hrundo1 INCLUDING CONTENTS AND DATAFILES CASCADE CONSTRAINTS; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657### 查询表空间信息1. 表空间信息: - DBA_TABLESPACES - V$TABLESPACE2. 数据文件信息: - DBA_DATA_FILES - V$DATAFILE3. 临时文件信息: - DBA_TEMP_FILES - V$TEMPFILE &gt;表空间描述:&lt;br/&gt; `SQL&gt; SELECT tablespace_name,block_size,initial_extent,max_extents FROM dba_tablespaces;`&gt; ![Oracle图片13](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片13.png)&gt; 查询表空间的名称,区管理方式,存储分配方式,类型等基本信息:&lt;br/&gt; `SELECT tablespace_name,extent_management,allocaton_type,contents FROM dba_tablespaces;`&gt; 查询表空间的数据文件信息:&lt;br/&gt; `SELECT file_name,blocks,tablespace_name FROM dba_data_files;`&gt; 查询数据文件的基本信息:&lt;br/&gt; `SELECT name ,file#,rfile#,status,bytes FROM v$datafile;`&gt; **注： #，表示什么的号，一般为数字列。**### 数据文件设置与管理- 数据文件(Data files)用于存储数据和相关脚本的文件，包括系统数据(数据字典)、用户数据(表、索引、簇等)、撤销(Undo)数据、临时数据等。 - 数据文件存储两种类型的数据：用户数据和系统数据。 1. 用户数据.用户数据是指用于应用系统的数据，包括与应用系统的所有相关信息。如本书的人力资源管理系统中的员工信息表、职位信息、部门信息等。 2. 系统数据.系统数据是指用于管理用户数据和Oracle数据库本身的数据。如表的结构、空间、用户、数据文件的位置（存放路径、访问时间等），数据字典。&gt; Oracle数据库中有一种特殊的数据文件，称为临时数据文件，属于数据库的临时表空间。临时数据文件中的内容是临时性的，在一定条件下自动释放。### 数据文件- 数据文件的存储策略 - 由于对数据库的操作最终转换为对数据文件的操作，因此在数据库运行过程中对数据文件进行频繁的读写操作。为了提供I/O效率，应该合理的分配数据文件的存储位置。 - 把不同存储内容的数据文件放置在不同的硬盘上，可以并行访问数据，提高系统读写的效率。 - 初始化参数文件、控制文件、重做日志文件最好不要与数据文件存放在同一个磁盘上，以免数据库发生介质故障时，无法恢复数据库。 &gt; 数据文件与表空间的关系： &lt;BR/&gt; 1. 一个表空间可以包含几个数据文件&lt;BR/&gt; 2. 一个数据文件只能对应一个表空间 ![Oracle图片14](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片14.png)---- 数据文件的管理 - 创建数据文件 - 修改数据文件的大小 - 改变数据文件的可用性 - 改变数据文件的名称和位置 - 查询数据文件的信息### 创建数据文件1. 数据文件依附于表空间而存在，创建数据文件就是向表空间添加文件2. 在创建数据文件时应该根据文件数据量的大小确定文件的大小以及文件的增长方式。 3. 语法： - ALTER TABLESPACE…ADD DATAFILE… - ALTER TABLESPACE…ADD TEMPFILE… 14. 例子： 例: 向TEMP表空间添加一个大小为5MB的临时数据文件。 SQL&gt;ALTER TABLESPACE temp ADD TEMPFILE &#39;d:\\app\\administrator\\oradata\\temp03.dbf&#39; SIZE 5M; 1234567891011### 修改数据文件大小1. 方法 - 设置数据文件为自动增长方式。 - 手工改变数据文件的大小。2. 设置数据文件为自动增长方式 - 创建时设置数据文件为自动增长 - 创建后修改数据文件为自动增长 - `AUTOEXTEND ON NEXT…MAXSIZE…| UNLIMITED`3. 手工改变数据文件的大小 -`ALTER DATABASE DATAFILE…RESIZE…` 例：为ORCL数据库的USERS表空间添加一个自动增长的数据文件。 SQL&gt;ALTER TABLESPACE users ADD DATAFILE ‘d:\\app\\administrator\\oradata\\orcl\\userdata03.dbf&#39; SIZE 10M AUTOEXTEND ON NEXT 512K MAXSIZE 250M; 例：修改ORCL数据库USERS表空间的数据文件userdata02.dbf为自动增长。 SQL&gt;ALTER DATABASE DATAFILE &#39;d:\\app\\administrator\\oradata\\orcl\\userdata02.dbf &#39; AUTOEXTEND ON NEXT 512K MAXSIZE UNLIMITED; 1234567891011121314### 改变数据文件的可用性1. 概念:可以通过将数据文件联机或脱机来改变数据文件的可用性。2. 在下面几种情况下需要改变数据文件的可用性： - 要进行数据文件的脱机备份时，需要先将数据文件脱机； - 需要重命名数据文件或改变数据文件的位置时，需要先将数据文件脱机； - 如果Oracle在写入某个数据文件时发生错误，会自动将该数据文件设置为脱机状态，并且记录在警告文件中。排除故障后，需要以手动方式重新将该数据文件恢复为联机状态。 - 数据文件丢失或损坏，需要在启动数据库之前将数据文件脱机。3. 归档模式下数据文件可用性的改变 - 数据文件可用性的改变 `ALTER DATABASE DATAFILE… ONLINE|OFFLINE` - 临时数据文件可用性的改变 `ALTER DATABASE TEMPFILE… ONLINE|OFFLINE`4. 例子：（数据文件脱机后需要进行恢复再联机才可以完成联机） 1. 将USERS表空间的数据文件USERS02.DBF脱机 SQL&gt;ALTER DATABASE DATAFILE &#39;d:\\app\\administrator\\oradata\\ users02.dbf&#39; OFFLINE; 2. 在归档模式下，将数据文件联机之前需要使用RECOVER DATAFILE语句对数据文件进行恢复 SQL&gt; RECOVER DATAFILE &#39;d:\\app\\administrator\\oradata\\users02.dbf‘ 3. 将USERS表空间的数据文件USERS02.DBF联机 SQL&gt;ALTER DATABASE DATAFILE &#39;d:\\app\\administrator\\oradata\\users02.dbf&#39; ONLINE; 123456789101112131415161718192021### 改变数据文件的名称和位置1. 改变数据文件的名称和位置分为两种情况 - 如果数据文件属于同一个表空间，使用: `ALTER ==TABLESPACE== … RENAME DATAFILE … TO` - 如果数据文件属于多个表空间，使用: `ALTER ==DATABASE== … RENAME FILE … TO`2. 注意： &gt; 改变数据文件的名称或位置时，Oracle只是改变记录在控制文件和数据字典中的数据文件信息，并没有改变操作系统中数据文件的名称和位置，因此需要DBA手动更改操作系统中数据文件的名称和位置3. 改变同一个表空间的数据文件步骤： - (1)表空间脱机 `ALTER TABLESPACE tablespace_name… OFFLINE` - (2)修改操作系统中文件名称或位置 - (3)执行ALTER 重命名语句 `ALTER TABLESPACE tablespace_name…RENAME DATAFILE…TO` - (4)表空间联机 `ALTER TABLESPACE tablespace…ONLINE` 将ORCL数据库中USERS表空间的数据文件users01.dbf移动到d:\\app\\administrator\\oradata目录中。 (1) ALTER TABLESPACE users OFFLINE; (2) HOST COPY d:\\app\\administrator\\oradata\\orcl\\users01.dbf (原位置) d:\\app\\administrator\\oradata\\users01.dbf （新位置） (3) ALTER TABLESPACE users RENAME DATAFILE ‘d:\\app\\administrator\\oradata\\orcl\\users01.dbf’ TO ‘d:\\app\\administrator\\oradata\\users01.dbf’ (4) ALTER TABLESPACE users ONLINE; 12345678### 查询数据文件信息1. 数据文件信息 - dba_data_files:包含数据库中所有数据文件的信息，包括数据文件所属的表空间、数据文件编号等。 - v$datafile:包含从控制文件中获取的数据文件信息。2. 临时文件信息 - dba_temp_files:包含数据库中所有临时数据文件的信息。 - $tempfile:包含所有临时文件的基本信息。 3. 例子： 1. 查询数据文件动态信息 SELECT name,file#,status,checkpoint_change# FROM v$datafile 2. 查询数据文件的增长方式 SELECT tablespace_name,bytes,autoextensible, file_name FROM dba_data_files 3. 查询临时数据文件信息 SELECT tablespace_name,file_name, autoextensible FROM dba_temp_files; 1234567891011121314151617181920212223242526---------### 控制文件设置与管理- 控制文件是一个很小的二进制文件。用于记录和维护数据库的物理结构, 包括:数据库名称、数据文件和重做日志文件的名称和位置等。- 一个实例只能访问一个数据库，通过控制文件在实例和数据库之间建立关联。- Oracle启动时通过控制文件查找数据文件位置和联机重做日志。- 数据库运行时，控制文件被不断更新。- 数据库至少要包含一个控制文件,一个数据库也可以同时拥有多个控制文件，Oracle建议使用多个控制文件避免因单个控制文件损坏而导致的数据库无法启动。- 控制文件对数据库至关重要，应联机保存多个备份，存储在不同的磁盘上。1. 数据库控制文件名通过init.ora文件的CONTROL_FILES 参数规定。 - 主要包含信息类型： - (1) 数据名 - (2) 数据库创建时间 - (3) 数据文件和重做日志文件的存放位置 - (4) 表空间名 - (5) 当前日志序列号 - (6) 检查点信息 - (7) 关于重做日志和归档的当前状态信息 ![Oracle图片15](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片15.png) - v$controlfile中保存着控制文件信息的最基本信息。 - (1) DESC v$controlfile; - (2) SELECT * FROM v$controlfile; SQL&gt;SELECT name FROM v$controlfile; 运行结果： NAME -- -- -- D:\\app\\administrator\\oradata\\orcl\\control01.ctl D:\\app\\administrator\\recvery_area\\orcl\\control02.ctl 12345678910112. 创建控制文件 - 实现多路复用控制文件 - 备份控制文件 - 删除控制文件 - 查看控制文件的信息3. 创建控制文件的情形 - 创建数据库时，需要创建控制文件； - 控制文件全部丢失或损坏； - 需要修改某个永久性数据库结构参数； 如： 数据库名称、 MAXLOGFILES（ 最大重做日子文件数量）、 MAXLOGMEMBERS（重做日志文件组中最大成员数量）、 MAXDATAFILES（最大数据文件数量）、 MAXINSTANCES（同时可访问数据库最大实例个数）等。 1234. 创建控制文件的基本步骤 - 列出数据库中所有的数据文件和重做日志文件的名称和路径 select member from v$logfile; select name from v$datafile; select value from v$parameter where name=&#39;control_files&#39;; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 - 如果数据库仍然处于运行状态，则关闭数据库 ` SHUTDOWN IMMEDIATE` - 在操作系统级别备份所有的数据文件和联机重做日志文件 - 启动实例，STARTUP NOMOUNT4. 创建控制文件的基本步骤 (续) - 利用前面得到的文件列表，执行CREATE CONTROLFILE创建一个新控制文件。 - 在操作系统级别对新建的控制文件进行备份 `ALTER DATABASE BACKUP CONTROLFILE TO &#x27;FILE&#x27;` - 如果数据库需要恢复，则进行恢复数据库操作 - 如果创建控制文件时指定了NORESTLOGS，可以完全恢复数据库。 ` RECOVER DATABASE ;` - 如果创建控制文件时指定了RESETLOGS，则必须在恢复时指定USING BACKUP CONTROLFILE。 `RECOVER DATABASE USING BACKUP CONTROLFILE;`4. 创建控制文件的基本步骤 (续) - 重新打开数据库 - 如果数据库不需要恢复或已经对数据库进行了完全恢复，则可以正常打开数据库。 `ALTER DATABASE OPEN;` - 如果在创建控制文件时使用了RESETLOGS参数，则必须指定以RESETLOGS方式打开数据库 `ALTER DATABASE OPEN RESETLOGS;`### 补充：oracle的启动状态Oracle数据库启动的基本步骤 1. nomount：读初始化参数文件，启动实例。 ==startup nomount== //读取初始化参数init.ora文件，启动instance，即启动SGA和后台进程，这种启动只需要init.ora文件。这种方式启动下可执行：重建控制文件、重建数据库2. mount ： 执行“nomount”，然后打开控制文件，确认数据文件和联机日志文件的位置，但此时不对数据文件和日志文件进行校验检查(是否存在)。这种方式启动下可执行：数据库日志归档、数据库介质恢复、使数据文件联机或脱机。3. open ：先执行“nomount”，然后执行“mount”，再打开包括Redo log文件在内的所有数据库文件，即所有数据文件，日志文件。这种方式下可访问数据库中的数据。可以对全体用户提供服务了。![Oracle图片16](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片16.png)### 实现多路复用控制文件1.控制文件多路复用的特点1. 在数据库服务器上将控制文件存放在多个磁盘分区或者多块硬盘上。2. 数据库系统在需要更新控制文件的时候，就会自动同时更新多个控制文件。如此的话，当其中一个控制文件出现损坏时，系统会自动启用另外的控制文件。所以采用多路复用控制文件可以在很大程度上提高控制文件的安全性。3. 最重要的是，在控制文件转换的过程之中，不会有停机现象的产生。4. 多个镜像文件通过参数文件的 control_files设置。&lt;br/&gt;2.多路复用控制文件创建步骤1. 编辑初始化参数CONTROL_FILES 用来(从逻辑上（dbms角度）增加控制文件。)2. 关闭数据库 `SHUTDOWN IMMEDIATE; `3. 拷贝一个原有的控制文件到新的位置，并重新命名(从物理上（操作系统角度）增加控制文件，与第一步中增加的文件相对应。)4. 重新启动数据库 STARTUP - 例子： 例：当前数据库的控制文件为control01.ctl和control02.ctl，再添加一个名为control03.ctl的控制文件。 （1）alter system set control_files= &#39;d:\\app\\administrator\\oradata\\control01.ctl&#39;, &#39;d:\\app\\administrator\\oradata\\control02.ctl&#39;, &#39;d:\\app\\administrator\\control03.ctl&#39; scope=spfile; （2）shutdown immediate （3）host copy d:\\app\\administrator\\oradata\\control01.ctl d:\\app\\administrator\\control03.ctl （4）startup 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168### 删除控制文件删除控制文件的步骤：- 编辑CONTROL_FILES初始化参数，使其不包含要删除的控制文件（dbms级上逻辑删除）- 关闭数据库- 在操作系统中删除控制文件（实际删除文件）- 重新启动数据库 ---操作：- ![Oracle图片17](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片17.png)- 退出数据库，- 在操作系统下建好要添加的控制文件![Oracle图片18](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片18.png)- ORA-01507错误处理： - ![Oracle图片19](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片19.png)# 第六章![Oracle图片20](https://gitee.com/RoleHalo/blog-image/raw/master/image/Oracle图片20.png)#### 5. DQL:数据检索，包括select### 模式1. 创建数据库，并完成数据库的存储设置后，就可以根据应用的需求设计来创建所需要的数据库对象，并使用这些数据库对象。2. Oracle数据库常用对象主要包括表、索引、视图、序列、分区表与分区索引等等。3. 模式(Schema)概念 - 是指一系列逻辑数据结构或对象的集合。在创建用户的时候，会同时生成一个与用户同名的方案(模式)，此方案归同名用户所有。 - 通常情况下，用户所创建数据库对象都保存在与自己同名的模式中。 - 同一模式中数据库对象的名称必须惟一，而在不同模式中的数据库对象可以同名。 - 默认情况下，用户引用的对象是与自己同名模式中的对象，如果要引用其他模式中的对象，需要在该对象名之前指明对象所属模式。 ---## 约束与参数约束（constraint）约束作用 是在表中定义的用于维护数据库完整性的一些规则。通过对表中列定义约束，可以防止在执行DML（Data Manipulation Language）操作时，将不符合要求的数据插入到表中。约束类型PRIMARY KEY：主键约束UNIQUE：惟一性约束CHECK：检查约束FOREIGN KEY：外键约束NULL/NOT NULL：空/非空约束约束的两种形式：列级约束和表级约束。列级约束：从形式上看，在每列定义完后马上定义的约束，在逗号之前就定义好了。定义列级约束的语法为： [CONSTRAINT constraint_name] constraint_type [conditioin]; 举例：create table parent(c1 number primary key ); create table child (c number primary key , c2 number references parent(c1));。注意Oracle约束通过名称进行标识。在定义时可以通过CONSTRAINT关键字定义约束命名。如果用户没有为约束命名，Oracle将自动为约束命名。 表级约束：在表中列都定义完后在单独定义约束语法： [CONSTRAINT constraint_name] constraint_type([column1_name, column2_name,…]|[condition]);举例：Create table child( c number , c2 number , primary key (c2), foreign key(c2) references parent(c1));有些时候，列级约束无法实现某种约束的定义，比如联合主键的定义，就要用到表级约束:create table test(id1 number , id2 number, primary key(id1, id2));### PRIMARY KEY：主键约束PRIMARY KEY特点定义主键，起惟一标识作用，其值不能为NULL，也不能重复；一个表中只能定义一个主键约束；建立主键约束的同时，在该列上建立一个惟一性索引，可以为它指定存储位置和存储参数；主键约束可以是列级约束，也可以是表级约束。### 惟一性约束：UNIQUE惟一性约束特点定义为惟一性约束的某一列或多个列的组合的取值必须惟一；如果某一列或多个列仅定义惟一性约束，而没有定义非空约束，则该约束列可以包含多个空值；Oracle自动在惟一性约束列上建立一个惟一性索引，可以为它指定存储位置和存储参数；惟一性约束可以是列级约束，也可以是表级约束。 #### PRIMARY KEY与UNIQUE比较在一个基本表中只能定义一个PRIMARY KEY约束，但可定义多个UNIQUE约束；对于指定为PRIMARY KEY的一个列或多个列的组合，其中任何一个列都不能出现空值，而对于UNIQUE所约束的唯一键，则允许为空。不能为同一个列或一组列既定义UNIQUE约束，又定义PRIMARY KEY约束。### 检查约束特点检查约束用来限制列值所允许的取值范围，其表达式中必须引用相应列，并且表达式的计算结果必须是一个布尔值；一个列可以定义多个检查约束；检查约束可以是列级约束，也可以是表级约束。 ### 外键约束：FOREIGN KEY概念FOREIGN KEY约束指定某一个列或一组列作为外部键，其中，包含外部键的表称为从表，包含外部键所引用的主键或唯一键的表称主表。系统保证从表在外部键上的取值要么是主表中某一个主键值或唯一键值，要么取空值。以此保证两个表之间的连接，确保了实体的参照完整性。特点定义外键约束的列的取值要么是主表参照列的值，要么为空；外键列只能参照于主表中的主键约束列或惟一性约束列；可以在一列或多列组合上定义外键约束；外键约束可以是列级约束，也可以是表级约束。### 空/非空约束：NULL/NOT NULL 特点在同一个表中可以定义多个NOT NULL约束；只能是列级约束。## 参数### 参数（parameter_list）1. 在定义表时，可以通过参数设置表存储在哪一个表空间中，和存储空间分配等。 - TABLESPACE：TABLESPACE子句用于指定表存储的表空间。 - STORAGE：STORAGE子句用于设置表的存储参数。若不指定，则继承表空间的存储参数设置。 NITIAL NEXTPCTINCREASEMINEXTENTSMAXEXTENTSBUFFER_POOL (KEEP、RECYCLE、DEFAULT) STORAGE参数设置需注意如果表空间管理方式为EXTENT MANAGEMENT LOCAL AUTOALLOCATE，则在STORAGE中只能指定INITIAL，NEXT和MINEXTENTS这3个参数；如果表空间管理方式为EXTENT MANAGEMENT LOCAL UNIFORM，则不能指定任何STORAGE子句；如果表空间管理方式为EXTENT MANAGEMENT DICTIONARY，则在STORAG中可以设置任何参数。数据块管理参数 PCTFREE：用于指定数据块中必须保留的最小空闲空间。PCTUSED：用于指定当数据块空闲空间达到PCTFREE参数的限制后，数据块能够被再次使用前，已占用的存储空间必须低于的比例。INITRANS：用于指定能够并发访问同一个数据块的事务的数量。MAXTRANS：用于指定能够并发访问同一个数据块的事务的最大数量。LOGGING与NOLOGGING子句默认为NOLOGGING，即表的创建操作不会记录到重做日志文件中，尤其适合通过查询创建表的情况。使用LOGGING子句，表的创建操作（包括通过查询创建表时的插入记录操作）都将记录到重做日志文件中。PARALLEL、NOPARALLEL 并行建表CACHE、NOCACHE 表中数据是否缓存### 索引1. 索引概念及作用：索引是为了加速对表中元组的检索而创建的一种分散存储结构；2. 是对表而建立的，由除存放表的数据页面以外的索引页面组成，独立于被索引的表；3. 通过使用索引加速行的检索，但减慢更新的速度；4. 快速定位数据，减少磁盘 I/O；5. Oracle自动使用、维护索引### 序列### 分区#### 1. 分区概念- 所谓的分区是指将一个巨型表或巨型索引分成若干独立的组成部分进行存储和管理，每一个相对小的、可以独立管理的部分，称为原来表或索引的分区。- 每个分区都具有相同的逻辑属性，但物理属性可以不同。如具有相同列、数据类型、约束等，但可以具有不同的存储参数、位于不同的表空间等。分区后，表中每个记录或索引条目根据分区条件分散存储到不同分区中 。#### 2. 对巨型表进行分区具有下列优点：- 提高数据的安全性，一个分区的损坏不影响其他分区中数据的正常使用。- 将表的各个分区存储在不同磁盘上，提高数据的并行操作能力。- 简化数据的管理，可以将某些分区设置为不可用状态，某些分区设置为可用状态，某些分区设置为只读状态，某些分区设置为读写状态。- 操作的透明性，对表进行分区并不影响对数据进行操作的SQL语句。- 分区条件： - 表的大小超过2GB - 要对一个表进行并行DML操作，必须分区; - 为了平衡硬盘的I/O操作，将一个表分散存储在不同的表空间中，必须对它进行分区; - 如果需要将表一部分设置为只读，另一部分为可更新的，必须对表进行分区;#### 范围分区：- 语法: create table table(…) partition by range (column1[,column2,…]) ( partition partition1 values less than(literal|maxvalue) [tablespace tablespace] [,partition partition2 values less than(literal|maxvalue) [tablespace tablespace],…] )… 123456789 - 其中： - PARTITION BY RANGE：指明采用范围分区方法。 - column：分区列，可以是单列分区，也可以是多列分区。 - PARTITION partition1 ：设置分区名称。 - VALUES LESS THAN：设置分区列值的上界。 - TABLESPACE：设置分区对应的表空间。- 例子： 创建一个分区表，将学生信息根据其出生日期不同进行分区，将1980年1月1日前出生的学生信息保存在TBS1表空间， 1980年1月1日到1990年1月1日出生的学生信息保存在TBS2表空间中，其他学生信息保存在TBS3表空间中。 create table student_range( sno number(6) primary key, sname varchar2(10), sage int, birthday date ) partition by range(birthday) ( partition p1 values less than(to_date(&#39;1980-1-1&#39;, &#39;yyyy-mm-dd&#39;)) tablespace tbs1, partition p2 values less than(to_date(&#39;1990-1-1&#39;, &#39;yyyy-mm-dd&#39;)) tablespace tbs2, partition p3 values less than(maxvalue) tablespace tbs3 ); 12#### 列表分区- 语法: create table table(…) partition by list(column) ( partition partition1 values([literal|null]|[default]) [tablespace tablespace] [,partition partition2 values([literal|null]|[default]) [tablespace tablespace],…] )… 1234- 例子：创建一个分区表，将学生信息按性别不同进行分区，男学生信息保存在表空间TBS1中，而女学生信息保存在TBS2中 。&gt; 注意需要先创建TBS1， TBS2CREATE TABLESPACE TBS1 DATAFILE &#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\ORCLTBS1_1.DBF&#x27; SIZE 50M; create table student_list( sno number(6) primary key, sname varchar2(10), sex char(2) check(sex in (&#39;m&#39;, &#39;f&#39;)) ) partition by list(sex) ( partition stu_male values(&#39;m&#39;) tablespace tbs1, partition stu_female values(&#39;f&#39;) tablespace tbs2 ); 12#### 散列分区- 语法： create table table(…) partition by hash (column1[,column2,…]) [(partition partition [tablespace tablespace][,…])]| [partitions hash_partition_quantity store in (tablespace1[,…])]… 参数： paritition by hash（col1,…) 使用partition指定分区数量及store in指定分区存储空间；或使用partiton指定每个分区名称以及其存储空间。 1- 例子： 例：创建一个分区表，根据学号将学生信息均匀分布到TBS1 和TBS2两个表空间中 。 create table student_hash ( sno number(6) primary key, sname varchar2(10) ) partition by hash(sno) ( partition p1 tablespace tbs1, partition p2 tablespace tbs2 ); 123456#### 复合分区1. 复合分区包括: - 范围-列表复合分区: - 范围-列表复合分区先对表进行范围分区，然后再对每个分区进行列表分区，即在一个范围分区中创建多个列表子分区。 - 创建一个范围-列表复合分区表，将1980年1月1日前出生的男、女学生信息分别保存在TBS1和TBS2表空间中，1980年1月1日到1990年1月1日出生的男、女学生信息分别保存在TBS3和TBS4表空间中，其他学生信息保存在TBS5表空间间中。 创建一个范围-列表复合分区表，将1980年1月1日前出生的男、女学生信息分别保存在TBS1和TBS2表空间中，1980年1月1日到1990年1月1日出生的男、女学生信息分别保存在TBS3和TBS4表空间中，其他学生信息保存在TBS5表空间中。 create table student_range_list( sno number(6) primary key, sname varchar2(10), sex char(2) check(sex in (&#39;m&#39;,&#39;f&#39;)), sage number(4), birthday date ) partition by range(birthday) subpartition by list(sex) (partition p1 values less than(to_date(&#39;1980-1-1&#39;, &#39;yyyy-mm-dd&#39;)) (subpartition p1_sub1 values(&#39;m&#39;) tablespace tbs1, subpartition p1_sub2 values(&#39;f&#39;) tablespace tbs2), partition p2 values less than(to_date(&#39;1990-1-1&#39;, &#39;yyyy-mm-dd&#39;)) (subpartition p2_sub1 values(&#39;m&#39;) tablespace tbs3, subpartition p2_sub2 values(&#39;f&#39;) tablespace tbs4), partition p3 values less than(maxvalue) tablespace tbs5 ); 1234- 范围-散列复合分区: - 范围-散列复合分区先对表进行范围分区，然后再对每个分区进行散列分区，即在一个范围分区中创建多个散列子分区。 - 示例: - 创建一个范围-散列复合分区表，将1980年1月1日前出生的学生信息均匀地保存在ORCLTBS1和ORCLTBS2表空间中，1980年1月1日到1990年1月1日出生的学生信息保存在ORCLTBS3和ORCLTBS4表空间中，其他学生信息保存在ORCLTBS5表空间中。 create table student_range_hash( sno number(6) primary key, sname varchar2(10), sage number(4), birthday date ) partition by range(birthday) subpartition by hash(sage) (partition p1 values less than(to_date(&#39;1980-1-1&#39;, &#39;yyyy-mm-dd&#39;)) (subpartition p1_sub1 tablespace orcltbs1, subpartition p1_sub2 tablespace orcltbs2), partition p2 values less than(to_date(&quot;1990-1-1&quot;, &quot;yyyy-mm-dd&quot;)) (subpartition p2_sub1 tablespace orcltbs3, subpartition p2_sub2 tablespace orcltbs4), partition p3 values less than(maxvalue) tablespace orcltbs5 ); ``` 创建复合分区时需要指定: 分区方法（partition by range） 分区列 子分区方法（subpartition by hash， subpartition by list） 子分区列 每个分区中子分区数量或子分区的描述。","comments":true,"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://example.com/tags/Oracle/"}]}]